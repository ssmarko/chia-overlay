From 337dbd4e5c3d1d097c8a59759dad5377b50681e7 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Tue, 19 Apr 2022 13:53:59 -0500
Subject: [PATCH 01/77] Revert "Revert "Pin mac intel installer to 10.15
 (#11209)" (#11210)" (#11211)

This reverts commit d3e73a75ab44c799f8b6f9a76fab550ad6d7824a.
---
 .github/workflows/build-macos-installer.yml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/.github/workflows/build-macos-installer.yml b/.github/workflows/build-macos-installer.yml
index 09597f3ef..e7cd7e639 100644
--- a/.github/workflows/build-macos-installer.yml
+++ b/.github/workflows/build-macos-installer.yml
@@ -25,7 +25,7 @@ jobs:
       max-parallel: 4
       matrix:
         python-version: [3.9]
-        os: [macOS-latest]
+        os: [macos-10.15]
 
     steps:
     - name: Checkout Code
-- 
2.34.1


From 7a123afddb1bb1c5b431ca6c419696e205be6fc5 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Tue, 19 Apr 2022 17:43:06 -0500
Subject: [PATCH 02/77] Fix install.sh test for bookworm (#11227)

---
 .github/workflows/test-install-scripts.yml | 10 ++++++++++
 1 file changed, 10 insertions(+)

diff --git a/.github/workflows/test-install-scripts.yml b/.github/workflows/test-install-scripts.yml
index 0a79447b3..7d27cec94 100644
--- a/.github/workflows/test-install-scripts.yml
+++ b/.github/workflows/test-install-scripts.yml
@@ -156,6 +156,16 @@ jobs:
         apt-get --yes update
         apt-get install --yes git lsb-release sudo
 
+    # @TODO this step can be removed once Python 3.10 is supported
+    # Python 3.10 is now the default in bookworm, so install 3.9 specifically so install does not fail
+    - name: Prepare debian:bookworm
+      if: ${{ matrix.distribution.name == 'debian:bookworm' }}
+      env:
+        DEBIAN_FRONTEND: noninteractive
+      run: |
+        apt-get update -y
+        apt-get install -y python3.9-venv
+
     - name: Prepare Fedora
       if: ${{ matrix.distribution.type == 'fedora' }}
       run: |
-- 
2.34.1


From 83a740571b3be4eadc23d9def5640b14ebd6d3de Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 20 Apr 2022 11:02:45 -0700
Subject: [PATCH 03/77] aiohttp==3.8.1 for Python 3.10 (#11129)

---
 setup.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/setup.py b/setup.py
index 2ac24927f..adfadae70 100644
--- a/setup.py
+++ b/setup.py
@@ -11,7 +11,7 @@ dependencies = [
     "clvm_tools==0.4.4",  # Currying, Program.to, other conveniences
     "chia_rs==0.1.1",
     "clvm-tools-rs==0.1.7",  # Rust implementation of clvm_tools
-    "aiohttp==3.7.4",  # HTTP server for full node rpc
+    "aiohttp==3.8.1",  # HTTP server for full node rpc
     "aiosqlite==0.17.0",  # asyncio wrapper for sqlite, to store blocks
     "bitstring==3.1.9",  # Binary data management library
     "colorama==0.4.4",  # Colorizes terminal output
-- 
2.34.1


From 0aaa3436910dd86cf381dbba6305b2b312d4158b Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 20 Apr 2022 11:03:31 -0700
Subject: [PATCH 04/77] replace some
 asyncio.get_event_loop().run_until_complete() with asyncio.run() (#11131)

---
 tests/core/util/test_config.py           | 2 +-
 tests/util/alert_server.py               | 2 +-
 tests/wallet/test_singleton_lifecycle.py | 3 +--
 3 files changed, 3 insertions(+), 4 deletions(-)

diff --git a/tests/core/util/test_config.py b/tests/core/util/test_config.py
index e2493f8c8..c1c80ce51 100644
--- a/tests/core/util/test_config.py
+++ b/tests/core/util/test_config.py
@@ -138,7 +138,7 @@ def run_reader_and_writer_tasks(root_path: Path, default_config: Dict):
     Subprocess entry point. This function spins-off threads to perform read/write tasks
     concurrently, possibly leading to synchronization issues accessing config data.
     """
-    asyncio.get_event_loop().run_until_complete(create_reader_and_writer_tasks(root_path, default_config))
+    asyncio.run(create_reader_and_writer_tasks(root_path, default_config))
 
 
 @pytest.fixture(scope="function")
diff --git a/tests/util/alert_server.py b/tests/util/alert_server.py
index fbf25bf50..4f0f2d7ad 100644
--- a/tests/util/alert_server.py
+++ b/tests/util/alert_server.py
@@ -77,7 +77,7 @@ def main():
         )
         quit()
 
-    return asyncio.get_event_loop().run_until_complete(run_and_wait(file_path, port))
+    return asyncio.run(run_and_wait(file_path, port))
 
 
 if __name__ == "__main__":
diff --git a/tests/wallet/test_singleton_lifecycle.py b/tests/wallet/test_singleton_lifecycle.py
index d332a20c1..1cf8a8c18 100644
--- a/tests/wallet/test_singleton_lifecycle.py
+++ b/tests/wallet/test_singleton_lifecycle.py
@@ -113,8 +113,7 @@ def test_only_odd_coins_0():
     conditions = Program.to(condition_list)
     coin_spend = CoinSpend(farmed_coin, ANYONE_CAN_SPEND_PUZZLE, conditions)
     spend_bundle = SpendBundle.aggregate([launcher_spend_bundle, SpendBundle([coin_spend], G2Element())])
-    run = asyncio.get_event_loop().run_until_complete
-    coins_added, coins_removed = run(check_spend_bundle_validity(bt.constants, blocks, spend_bundle))
+    coins_added, coins_removed = asyncio.run(check_spend_bundle_validity(bt.constants, blocks, spend_bundle))
 
     coin_set_added = set([_.coin for _ in coins_added])
     coin_set_removed = set([_.coin for _ in coins_removed])
-- 
2.34.1


From a663ece4c3259efde7c175611d33603ced8be9d9 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 20 Apr 2022 11:05:52 -0700
Subject: [PATCH 05/77] fix ssl context creation for server vs. client side
 (#11134)

---
 chia/rpc/rpc_server.py | 7 +++++--
 chia/server/server.py  | 2 +-
 tests/block_tools.py   | 4 ++--
 3 files changed, 8 insertions(+), 5 deletions(-)

diff --git a/chia/rpc/rpc_server.py b/chia/rpc/rpc_server.py
index 4abf16969..aff8aecaf 100644
--- a/chia/rpc/rpc_server.py
+++ b/chia/rpc/rpc_server.py
@@ -9,7 +9,7 @@ from aiohttp import ClientConnectorError, ClientSession, ClientWebSocketResponse
 
 from chia.rpc.util import wrap_http_handler
 from chia.server.outbound_message import NodeType
-from chia.server.server import ssl_context_for_server
+from chia.server.server import ssl_context_for_client, ssl_context_for_server
 from chia.types.peer_info import PeerInfo
 from chia.util.byte_types import hexstr_to_bytes
 from chia.util.ints import uint16
@@ -42,6 +42,9 @@ class RpcServer:
         self.ssl_context = ssl_context_for_server(
             self.ca_cert_path, self.ca_key_path, self.crt_path, self.key_path, log=self.log
         )
+        self.ssl_client_context = ssl_context_for_client(
+            self.ca_cert_path, self.ca_key_path, self.crt_path, self.key_path, log=self.log
+        )
 
     async def stop(self):
         self.shut_down = True
@@ -278,7 +281,7 @@ class RpcServer:
                     autoclose=True,
                     autoping=True,
                     heartbeat=60,
-                    ssl_context=self.ssl_context,
+                    ssl_context=self.ssl_client_context,
                     max_msg_size=max_message_size,
                 )
                 await self.connection(self.websocket)
diff --git a/chia/server/server.py b/chia/server/server.py
index 9edac98fc..896906ce1 100644
--- a/chia/server/server.py
+++ b/chia/server/server.py
@@ -48,7 +48,7 @@ def ssl_context_for_server(
     if check_permissions:
         verify_ssl_certs_and_keys([ca_cert, private_cert_path], [ca_key, private_key_path], log)
 
-    ssl_context = ssl._create_unverified_context(purpose=ssl.Purpose.SERVER_AUTH, cafile=str(ca_cert))
+    ssl_context = ssl._create_unverified_context(purpose=ssl.Purpose.CLIENT_AUTH, cafile=str(ca_cert))
     ssl_context.check_hostname = False
     ssl_context.minimum_version = ssl.TLSVersion.TLSv1_2
     ssl_context.set_ciphers(
diff --git a/tests/block_tools.py b/tests/block_tools.py
index 9a7317297..6c573dffe 100644
--- a/tests/block_tools.py
+++ b/tests/block_tools.py
@@ -50,7 +50,7 @@ from chia.consensus.vdf_info_computation import get_signage_point_vdf_info
 from chia.full_node.signage_point import SignagePoint
 from chia.plotting.util import PlotsRefreshParameter, PlotRefreshResult, PlotRefreshEvents, parse_plot_info
 from chia.plotting.manager import PlotManager
-from chia.server.server import ssl_context_for_server
+from chia.server.server import ssl_context_for_client
 from chia.types.blockchain_format.classgroup import ClassgroupElement
 from chia.types.blockchain_format.coin import Coin, hash_coin_list
 from chia.types.blockchain_format.foliage import Foliage, FoliageBlockData, FoliageTransactionBlock, TransactionsInfo
@@ -364,7 +364,7 @@ class BlockTools:
         key_path = self.root_path / self.config["daemon_ssl"]["private_key"]
         ca_cert_path = self.root_path / self.config["private_ssl_ca"]["crt"]
         ca_key_path = self.root_path / self.config["private_ssl_ca"]["key"]
-        return ssl_context_for_server(ca_cert_path, ca_key_path, crt_path, key_path)
+        return ssl_context_for_client(ca_cert_path, ca_key_path, crt_path, key_path)
 
     def get_plot_signature(self, m: bytes32, plot_pk: G1Element) -> G2Element:
         """
-- 
2.34.1


From 1e7703fe6a8a1394256dff0de651b391478dee81 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:08:35 +0200
Subject: [PATCH 06/77] plotting|tests|setup: Improve `PlotManager` cache
 (#9903)

* plotting|tests: Extend the lifetime of plot data cache entries

* plotting|tests: Add `prover` and `farmer_public_key` to the cache

* plotting: Missing type hints in `Cache` and `CacheEntry`

* setup: Bump `chiapos` to 1.0.10

* plotting: Move cache classes into `chia.plotting.cache`

* plotting: Introduce `CacheEntry.from_disk_prover`

* Make `Cache` a dataclass

* `staticmethod` -> `classmethod`

* Store cache data as `bytes` in `DiskCache`
---
 chia/plotting/cache.py              | 176 ++++++++++++++++++++++++
 chia/plotting/manager.py            | 199 +++++++---------------------
 setup.py                            |   2 +-
 tests/plotting/test_plot_manager.py |  44 +++++-
 4 files changed, 267 insertions(+), 154 deletions(-)
 create mode 100644 chia/plotting/cache.py

diff --git a/chia/plotting/cache.py b/chia/plotting/cache.py
new file mode 100644
index 000000000..58d73a2b9
--- /dev/null
+++ b/chia/plotting/cache.py
@@ -0,0 +1,176 @@
+import logging
+import time
+import traceback
+from dataclasses import dataclass, field
+from pathlib import Path
+from typing import Dict, ItemsView, KeysView, List, Optional, Tuple, ValuesView
+
+from blspy import G1Element
+from chiapos import DiskProver
+
+from chia.plotting.util import parse_plot_info
+from chia.types.blockchain_format.proof_of_space import ProofOfSpace
+from chia.types.blockchain_format.sized_bytes import bytes32
+from chia.util.ints import uint16, uint64
+from chia.util.path import mkdir
+from chia.util.streamable import Streamable, streamable
+from chia.wallet.derive_keys import master_sk_to_local_sk
+
+log = logging.getLogger(__name__)
+
+CURRENT_VERSION: int = 1
+
+
+@streamable
+@dataclass(frozen=True)
+class DiskCacheEntry(Streamable):
+    prover_data: bytes
+    farmer_public_key: G1Element
+    pool_public_key: Optional[G1Element]
+    pool_contract_puzzle_hash: Optional[bytes32]
+    plot_public_key: G1Element
+    last_use: uint64
+
+
+@streamable
+@dataclass(frozen=True)
+class DiskCache(Streamable):
+    version: uint16
+    data: bytes
+
+
+@streamable
+@dataclass(frozen=True)
+class CacheDataV1(Streamable):
+    entries: List[Tuple[str, DiskCacheEntry]]
+
+
+@dataclass
+class CacheEntry:
+    prover: DiskProver
+    farmer_public_key: G1Element
+    pool_public_key: Optional[G1Element]
+    pool_contract_puzzle_hash: Optional[bytes32]
+    plot_public_key: G1Element
+    last_use: float
+
+    @classmethod
+    def from_disk_prover(cls, prover: DiskProver) -> "CacheEntry":
+        (
+            pool_public_key_or_puzzle_hash,
+            farmer_public_key,
+            local_master_sk,
+        ) = parse_plot_info(prover.get_memo())
+
+        pool_public_key: Optional[G1Element] = None
+        pool_contract_puzzle_hash: Optional[bytes32] = None
+        if isinstance(pool_public_key_or_puzzle_hash, G1Element):
+            pool_public_key = pool_public_key_or_puzzle_hash
+        else:
+            assert isinstance(pool_public_key_or_puzzle_hash, bytes32)
+            pool_contract_puzzle_hash = pool_public_key_or_puzzle_hash
+
+        local_sk = master_sk_to_local_sk(local_master_sk)
+
+        plot_public_key: G1Element = ProofOfSpace.generate_plot_public_key(
+            local_sk.get_g1(), farmer_public_key, pool_contract_puzzle_hash is not None
+        )
+
+        return cls(prover, farmer_public_key, pool_public_key, pool_contract_puzzle_hash, plot_public_key, time.time())
+
+    def bump_last_use(self) -> None:
+        self.last_use = time.time()
+
+    def expired(self, expiry_seconds: int) -> bool:
+        return time.time() - self.last_use > expiry_seconds
+
+
+@dataclass
+class Cache:
+    _path: Path
+    _changed: bool = False
+    _data: Dict[Path, CacheEntry] = field(default_factory=dict)
+    expiry_seconds: int = 7 * 24 * 60 * 60  # Keep the cache entries alive for 7 days after its last access
+
+    def __post_init__(self) -> None:
+        mkdir(self._path.parent)
+
+    def __len__(self) -> int:
+        return len(self._data)
+
+    def update(self, path: Path, entry: CacheEntry) -> None:
+        self._data[path] = entry
+        self._changed = True
+
+    def remove(self, cache_keys: List[Path]) -> None:
+        for key in cache_keys:
+            if key in self._data:
+                del self._data[key]
+                self._changed = True
+
+    def save(self) -> None:
+        try:
+            disk_cache_entries: Dict[str, DiskCacheEntry] = {
+                str(path): DiskCacheEntry(
+                    bytes(cache_entry.prover),
+                    cache_entry.farmer_public_key,
+                    cache_entry.pool_public_key,
+                    cache_entry.pool_contract_puzzle_hash,
+                    cache_entry.plot_public_key,
+                    uint64(int(cache_entry.last_use)),
+                )
+                for path, cache_entry in self.items()
+            }
+            cache_data: CacheDataV1 = CacheDataV1(
+                [(plot_id, cache_entry) for plot_id, cache_entry in disk_cache_entries.items()]
+            )
+            disk_cache: DiskCache = DiskCache(uint16(CURRENT_VERSION), bytes(cache_data))
+            serialized: bytes = bytes(disk_cache)
+            self._path.write_bytes(serialized)
+            self._changed = False
+            log.info(f"Saved {len(serialized)} bytes of cached data")
+        except Exception as e:
+            log.error(f"Failed to save cache: {e}, {traceback.format_exc()}")
+
+    def load(self) -> None:
+        try:
+            serialized = self._path.read_bytes()
+            log.info(f"Loaded {len(serialized)} bytes of cached data")
+            stored_cache: DiskCache = DiskCache.from_bytes(serialized)
+            if stored_cache.version == CURRENT_VERSION:
+                cache_data: CacheDataV1 = CacheDataV1.from_bytes(stored_cache.data)
+                self._data = {
+                    Path(path): CacheEntry(
+                        DiskProver.from_bytes(cache_entry.prover_data),
+                        cache_entry.farmer_public_key,
+                        cache_entry.pool_public_key,
+                        cache_entry.pool_contract_puzzle_hash,
+                        cache_entry.plot_public_key,
+                        float(cache_entry.last_use),
+                    )
+                    for path, cache_entry in cache_data.entries
+                }
+            else:
+                raise ValueError(f"Invalid cache version {stored_cache.version}. Expected version {CURRENT_VERSION}.")
+        except FileNotFoundError:
+            log.debug(f"Cache {self._path} not found")
+        except Exception as e:
+            log.error(f"Failed to load cache: {e}, {traceback.format_exc()}")
+
+    def keys(self) -> KeysView[Path]:
+        return self._data.keys()
+
+    def values(self) -> ValuesView[CacheEntry]:
+        return self._data.values()
+
+    def items(self) -> ItemsView[Path, CacheEntry]:
+        return self._data.items()
+
+    def get(self, path: Path) -> Optional[CacheEntry]:
+        return self._data.get(path)
+
+    def changed(self) -> bool:
+        return self._changed
+
+    def path(self) -> Path:
+        return self._path
diff --git a/chia/plotting/manager.py b/chia/plotting/manager.py
index aa309795e..ee158848c 100644
--- a/chia/plotting/manager.py
+++ b/chia/plotting/manager.py
@@ -1,4 +1,3 @@
-from dataclasses import dataclass
 import logging
 import threading
 import time
@@ -11,107 +10,18 @@ from blspy import G1Element
 from chiapos import DiskProver
 
 from chia.consensus.pos_quality import UI_ACTUAL_SPACE_CONSTANT_FACTOR, _expected_plot_size
+from chia.plotting.cache import Cache, CacheEntry
 from chia.plotting.util import (
     PlotInfo,
     PlotRefreshResult,
     PlotsRefreshParameter,
     PlotRefreshEvents,
     get_plot_filenames,
-    parse_plot_info,
 )
 from chia.util.generator_tools import list_to_batches
-from chia.util.ints import uint16
-from chia.util.path import mkdir
-from chia.util.streamable import Streamable, streamable
-from chia.types.blockchain_format.proof_of_space import ProofOfSpace
-from chia.types.blockchain_format.sized_bytes import bytes32
-from chia.wallet.derive_keys import master_sk_to_local_sk
 
 log = logging.getLogger(__name__)
 
-CURRENT_VERSION: uint16 = uint16(0)
-
-
-@streamable
-@dataclass(frozen=True)
-class CacheEntry(Streamable):
-    pool_public_key: Optional[G1Element]
-    pool_contract_puzzle_hash: Optional[bytes32]
-    plot_public_key: G1Element
-
-
-@streamable
-@dataclass(frozen=True)
-class DiskCache(Streamable):
-    version: uint16
-    data: List[Tuple[bytes32, CacheEntry]]
-
-
-class Cache:
-    _changed: bool
-    _data: Dict[bytes32, CacheEntry]
-
-    def __init__(self, path: Path):
-        self._changed = False
-        self._data = {}
-        self._path = path
-        if not path.parent.exists():
-            mkdir(path.parent)
-
-    def __len__(self):
-        return len(self._data)
-
-    def update(self, plot_id: bytes32, entry: CacheEntry):
-        self._data[plot_id] = entry
-        self._changed = True
-
-    def remove(self, cache_keys: List[bytes32]):
-        for key in cache_keys:
-            if key in self._data:
-                del self._data[key]
-                self._changed = True
-
-    def save(self):
-        try:
-            disk_cache: DiskCache = DiskCache(
-                CURRENT_VERSION, [(plot_id, cache_entry) for plot_id, cache_entry in self.items()]
-            )
-            serialized: bytes = bytes(disk_cache)
-            self._path.write_bytes(serialized)
-            self._changed = False
-            log.info(f"Saved {len(serialized)} bytes of cached data")
-        except Exception as e:
-            log.error(f"Failed to save cache: {e}, {traceback.format_exc()}")
-
-    def load(self):
-        try:
-            serialized = self._path.read_bytes()
-            log.info(f"Loaded {len(serialized)} bytes of cached data")
-            stored_cache: DiskCache = DiskCache.from_bytes(serialized)
-            if stored_cache.version != CURRENT_VERSION:
-                # TODO, Migrate or drop current cache if the version changes.
-                raise ValueError(f"Invalid cache version {stored_cache.version}. Expected version {CURRENT_VERSION}.")
-            self._data = {plot_id: cache_entry for plot_id, cache_entry in stored_cache.data}
-        except FileNotFoundError:
-            log.debug(f"Cache {self._path} not found")
-        except Exception as e:
-            log.error(f"Failed to load cache: {e}, {traceback.format_exc()}")
-
-    def keys(self):
-        return self._data.keys()
-
-    def items(self):
-        return self._data.items()
-
-    def get(self, plot_id):
-        return self._data.get(plot_id)
-
-    def changed(self):
-        return self._changed
-
-    def path(self):
-        return self._path
-
 
 class PlotManager:
     plots: Dict[Path, PlotInfo]
@@ -299,10 +209,15 @@ class PlotManager:
                 self._initial = False
 
                 # Cleanup unused cache
-                available_ids = set([plot_info.prover.get_id() for plot_info in self.plots.values()])
-                invalid_cache_keys = [plot_id for plot_id in self.cache.keys() if plot_id not in available_ids]
-                self.cache.remove(invalid_cache_keys)
-                self.log.debug(f"_refresh_task: cached entries removed: {len(invalid_cache_keys)}")
+                self.log.debug(f"_refresh_task: cached entries before cleanup: {len(self.cache)}")
+                remove_paths: List[Path] = []
+                for path, cache_entry in self.cache.items():
+                    if cache_entry.expired(Cache.expiry_seconds) and path not in self.plots:
+                        remove_paths.append(path)
+                    elif path in self.plots:
+                        cache_entry.bump_last_use()
+                self.cache.remove(remove_paths)
+                self.log.debug(f"_refresh_task: cached entries removed: {len(remove_paths)}")
 
                 if self.cache.changed():
                     self.cache.save()
@@ -355,78 +270,61 @@ class PlotManager:
                 if not file_path.exists():
                     return None
 
-                prover = DiskProver(str(file_path))
-
-                log.debug(f"process_file {str(file_path)}")
-
-                expected_size = _expected_plot_size(prover.get_size()) * UI_ACTUAL_SPACE_CONSTANT_FACTOR
                 stat_info = file_path.stat()
 
-                # TODO: consider checking if the file was just written to (which would mean that the file is still
-                # being copied). A segfault might happen in this edge case.
+                cache_entry = self.cache.get(file_path)
+                cache_hit = cache_entry is not None
+                if not cache_hit:
+                    prover = DiskProver(str(file_path))
 
-                if prover.get_size() >= 30 and stat_info.st_size < 0.98 * expected_size:
-                    log.warning(
-                        f"Not farming plot {file_path}. Size is {stat_info.st_size / (1024**3)} GiB, but expected"
-                        f" at least: {expected_size / (1024 ** 3)} GiB. We assume the file is being copied."
-                    )
-                    return None
+                    log.debug(f"process_file {str(file_path)}")
 
-                cache_entry = self.cache.get(prover.get_id())
-                if cache_entry is None:
-                    (
-                        pool_public_key_or_puzzle_hash,
-                        farmer_public_key,
-                        local_master_sk,
-                    ) = parse_plot_info(prover.get_memo())
-
-                    # Only use plots that correct keys associated with them
-                    if farmer_public_key not in self.farmer_public_keys:
-                        log.warning(f"Plot {file_path} has a farmer public key that is not in the farmer's pk list.")
-                        self.no_key_filenames.add(file_path)
-                        if not self.open_no_key_filenames:
-                            return None
-
-                    pool_public_key: Optional[G1Element] = None
-                    pool_contract_puzzle_hash: Optional[bytes32] = None
-                    if isinstance(pool_public_key_or_puzzle_hash, G1Element):
-                        pool_public_key = pool_public_key_or_puzzle_hash
-                    else:
-                        assert isinstance(pool_public_key_or_puzzle_hash, bytes32)
-                        pool_contract_puzzle_hash = pool_public_key_or_puzzle_hash
+                    expected_size = _expected_plot_size(prover.get_size()) * UI_ACTUAL_SPACE_CONSTANT_FACTOR
 
-                    if pool_public_key is not None and pool_public_key not in self.pool_public_keys:
-                        log.warning(f"Plot {file_path} has a pool public key that is not in the farmer's pool pk list.")
-                        self.no_key_filenames.add(file_path)
-                        if not self.open_no_key_filenames:
-                            return None
+                    # TODO: consider checking if the file was just written to (which would mean that the file is still
+                    # being copied). A segfault might happen in this edge case.
 
-                    # If a plot is in `no_key_filenames` the keys were missing in earlier refresh cycles. We can remove
-                    # the current plot from that list if its in there since we passed the key checks above.
-                    if file_path in self.no_key_filenames:
-                        self.no_key_filenames.remove(file_path)
+                    if prover.get_size() >= 30 and stat_info.st_size < 0.98 * expected_size:
+                        log.warning(
+                            f"Not farming plot {file_path}. Size is {stat_info.st_size / (1024 ** 3)} GiB, but expected"
+                            f" at least: {expected_size / (1024 ** 3)} GiB. We assume the file is being copied."
+                        )
+                        return None
 
-                    local_sk = master_sk_to_local_sk(local_master_sk)
+                    cache_entry = CacheEntry.from_disk_prover(prover)
+                    self.cache.update(file_path, cache_entry)
 
-                    plot_public_key: G1Element = ProofOfSpace.generate_plot_public_key(
-                        local_sk.get_g1(), farmer_public_key, pool_contract_puzzle_hash is not None
-                    )
+                assert cache_entry is not None
+                # Only use plots that correct keys associated with them
+                if cache_entry.farmer_public_key not in self.farmer_public_keys:
+                    log.warning(f"Plot {file_path} has a farmer public key that is not in the farmer's pk list.")
+                    self.no_key_filenames.add(file_path)
+                    if not self.open_no_key_filenames:
+                        return None
+
+                if cache_entry.pool_public_key is not None and cache_entry.pool_public_key not in self.pool_public_keys:
+                    log.warning(f"Plot {file_path} has a pool public key that is not in the farmer's pool pk list.")
+                    self.no_key_filenames.add(file_path)
+                    if not self.open_no_key_filenames:
+                        return None
 
-                    cache_entry = CacheEntry(pool_public_key, pool_contract_puzzle_hash, plot_public_key)
-                    self.cache.update(prover.get_id(), cache_entry)
+                # If a plot is in `no_key_filenames` the keys were missing in earlier refresh cycles. We can remove
+                # the current plot from that list if its in there since we passed the key checks above.
+                if file_path in self.no_key_filenames:
+                    self.no_key_filenames.remove(file_path)
 
                 with self.plot_filename_paths_lock:
                     paths: Optional[Tuple[str, Set[str]]] = self.plot_filename_paths.get(file_path.name)
                     if paths is None:
-                        paths = (str(Path(prover.get_filename()).parent), set())
+                        paths = (str(Path(cache_entry.prover.get_filename()).parent), set())
                         self.plot_filename_paths[file_path.name] = paths
                     else:
-                        paths[1].add(str(Path(prover.get_filename()).parent))
+                        paths[1].add(str(Path(cache_entry.prover.get_filename()).parent))
                         log.warning(f"Have multiple copies of the plot {file_path.name} in {[paths[0], *paths[1]]}.")
                         return None
 
                 new_plot_info: PlotInfo = PlotInfo(
-                    prover,
+                    cache_entry.prover,
                     cache_entry.pool_public_key,
                     cache_entry.pool_contract_puzzle_hash,
                     cache_entry.plot_public_key,
@@ -434,6 +332,8 @@ class PlotManager:
                     stat_info.st_mtime,
                 )
 
+                cache_entry.bump_last_use()
+
                 with counter_lock:
                     result.loaded.append(new_plot_info)
 
@@ -445,7 +345,8 @@ class PlotManager:
                 log.error(f"Failed to open file {file_path}. {e} {tb}")
                 self.failed_to_open_filenames[file_path] = int(time.time())
                 return None
-            log.info(f"Found plot {file_path} of size {new_plot_info.prover.get_size()}")
+            log.info(f"Found plot {file_path} of size {new_plot_info.prover.get_size()}, cache_hit: {cache_hit}")
+
             return new_plot_info
 
         with self, ThreadPoolExecutor() as executor:
diff --git a/setup.py b/setup.py
index adfadae70..5bd1599eb 100644
--- a/setup.py
+++ b/setup.py
@@ -6,7 +6,7 @@ dependencies = [
     "blspy==1.0.9",  # Signature library
     "chiavdf==1.0.5",  # timelord and vdf verification
     "chiabip158==1.1",  # bip158-style wallet filters
-    "chiapos==1.0.9",  # proof of space
+    "chiapos==1.0.10",  # proof of space
     "clvm==0.9.7",
     "clvm_tools==0.4.4",  # Currying, Program.to, other conveniences
     "chia_rs==0.1.1",
diff --git a/tests/plotting/test_plot_manager.py b/tests/plotting/test_plot_manager.py
index fea50cc4e..41a9a363c 100644
--- a/tests/plotting/test_plot_manager.py
+++ b/tests/plotting/test_plot_manager.py
@@ -19,7 +19,7 @@ from chia.plotting.util import (
 )
 from chia.util.config import create_default_chia_config
 from chia.util.path import mkdir
-from chia.plotting.manager import PlotManager
+from chia.plotting.manager import Cache, PlotManager
 from tests.block_tools import get_plot_dir
 from tests.plotting.util import get_test_plots
 from tests.time_out_assert import time_out_assert
@@ -185,7 +185,6 @@ async def test_plot_refreshing(test_plot_environment):
         assert len(get_plot_directories(env.root_path)) == expected_directories
         await env.refresh_tester.run(expected_result)
         assert len(env.refresh_tester.plot_manager.plots) == expect_total_plots
-        assert len(env.refresh_tester.plot_manager.cache) == expect_total_plots
         assert len(env.refresh_tester.plot_manager.get_duplicates()) == expect_duplicates
         assert len(env.refresh_tester.plot_manager.failed_to_open_filenames) == 0
 
@@ -478,10 +477,13 @@ async def test_plot_info_caching(test_plot_environment, bt):
     assert env.refresh_tester.plot_manager.cache.path().exists()
     refresh_tester: PlotRefreshTester = PlotRefreshTester(env.root_path)
     plot_manager = refresh_tester.plot_manager
+    plot_manager.set_public_keys(bt.plot_manager.farmer_public_keys, bt.plot_manager.pool_public_keys)
     plot_manager.cache.load()
     assert len(plot_manager.cache) == len(env.refresh_tester.plot_manager.cache)
-    for plot_id, cache_entry in env.refresh_tester.plot_manager.cache.items():
-        cache_entry_new = plot_manager.cache.get(plot_id)
+    for path, cache_entry in env.refresh_tester.plot_manager.cache.items():
+        cache_entry_new = plot_manager.cache.get(path)
+        assert bytes(cache_entry_new.prover) == bytes(cache_entry.prover)
+        assert cache_entry_new.farmer_public_key == cache_entry.farmer_public_key
         assert cache_entry_new.pool_public_key == cache_entry.pool_public_key
         assert cache_entry_new.pool_contract_puzzle_hash == cache_entry.pool_contract_puzzle_hash
         assert cache_entry_new.plot_public_key == cache_entry.plot_public_key
@@ -515,6 +517,40 @@ async def test_plot_info_caching(test_plot_environment, bt):
     plot_manager.stop_refreshing()
 
 
+@pytest.mark.asyncio
+async def test_cache_lifetime(test_plot_environment: TestEnvironment) -> None:
+    # Load a directory to produce a cache file
+    env: TestEnvironment = test_plot_environment
+    expected_result = PlotRefreshResult()
+    add_plot_directory(env.root_path, str(env.dir_1.path))
+    expected_result.loaded = env.dir_1.plot_info_list()  # type: ignore[assignment]
+    expected_result.removed = []
+    expected_result.processed = len(env.dir_1)
+    expected_result.remaining = 0
+    await env.refresh_tester.run(expected_result)
+    expected_result.loaded = []
+    cache_v1: Cache = env.refresh_tester.plot_manager.cache
+    assert len(cache_v1) > 0
+    count_before = len(cache_v1)
+    # Remove half of the plots in dir1
+    for path in env.dir_1.path_list()[0 : int(len(env.dir_1) / 2)]:
+        expected_result.processed -= 1
+        expected_result.removed.append(path)
+        unlink(path)
+    # Modify the `last_use` timestamp of all cache entries to let them expire
+    last_use_before = time.time() - Cache.expiry_seconds - 1
+    for cache_entry in cache_v1.values():
+        cache_entry.last_use = last_use_before
+        assert cache_entry.expired(Cache.expiry_seconds)
+    # The next refresh cycle will now lead to half of the cache entries being removed because they are expired and
+    # the related plots do not longer exist.
+    await env.refresh_tester.run(expected_result)
+    assert len(cache_v1) == count_before - len(expected_result.removed)
+    # The other half of the cache entries should have a different `last_use` value now.
+    for cache_entry in cache_v1.values():
+        assert cache_entry.last_use != last_use_before
+
+
 @pytest.mark.parametrize(
     ["event_to_raise"],
     [
-- 
2.34.1


From 79cbadf9873406f23c1b3e586e6401ddf952d3ee Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:09:41 +0200
Subject: [PATCH 07/77] streamable: Enable `isort` + more `mypy` (#10539)

* isort: Fix `streamable.py` and `test_streamable.py`

* mypy: Drop `streamable.py` and `test_streamable.py` form exclusion

And fix all the mypy issues.

* Fix `pylint`

* Introduce `ParseFunctionType` and `StreamFunctionType`

* Use `object` instead of `Type[Any]` for `is_type_*` functions

* Some `Any` -> `object`

* Use `typing.overload` for `recurse_jsonify`

* Move some comments

* Drop `Union`, use `Literal` properly

* Explicitly ignore the return of `f_type.parse`

Co-authored-by: Kyle Altendorf <sda@fstab.net>

* Merge two `recurse_jsonify` overloads

* Typing for the base definition of `recurse_jsonify`

Co-authored-by: Kyle Altendorf <sda@fstab.net>
---
 .isort.cfg                         |   2 -
 chia/util/streamable.py            | 117 +++++++++++------
 mypy.ini                           |   2 +-
 tests/core/util/test_streamable.py | 201 ++++++++++++++++-------------
 4 files changed, 192 insertions(+), 130 deletions(-)

diff --git a/.isort.cfg b/.isort.cfg
index 9ed754a63..c96731587 100644
--- a/.isort.cfg
+++ b/.isort.cfg
@@ -109,7 +109,6 @@ extend_skip=
     chia/util/profiler.py
     chia/util/service_groups.py
     chia/util/ssl_check.py
-    chia/util/streamable.py
     chia/util/ws_message.py
     chia/wallet/cat_wallet/cat_info.py
     chia/wallet/cat_wallet/cat_utils.py
@@ -191,7 +190,6 @@ extend_skip=
     tests/core/util/test_files.py
     tests/core/util/test_keychain.py
     tests/core/util/test_keyring_wrapper.py
-    tests/core/util/test_streamable.py
     tests/generator/test_compression.py
     tests/generator/test_generator_types.py
     tests/generator/test_list_to_batches.py
diff --git a/chia/util/streamable.py b/chia/util/streamable.py
index cf545fd48..fd5fd468e 100644
--- a/chia/util/streamable.py
+++ b/chia/util/streamable.py
@@ -5,7 +5,21 @@ import io
 import pprint
 import sys
 from enum import Enum
-from typing import Any, BinaryIO, Dict, get_type_hints, List, Tuple, Type, TypeVar, Union, Callable, Optional, Iterator
+from typing import (
+    Any,
+    BinaryIO,
+    Callable,
+    Dict,
+    Iterator,
+    List,
+    Optional,
+    Tuple,
+    Type,
+    TypeVar,
+    Union,
+    get_type_hints,
+    overload,
+)
 
 from blspy import G1Element, G2Element, PrivateKey
 from typing_extensions import Literal
@@ -58,29 +72,32 @@ big_ints = [uint64, int64, uint128, int512]
 
 _T_Streamable = TypeVar("_T_Streamable", bound="Streamable")
 
+ParseFunctionType = Callable[[BinaryIO], object]
+StreamFunctionType = Callable[[object, BinaryIO], None]
+
 
 # Caches to store the fields and (de)serialization methods for all available streamable classes.
-FIELDS_FOR_STREAMABLE_CLASS = {}
-STREAM_FUNCTIONS_FOR_STREAMABLE_CLASS = {}
-PARSE_FUNCTIONS_FOR_STREAMABLE_CLASS = {}
+FIELDS_FOR_STREAMABLE_CLASS: Dict[Type[object], Dict[str, Type[object]]] = {}
+STREAM_FUNCTIONS_FOR_STREAMABLE_CLASS: Dict[Type[object], List[StreamFunctionType]] = {}
+PARSE_FUNCTIONS_FOR_STREAMABLE_CLASS: Dict[Type[object], List[ParseFunctionType]] = {}
 
 
-def is_type_List(f_type: Type) -> bool:
+def is_type_List(f_type: object) -> bool:
     return get_origin(f_type) == list or f_type == list
 
 
-def is_type_SpecificOptional(f_type) -> bool:
+def is_type_SpecificOptional(f_type: object) -> bool:
     """
     Returns true for types such as Optional[T], but not Optional, or T.
     """
     return get_origin(f_type) == Union and get_args(f_type)[1]() is None
 
 
-def is_type_Tuple(f_type: Type) -> bool:
+def is_type_Tuple(f_type: object) -> bool:
     return get_origin(f_type) == tuple or f_type == tuple
 
 
-def dataclass_from_dict(klass, d):
+def dataclass_from_dict(klass: Type[Any], d: Any) -> Any:
     """
     Converts a dictionary based on a dataclass, into an instance of that dataclass.
     Recursively goes through lists, optionals, and dictionaries.
@@ -100,7 +117,8 @@ def dataclass_from_dict(klass, d):
         return tuple(klass_properties)
     elif dataclasses.is_dataclass(klass):
         # Type is a dataclass, data is a dictionary
-        fieldtypes = {f.name: f.type for f in dataclasses.fields(klass)}
+        hints = get_type_hints(klass)
+        fieldtypes = {f.name: hints.get(f.name, f.type) for f in dataclasses.fields(klass)}
         return klass(**{f: dataclass_from_dict(fieldtypes[f], d[f]) for f in d})
     elif is_type_List(klass):
         # Type is a list, data is a list
@@ -116,7 +134,17 @@ def dataclass_from_dict(klass, d):
         return klass(d)
 
 
-def recurse_jsonify(d):
+@overload
+def recurse_jsonify(d: Union[List[Any], Tuple[Any, ...]]) -> List[Any]:
+    ...
+
+
+@overload
+def recurse_jsonify(d: Dict[str, Any]) -> Dict[str, Any]:
+    ...
+
+
+def recurse_jsonify(d: Union[List[Any], Tuple[Any, ...], Dict[str, Any]]) -> Union[List[Any], Dict[str, Any]]:
     """
     Makes bytes objects and unhashable types into strings with 0x, and makes large ints into
     strings.
@@ -173,11 +201,11 @@ def parse_uint32(f: BinaryIO, byteorder: Literal["little", "big"] = "big") -> ui
     return uint32(int.from_bytes(size_bytes, byteorder))
 
 
-def write_uint32(f: BinaryIO, value: uint32, byteorder: Literal["little", "big"] = "big"):
+def write_uint32(f: BinaryIO, value: uint32, byteorder: Literal["little", "big"] = "big") -> None:
     f.write(value.to_bytes(4, byteorder))
 
 
-def parse_optional(f: BinaryIO, parse_inner_type_f: Callable[[BinaryIO], Any]) -> Optional[Any]:
+def parse_optional(f: BinaryIO, parse_inner_type_f: ParseFunctionType) -> Optional[object]:
     is_present_bytes = f.read(1)
     assert is_present_bytes is not None and len(is_present_bytes) == 1  # Checks for EOF
     if is_present_bytes == bytes([0]):
@@ -195,8 +223,8 @@ def parse_bytes(f: BinaryIO) -> bytes:
     return bytes_read
 
 
-def parse_list(f: BinaryIO, parse_inner_type_f: Callable[[BinaryIO], Any]) -> List[Any]:
-    full_list: List = []
+def parse_list(f: BinaryIO, parse_inner_type_f: ParseFunctionType) -> List[object]:
+    full_list: List[object] = []
     # wjb assert inner_type != get_args(List)[0]
     list_size = parse_uint32(f)
     for list_index in range(list_size):
@@ -204,14 +232,14 @@ def parse_list(f: BinaryIO, parse_inner_type_f: Callable[[BinaryIO], Any]) -> Li
     return full_list
 
 
-def parse_tuple(f: BinaryIO, list_parse_inner_type_f: List[Callable[[BinaryIO], Any]]) -> Tuple[Any, ...]:
-    full_list = []
+def parse_tuple(f: BinaryIO, list_parse_inner_type_f: List[ParseFunctionType]) -> Tuple[object, ...]:
+    full_list: List[object] = []
     for parse_f in list_parse_inner_type_f:
         full_list.append(parse_f(f))
     return tuple(full_list)
 
 
-def parse_size_hints(f: BinaryIO, f_type: Type, bytes_to_read: int) -> Any:
+def parse_size_hints(f: BinaryIO, f_type: Type[Any], bytes_to_read: int) -> Any:
     bytes_read = f.read(bytes_to_read)
     assert bytes_read is not None and len(bytes_read) == bytes_to_read
     return f_type.from_bytes(bytes_read)
@@ -224,7 +252,7 @@ def parse_str(f: BinaryIO) -> str:
     return bytes.decode(str_read_bytes, "utf-8")
 
 
-def stream_optional(stream_inner_type_func: Callable[[Any, BinaryIO], None], item: Any, f: BinaryIO) -> None:
+def stream_optional(stream_inner_type_func: StreamFunctionType, item: Any, f: BinaryIO) -> None:
     if item is None:
         f.write(bytes([0]))
     else:
@@ -237,13 +265,13 @@ def stream_bytes(item: Any, f: BinaryIO) -> None:
     f.write(item)
 
 
-def stream_list(stream_inner_type_func: Callable[[Any, BinaryIO], None], item: Any, f: BinaryIO) -> None:
+def stream_list(stream_inner_type_func: StreamFunctionType, item: Any, f: BinaryIO) -> None:
     write_uint32(f, uint32(len(item)))
     for element in item:
         stream_inner_type_func(element, f)
 
 
-def stream_tuple(stream_inner_type_funcs: List[Callable[[Any, BinaryIO], None]], item: Any, f: BinaryIO) -> None:
+def stream_tuple(stream_inner_type_funcs: List[StreamFunctionType], item: Any, f: BinaryIO) -> None:
     assert len(stream_inner_type_funcs) == len(item)
     for i in range(len(item)):
         stream_inner_type_funcs[i](item[i], f)
@@ -255,7 +283,19 @@ def stream_str(item: Any, f: BinaryIO) -> None:
     f.write(str_bytes)
 
 
-def streamable(cls: Any):
+def stream_bool(item: Any, f: BinaryIO) -> None:
+    f.write(int(item).to_bytes(1, "big"))
+
+
+def stream_streamable(item: object, f: BinaryIO) -> None:
+    getattr(item, "stream")(f)
+
+
+def stream_byte_convertible(item: object, f: BinaryIO) -> None:
+    f.write(getattr(item, "__bytes__")())
+
+
+def streamable(cls: Type[_T_Streamable]) -> Type[_T_Streamable]:
     """
     This decorator forces correct streamable protocol syntax/usage and populates the caches for types hints and
     (de)serialization methods for all members of the class. The correct usage is:
@@ -279,7 +319,9 @@ def streamable(cls: Any):
         raise DefinitionError(f"@dataclass(frozen=True) required first. {correct_usage_string}")
 
     try:
-        object.__new__(cls)._streamable_test_if_dataclass_frozen_ = None
+        # Ignore mypy here because we especially want to access a not available member to test if
+        # the dataclass is frozen.
+        object.__new__(cls)._streamable_test_if_dataclass_frozen_ = None  # type: ignore[attr-defined]
     except dataclasses.FrozenInstanceError:
         pass
     else:
@@ -352,10 +394,10 @@ class Streamable:
     Make sure to use the streamable decorator when inheriting from the Streamable class to prepare the streaming caches.
     """
 
-    def post_init_parse(self, item: Any, f_name: str, f_type: Type) -> Any:
+    def post_init_parse(self, item: Any, f_name: str, f_type: Type[Any]) -> Any:
         if is_type_List(f_type):
-            collected_list: List = []
-            inner_type: Type = get_args(f_type)[0]
+            collected_list: List[Any] = []
+            inner_type: Type[Any] = get_args(f_type)[0]
             # wjb assert inner_type != get_args(List)[0]  # type: ignore
             if not is_type_List(type(item)):
                 raise ValueError(f"Wrong type for {f_name}, need a list.")
@@ -391,7 +433,7 @@ class Streamable:
             raise ValueError(f"Wrong type for {f_name}")
         return item
 
-    def __post_init__(self):
+    def __post_init__(self) -> None:
         try:
             fields = FIELDS_FOR_STREAMABLE_CLASS[type(self)]
         except Exception:
@@ -408,12 +450,12 @@ class Streamable:
                 object.__setattr__(self, f_name, self.post_init_parse(data[f_name], f_name, f_type))
 
     @classmethod
-    def function_to_parse_one_item(cls, f_type: Type) -> Callable[[BinaryIO], Any]:
+    def function_to_parse_one_item(cls, f_type: Type[Any]) -> ParseFunctionType:
         """
         This function returns a function taking one argument `f: BinaryIO` that parses
         and returns a value of the given type.
         """
-        inner_type: Type
+        inner_type: Type[Any]
         if f_type is bool:
             return parse_bool
         if is_type_SpecificOptional(f_type):
@@ -421,7 +463,8 @@ class Streamable:
             parse_inner_type_f = cls.function_to_parse_one_item(inner_type)
             return lambda f: parse_optional(f, parse_inner_type_f)
         if hasattr(f_type, "parse"):
-            return f_type.parse
+            # Ignoring for now as the proper solution isn't obvious
+            return f_type.parse  # type: ignore[no-any-return]
         if f_type == bytes:
             return parse_bytes
         if is_type_List(f_type):
@@ -444,7 +487,7 @@ class Streamable:
         # Create the object without calling __init__() to avoid unnecessary post-init checks in strictdataclass
         obj: _T_Streamable = object.__new__(cls)
         fields: Iterator[str] = iter(FIELDS_FOR_STREAMABLE_CLASS.get(cls, {}))
-        values: Iterator = (parse_f(f) for parse_f in PARSE_FUNCTIONS_FOR_STREAMABLE_CLASS[cls])
+        values: Iterator[object] = (parse_f(f) for parse_f in PARSE_FUNCTIONS_FOR_STREAMABLE_CLASS[cls])
         for field, value in zip(fields, values):
             object.__setattr__(obj, field, value)
 
@@ -456,8 +499,8 @@ class Streamable:
         return obj
 
     @classmethod
-    def function_to_stream_one_item(cls, f_type: Type) -> Callable[[Any, BinaryIO], Any]:
-        inner_type: Type
+    def function_to_stream_one_item(cls, f_type: Type[Any]) -> StreamFunctionType:
+        inner_type: Type[Any]
         if is_type_SpecificOptional(f_type):
             inner_type = get_args(f_type)[0]
             stream_inner_type_func = cls.function_to_stream_one_item(inner_type)
@@ -465,9 +508,9 @@ class Streamable:
         elif f_type == bytes:
             return stream_bytes
         elif hasattr(f_type, "stream"):
-            return lambda item, f: item.stream(f)
+            return stream_streamable
         elif hasattr(f_type, "__bytes__"):
-            return lambda item, f: f.write(bytes(item))
+            return stream_byte_convertible
         elif is_type_List(f_type):
             inner_type = get_args(f_type)[0]
             stream_inner_type_func = cls.function_to_stream_one_item(inner_type)
@@ -481,7 +524,7 @@ class Streamable:
         elif f_type is str:
             return stream_str
         elif f_type is bool:
-            return lambda item, f: f.write(int(item).to_bytes(1, "big"))
+            return stream_bool
         else:
             raise NotImplementedError(f"can't stream {f_type}")
 
@@ -518,9 +561,9 @@ class Streamable:
     def __repr__(self: Any) -> str:
         return pp.pformat(recurse_jsonify(dataclasses.asdict(self)))
 
-    def to_json_dict(self) -> Dict:
+    def to_json_dict(self) -> Dict[str, Any]:
         return recurse_jsonify(dataclasses.asdict(self))
 
     @classmethod
-    def from_json_dict(cls: Any, json_dict: Dict) -> Any:
+    def from_json_dict(cls: Any, json_dict: Dict[str, Any]) -> Any:
         return dataclass_from_dict(cls, json_dict)
diff --git a/mypy.ini b/mypy.ini
index 4c3f96cbf..795d940d3 100644
--- a/mypy.ini
+++ b/mypy.ini
@@ -17,7 +17,7 @@ no_implicit_reexport = True
 strict_equality = True
 
 # list created by: venv/bin/mypy | sed -n 's/.py:.*//p' | sort | uniq | tr '/' '.' | tr '\n' ','
-[mypy-benchmarks.block_ref,benchmarks.block_store,benchmarks.coin_store,benchmarks.utils,build_scripts.installer-version,chia.clvm.spend_sim,chia.cmds.configure,chia.cmds.db,chia.cmds.db_upgrade_func,chia.cmds.farm_funcs,chia.cmds.init,chia.cmds.init_funcs,chia.cmds.keys,chia.cmds.keys_funcs,chia.cmds.passphrase,chia.cmds.passphrase_funcs,chia.cmds.plotnft,chia.cmds.plotnft_funcs,chia.cmds.plots,chia.cmds.plotters,chia.cmds.show,chia.cmds.start_funcs,chia.cmds.wallet,chia.cmds.wallet_funcs,chia.consensus.block_body_validation,chia.consensus.blockchain,chia.consensus.blockchain_interface,chia.consensus.block_creation,chia.consensus.block_header_validation,chia.consensus.block_record,chia.consensus.block_root_validation,chia.consensus.coinbase,chia.consensus.constants,chia.consensus.difficulty_adjustment,chia.consensus.get_block_challenge,chia.consensus.multiprocess_validation,chia.consensus.pos_quality,chia.consensus.vdf_info_computation,chia.daemon.client,chia.daemon.keychain_proxy,chia.daemon.keychain_server,chia.daemon.server,chia.farmer.farmer,chia.farmer.farmer_api,chia.full_node.block_height_map,chia.full_node.block_store,chia.full_node.bundle_tools,chia.full_node.coin_store,chia.full_node.full_node,chia.full_node.full_node_api,chia.full_node.full_node_store,chia.full_node.generator,chia.full_node.hint_store,chia.full_node.lock_queue,chia.full_node.mempool,chia.full_node.mempool_check_conditions,chia.full_node.mempool_manager,chia.full_node.pending_tx_cache,chia.full_node.sync_store,chia.full_node.weight_proof,chia.harvester.harvester,chia.harvester.harvester_api,chia.introducer.introducer,chia.introducer.introducer_api,chia.plotters.bladebit,chia.plotters.chiapos,chia.plotters.install_plotter,chia.plotters.madmax,chia.plotters.plotters,chia.plotters.plotters_util,chia.plotting.check_plots,chia.plotting.create_plots,chia.plotting.manager,chia.plotting.util,chia.pools.pool_config,chia.pools.pool_puzzles,chia.pools.pool_wallet,chia.pools.pool_wallet_info,chia.protocols.pool_protocol,chia.rpc.crawler_rpc_api,chia.rpc.farmer_rpc_api,chia.rpc.farmer_rpc_client,chia.rpc.full_node_rpc_api,chia.rpc.full_node_rpc_client,chia.rpc.harvester_rpc_api,chia.rpc.harvester_rpc_client,chia.rpc.rpc_client,chia.rpc.rpc_server,chia.rpc.timelord_rpc_api,chia.rpc.util,chia.rpc.wallet_rpc_api,chia.rpc.wallet_rpc_client,chia.seeder.crawler,chia.seeder.crawler_api,chia.seeder.crawl_store,chia.seeder.dns_server,chia.seeder.peer_record,chia.seeder.start_crawler,chia.server.address_manager,chia.server.address_manager_store,chia.server.connection_utils,chia.server.introducer_peers,chia.server.node_discovery,chia.server.peer_store_resolver,chia.server.rate_limits,chia.server.reconnect_task,chia.server.server,chia.server.ssl_context,chia.server.start_farmer,chia.server.start_full_node,chia.server.start_harvester,chia.server.start_introducer,chia.server.start_service,chia.server.start_timelord,chia.server.start_wallet,chia.server.upnp,chia.server.ws_connection,chia.simulator.full_node_simulator,chia.simulator.start_simulator,chia.ssl.create_ssl,chia.timelord.iters_from_block,chia.timelord.timelord,chia.timelord.timelord_api,chia.timelord.timelord_launcher,chia.timelord.timelord_state,chia.types.announcement,chia.types.blockchain_format.classgroup,chia.types.blockchain_format.coin,chia.types.blockchain_format.program,chia.types.blockchain_format.proof_of_space,chia.types.blockchain_format.tree_hash,chia.types.blockchain_format.vdf,chia.types.full_block,chia.types.header_block,chia.types.mempool_item,chia.types.name_puzzle_condition,chia.types.peer_info,chia.types.spend_bundle,chia.types.transaction_queue_entry,chia.types.unfinished_block,chia.types.unfinished_header_block,chia.util.api_decorators,chia.util.block_cache,chia.util.byte_types,chia.util.cached_bls,chia.util.check_fork_next_block,chia.util.chia_logging,chia.util.config,chia.util.db_wrapper,chia.util.dump_keyring,chia.util.file_keyring,chia.util.files,chia.util.hash,chia.util.ints,chia.util.json_util,chia.util.keychain,chia.util.keyring_wrapper,chia.util.log_exceptions,chia.util.lru_cache,chia.util.make_test_constants,chia.util.merkle_set,chia.util.network,chia.util.partial_func,chia.util.pip_import,chia.util.profiler,chia.util.safe_cancel_task,chia.util.service_groups,chia.util.ssl_check,chia.util.streamable,chia.util.struct_stream,chia.util.validate_alert,chia.wallet.block_record,chia.wallet.cat_wallet.cat_utils,chia.wallet.cat_wallet.cat_wallet,chia.wallet.cat_wallet.lineage_store,chia.wallet.chialisp,chia.wallet.did_wallet.did_wallet,chia.wallet.did_wallet.did_wallet_puzzles,chia.wallet.key_val_store,chia.wallet.lineage_proof,chia.wallet.payment,chia.wallet.puzzles.load_clvm,chia.wallet.puzzles.p2_conditions,chia.wallet.puzzles.p2_delegated_conditions,chia.wallet.puzzles.p2_delegated_puzzle,chia.wallet.puzzles.p2_delegated_puzzle_or_hidden_puzzle,chia.wallet.puzzles.p2_m_of_n_delegate_direct,chia.wallet.puzzles.p2_puzzle_hash,chia.wallet.puzzles.prefarm.spend_prefarm,chia.wallet.puzzles.puzzle_utils,chia.wallet.puzzles.rom_bootstrap_generator,chia.wallet.puzzles.singleton_top_layer,chia.wallet.puzzles.tails,chia.wallet.rl_wallet.rl_wallet,chia.wallet.rl_wallet.rl_wallet_puzzles,chia.wallet.secret_key_store,chia.wallet.settings.user_settings,chia.wallet.trade_manager,chia.wallet.trade_record,chia.wallet.trading.offer,chia.wallet.trading.trade_store,chia.wallet.transaction_record,chia.wallet.util.debug_spend_bundle,chia.wallet.util.new_peak_queue,chia.wallet.util.peer_request_cache,chia.wallet.util.wallet_sync_utils,chia.wallet.wallet,chia.wallet.wallet_action_store,chia.wallet.wallet_blockchain,chia.wallet.wallet_coin_store,chia.wallet.wallet_interested_store,chia.wallet.wallet_node,chia.wallet.wallet_node_api,chia.wallet.wallet_pool_store,chia.wallet.wallet_puzzle_store,chia.wallet.wallet_state_manager,chia.wallet.wallet_sync_store,chia.wallet.wallet_transaction_store,chia.wallet.wallet_user_store,chia.wallet.wallet_weight_proof_handler,installhelper,tests.blockchain.blockchain_test_utils,tests.blockchain.test_blockchain,tests.blockchain.test_blockchain_transactions,tests.block_tools,tests.build-init-files,tests.build-workflows,tests.clvm.coin_store,tests.clvm.test_chialisp_deserialization,tests.clvm.test_clvm_compilation,tests.clvm.test_program,tests.clvm.test_puzzle_compression,tests.clvm.test_puzzles,tests.clvm.test_serialized_program,tests.clvm.test_singletons,tests.clvm.test_spend_sim,tests.conftest,tests.connection_utils,tests.core.cmds.test_keys,tests.core.consensus.test_pot_iterations,tests.core.custom_types.test_coin,tests.core.custom_types.test_proof_of_space,tests.core.custom_types.test_spend_bundle,tests.core.daemon.test_daemon,tests.core.full_node.full_sync.test_full_sync,tests.core.full_node.stores.test_block_store,tests.core.full_node.stores.test_coin_store,tests.core.full_node.stores.test_full_node_store,tests.core.full_node.stores.test_hint_store,tests.core.full_node.stores.test_sync_store,tests.core.full_node.test_address_manager,tests.core.full_node.test_block_height_map,tests.core.full_node.test_conditions,tests.core.full_node.test_full_node,tests.core.full_node.test_mempool,tests.core.full_node.test_mempool_performance,tests.core.full_node.test_node_load,tests.core.full_node.test_peer_store_resolver,tests.core.full_node.test_performance,tests.core.full_node.test_transactions,tests.core.make_block_generator,tests.core.node_height,tests.core.server.test_dos,tests.core.server.test_rate_limits,tests.core.ssl.test_ssl,tests.core.test_cost_calculation,tests.core.test_crawler_rpc,tests.core.test_daemon_rpc,tests.core.test_db_conversion,tests.core.test_farmer_harvester_rpc,tests.core.test_filter,tests.core.test_full_node_rpc,tests.core.test_merkle_set,tests.core.test_setproctitle,tests.core.util.test_cached_bls,tests.core.util.test_config,tests.core.util.test_file_keyring_synchronization,tests.core.util.test_files,tests.core.util.test_keychain,tests.core.util.test_keyring_wrapper,tests.core.util.test_lru_cache,tests.core.util.test_significant_bits,tests.core.util.test_streamable,tests.farmer_harvester.test_farmer_harvester,tests.generator.test_compression,tests.generator.test_generator_types,tests.generator.test_list_to_batches,tests.generator.test_rom,tests.generator.test_scan,tests.plotting.test_plot_manager,tests.pools.test_pool_cmdline,tests.pools.test_pool_config,tests.pools.test_pool_puzzles_lifecycle,tests.pools.test_pool_rpc,tests.pools.test_wallet_pool_store,tests.setup_nodes,tests.setup_services,tests.simulation.test_simulation,tests.time_out_assert,tests.tools.test_full_sync,tests.tools.test_run_block,tests.util.alert_server,tests.util.benchmark_cost,tests.util.blockchain,tests.util.build_network_protocol_files,tests.util.db_connection,tests.util.generator_tools_testing,tests.util.keyring,tests.util.key_tool,tests.util.misc,tests.util.network,tests.util.rpc,tests.util.test_full_block_utils,tests.util.test_lock_queue,tests.util.test_network_protocol_files,tests.util.test_struct_stream,tests.wallet.cat_wallet.test_cat_lifecycle,tests.wallet.cat_wallet.test_cat_wallet,tests.wallet.cat_wallet.test_offer_lifecycle,tests.wallet.cat_wallet.test_trades,tests.wallet.did_wallet.test_did,tests.wallet.did_wallet.test_did_rpc,tests.wallet.rl_wallet.test_rl_rpc,tests.wallet.rl_wallet.test_rl_wallet,tests.wallet.rpc.test_wallet_rpc,tests.wallet.simple_sync.test_simple_sync_protocol,tests.wallet.sync.test_wallet_sync,tests.wallet.test_bech32m,tests.wallet.test_chialisp,tests.wallet.test_puzzle_store,tests.wallet.test_singleton,tests.wallet.test_singleton_lifecycle,tests.wallet.test_singleton_lifecycle_fast,tests.wallet.test_taproot,tests.wallet.test_wallet,tests.wallet.test_wallet_blockchain,tests.wallet.test_wallet_interested_store,tests.wallet.test_wallet_key_val_store,tests.wallet.test_wallet_user_store,tests.wallet_tools,tests.weight_proof.test_weight_proof,tools.analyze-chain,tools.run_block,tools.test_full_sync]
+[mypy-benchmarks.block_ref,benchmarks.block_store,benchmarks.coin_store,benchmarks.utils,build_scripts.installer-version,chia.clvm.spend_sim,chia.cmds.configure,chia.cmds.db,chia.cmds.db_upgrade_func,chia.cmds.farm_funcs,chia.cmds.init,chia.cmds.init_funcs,chia.cmds.keys,chia.cmds.keys_funcs,chia.cmds.passphrase,chia.cmds.passphrase_funcs,chia.cmds.plotnft,chia.cmds.plotnft_funcs,chia.cmds.plots,chia.cmds.plotters,chia.cmds.show,chia.cmds.start_funcs,chia.cmds.wallet,chia.cmds.wallet_funcs,chia.consensus.block_body_validation,chia.consensus.blockchain,chia.consensus.blockchain_interface,chia.consensus.block_creation,chia.consensus.block_header_validation,chia.consensus.block_record,chia.consensus.block_root_validation,chia.consensus.coinbase,chia.consensus.constants,chia.consensus.difficulty_adjustment,chia.consensus.get_block_challenge,chia.consensus.multiprocess_validation,chia.consensus.pos_quality,chia.consensus.vdf_info_computation,chia.daemon.client,chia.daemon.keychain_proxy,chia.daemon.keychain_server,chia.daemon.server,chia.farmer.farmer,chia.farmer.farmer_api,chia.full_node.block_height_map,chia.full_node.block_store,chia.full_node.bundle_tools,chia.full_node.coin_store,chia.full_node.full_node,chia.full_node.full_node_api,chia.full_node.full_node_store,chia.full_node.generator,chia.full_node.hint_store,chia.full_node.lock_queue,chia.full_node.mempool,chia.full_node.mempool_check_conditions,chia.full_node.mempool_manager,chia.full_node.pending_tx_cache,chia.full_node.sync_store,chia.full_node.weight_proof,chia.harvester.harvester,chia.harvester.harvester_api,chia.introducer.introducer,chia.introducer.introducer_api,chia.plotters.bladebit,chia.plotters.chiapos,chia.plotters.install_plotter,chia.plotters.madmax,chia.plotters.plotters,chia.plotters.plotters_util,chia.plotting.check_plots,chia.plotting.create_plots,chia.plotting.manager,chia.plotting.util,chia.pools.pool_config,chia.pools.pool_puzzles,chia.pools.pool_wallet,chia.pools.pool_wallet_info,chia.protocols.pool_protocol,chia.rpc.crawler_rpc_api,chia.rpc.farmer_rpc_api,chia.rpc.farmer_rpc_client,chia.rpc.full_node_rpc_api,chia.rpc.full_node_rpc_client,chia.rpc.harvester_rpc_api,chia.rpc.harvester_rpc_client,chia.rpc.rpc_client,chia.rpc.rpc_server,chia.rpc.timelord_rpc_api,chia.rpc.util,chia.rpc.wallet_rpc_api,chia.rpc.wallet_rpc_client,chia.seeder.crawler,chia.seeder.crawler_api,chia.seeder.crawl_store,chia.seeder.dns_server,chia.seeder.peer_record,chia.seeder.start_crawler,chia.server.address_manager,chia.server.address_manager_store,chia.server.connection_utils,chia.server.introducer_peers,chia.server.node_discovery,chia.server.peer_store_resolver,chia.server.rate_limits,chia.server.reconnect_task,chia.server.server,chia.server.ssl_context,chia.server.start_farmer,chia.server.start_full_node,chia.server.start_harvester,chia.server.start_introducer,chia.server.start_service,chia.server.start_timelord,chia.server.start_wallet,chia.server.upnp,chia.server.ws_connection,chia.simulator.full_node_simulator,chia.simulator.start_simulator,chia.ssl.create_ssl,chia.timelord.iters_from_block,chia.timelord.timelord,chia.timelord.timelord_api,chia.timelord.timelord_launcher,chia.timelord.timelord_state,chia.types.announcement,chia.types.blockchain_format.classgroup,chia.types.blockchain_format.coin,chia.types.blockchain_format.program,chia.types.blockchain_format.proof_of_space,chia.types.blockchain_format.tree_hash,chia.types.blockchain_format.vdf,chia.types.full_block,chia.types.header_block,chia.types.mempool_item,chia.types.name_puzzle_condition,chia.types.peer_info,chia.types.spend_bundle,chia.types.transaction_queue_entry,chia.types.unfinished_block,chia.types.unfinished_header_block,chia.util.api_decorators,chia.util.block_cache,chia.util.byte_types,chia.util.cached_bls,chia.util.check_fork_next_block,chia.util.chia_logging,chia.util.config,chia.util.db_wrapper,chia.util.dump_keyring,chia.util.file_keyring,chia.util.files,chia.util.hash,chia.util.ints,chia.util.json_util,chia.util.keychain,chia.util.keyring_wrapper,chia.util.log_exceptions,chia.util.lru_cache,chia.util.make_test_constants,chia.util.merkle_set,chia.util.network,chia.util.partial_func,chia.util.pip_import,chia.util.profiler,chia.util.safe_cancel_task,chia.util.service_groups,chia.util.ssl_check,chia.util.struct_stream,chia.util.validate_alert,chia.wallet.block_record,chia.wallet.cat_wallet.cat_utils,chia.wallet.cat_wallet.cat_wallet,chia.wallet.cat_wallet.lineage_store,chia.wallet.chialisp,chia.wallet.did_wallet.did_wallet,chia.wallet.did_wallet.did_wallet_puzzles,chia.wallet.key_val_store,chia.wallet.lineage_proof,chia.wallet.payment,chia.wallet.puzzles.load_clvm,chia.wallet.puzzles.p2_conditions,chia.wallet.puzzles.p2_delegated_conditions,chia.wallet.puzzles.p2_delegated_puzzle,chia.wallet.puzzles.p2_delegated_puzzle_or_hidden_puzzle,chia.wallet.puzzles.p2_m_of_n_delegate_direct,chia.wallet.puzzles.p2_puzzle_hash,chia.wallet.puzzles.prefarm.spend_prefarm,chia.wallet.puzzles.puzzle_utils,chia.wallet.puzzles.rom_bootstrap_generator,chia.wallet.puzzles.singleton_top_layer,chia.wallet.puzzles.tails,chia.wallet.rl_wallet.rl_wallet,chia.wallet.rl_wallet.rl_wallet_puzzles,chia.wallet.secret_key_store,chia.wallet.settings.user_settings,chia.wallet.trade_manager,chia.wallet.trade_record,chia.wallet.trading.offer,chia.wallet.trading.trade_store,chia.wallet.transaction_record,chia.wallet.util.debug_spend_bundle,chia.wallet.util.new_peak_queue,chia.wallet.util.peer_request_cache,chia.wallet.util.wallet_sync_utils,chia.wallet.wallet,chia.wallet.wallet_action_store,chia.wallet.wallet_blockchain,chia.wallet.wallet_coin_store,chia.wallet.wallet_interested_store,chia.wallet.wallet_node,chia.wallet.wallet_node_api,chia.wallet.wallet_pool_store,chia.wallet.wallet_puzzle_store,chia.wallet.wallet_state_manager,chia.wallet.wallet_sync_store,chia.wallet.wallet_transaction_store,chia.wallet.wallet_user_store,chia.wallet.wallet_weight_proof_handler,installhelper,tests.blockchain.blockchain_test_utils,tests.blockchain.test_blockchain,tests.blockchain.test_blockchain_transactions,tests.block_tools,tests.build-init-files,tests.build-workflows,tests.clvm.coin_store,tests.clvm.test_chialisp_deserialization,tests.clvm.test_clvm_compilation,tests.clvm.test_program,tests.clvm.test_puzzle_compression,tests.clvm.test_puzzles,tests.clvm.test_serialized_program,tests.clvm.test_singletons,tests.clvm.test_spend_sim,tests.conftest,tests.connection_utils,tests.core.cmds.test_keys,tests.core.consensus.test_pot_iterations,tests.core.custom_types.test_coin,tests.core.custom_types.test_proof_of_space,tests.core.custom_types.test_spend_bundle,tests.core.daemon.test_daemon,tests.core.full_node.full_sync.test_full_sync,tests.core.full_node.stores.test_block_store,tests.core.full_node.stores.test_coin_store,tests.core.full_node.stores.test_full_node_store,tests.core.full_node.stores.test_hint_store,tests.core.full_node.stores.test_sync_store,tests.core.full_node.test_address_manager,tests.core.full_node.test_block_height_map,tests.core.full_node.test_conditions,tests.core.full_node.test_full_node,tests.core.full_node.test_mempool,tests.core.full_node.test_mempool_performance,tests.core.full_node.test_node_load,tests.core.full_node.test_peer_store_resolver,tests.core.full_node.test_performance,tests.core.full_node.test_transactions,tests.core.make_block_generator,tests.core.node_height,tests.core.server.test_dos,tests.core.server.test_rate_limits,tests.core.ssl.test_ssl,tests.core.test_cost_calculation,tests.core.test_crawler_rpc,tests.core.test_daemon_rpc,tests.core.test_db_conversion,tests.core.test_farmer_harvester_rpc,tests.core.test_filter,tests.core.test_full_node_rpc,tests.core.test_merkle_set,tests.core.test_setproctitle,tests.core.util.test_cached_bls,tests.core.util.test_config,tests.core.util.test_file_keyring_synchronization,tests.core.util.test_files,tests.core.util.test_keychain,tests.core.util.test_keyring_wrapper,tests.core.util.test_lru_cache,tests.core.util.test_significant_bits,tests.farmer_harvester.test_farmer_harvester,tests.generator.test_compression,tests.generator.test_generator_types,tests.generator.test_list_to_batches,tests.generator.test_rom,tests.generator.test_scan,tests.plotting.test_plot_manager,tests.pools.test_pool_cmdline,tests.pools.test_pool_config,tests.pools.test_pool_puzzles_lifecycle,tests.pools.test_pool_rpc,tests.pools.test_wallet_pool_store,tests.setup_nodes,tests.setup_services,tests.simulation.test_simulation,tests.time_out_assert,tests.tools.test_full_sync,tests.tools.test_run_block,tests.util.alert_server,tests.util.benchmark_cost,tests.util.blockchain,tests.util.build_network_protocol_files,tests.util.db_connection,tests.util.generator_tools_testing,tests.util.keyring,tests.util.key_tool,tests.util.misc,tests.util.network,tests.util.rpc,tests.util.test_full_block_utils,tests.util.test_lock_queue,tests.util.test_network_protocol_files,tests.util.test_struct_stream,tests.wallet.cat_wallet.test_cat_lifecycle,tests.wallet.cat_wallet.test_cat_wallet,tests.wallet.cat_wallet.test_offer_lifecycle,tests.wallet.cat_wallet.test_trades,tests.wallet.did_wallet.test_did,tests.wallet.did_wallet.test_did_rpc,tests.wallet.rl_wallet.test_rl_rpc,tests.wallet.rl_wallet.test_rl_wallet,tests.wallet.rpc.test_wallet_rpc,tests.wallet.simple_sync.test_simple_sync_protocol,tests.wallet.sync.test_wallet_sync,tests.wallet.test_bech32m,tests.wallet.test_chialisp,tests.wallet.test_puzzle_store,tests.wallet.test_singleton,tests.wallet.test_singleton_lifecycle,tests.wallet.test_singleton_lifecycle_fast,tests.wallet.test_taproot,tests.wallet.test_wallet,tests.wallet.test_wallet_blockchain,tests.wallet.test_wallet_interested_store,tests.wallet.test_wallet_key_val_store,tests.wallet.test_wallet_user_store,tests.wallet_tools,tests.weight_proof.test_weight_proof,tools.analyze-chain,tools.run_block,tools.test_full_sync]
 disallow_any_generics = False
 disallow_subclassing_any = False
 disallow_untyped_calls = False
diff --git a/tests/core/util/test_streamable.py b/tests/core/util/test_streamable.py
index 65b325521..28b0a3ba6 100644
--- a/tests/core/util/test_streamable.py
+++ b/tests/core/util/test_streamable.py
@@ -1,10 +1,13 @@
+from __future__ import annotations
+
+import io
 from dataclasses import dataclass
 from typing import Dict, List, Optional, Tuple
-import io
-import pytest
 
+import pytest
 from clvm_tools import binutils
 from pytest import raises
+from typing_extensions import Literal
 
 from chia.protocols.wallet_protocol import RespondRemovals
 from chia.types.blockchain_format.coin import Coin
@@ -16,19 +19,20 @@ from chia.util.ints import uint8, uint32, uint64
 from chia.util.streamable import (
     DefinitionError,
     Streamable,
-    streamable,
+    is_type_List,
+    is_type_SpecificOptional,
     parse_bool,
-    parse_uint32,
-    write_uint32,
-    parse_optional,
     parse_bytes,
     parse_list,
-    parse_tuple,
+    parse_optional,
     parse_size_hints,
     parse_str,
-    is_type_List,
-    is_type_SpecificOptional,
+    parse_tuple,
+    parse_uint32,
+    streamable,
+    write_uint32,
 )
+from tests.block_tools import BlockTools
 from tests.setup_nodes import test_constants
 
 
@@ -59,22 +63,26 @@ def test_dict_not_suppported() -> None:
             a: Dict[str, str]
 
 
+@dataclass(frozen=True)
+class DataclassOnly:
+    a: uint8
+
+
 def test_pure_dataclass_not_supported() -> None:
-    @dataclass(frozen=True)
-    class DataClassOnly:
-        a: uint8
 
     with raises(NotImplementedError):
 
         @streamable
         @dataclass(frozen=True)
         class TestClassDataclass(Streamable):
-            a: DataClassOnly
+            a: DataclassOnly
+
+
+class PlainClass:
+    a: uint8
 
 
 def test_plain_class_not_supported() -> None:
-    class PlainClass:
-        a: uint8
 
     with raises(NotImplementedError):
 
@@ -84,74 +92,81 @@ def test_plain_class_not_supported() -> None:
             a: PlainClass
 
 
-def test_basic_list():
+def test_basic_list() -> None:
     a = [1, 2, 3]
     assert is_type_List(type(a))
     assert is_type_List(List)
     assert is_type_List(List[int])
     assert is_type_List(List[uint8])
     assert is_type_List(list)
-    assert not is_type_List(Tuple)
+    assert not is_type_List(type(Tuple))
     assert not is_type_List(tuple)
     assert not is_type_List(dict)
 
 
-def test_not_lists():
+def test_not_lists() -> None:
     assert not is_type_List(Dict)
 
 
-def test_basic_optional():
+def test_basic_optional() -> None:
     assert is_type_SpecificOptional(Optional[int])
     assert is_type_SpecificOptional(Optional[Optional[int]])
     assert not is_type_SpecificOptional(List[int])
 
 
-def test_StrictDataClass():
+def test_StrictDataClass() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClass1(Streamable):
         a: uint8
         b: str
 
-    good: TestClass1 = TestClass1(24, "!@12")
+    # we want to test invalid here, hence the ignore.
+    good: TestClass1 = TestClass1(24, "!@12")  # type: ignore[arg-type]
     assert TestClass1.__name__ == "TestClass1"
     assert good
     assert good.a == 24
     assert good.b == "!@12"
-    good2 = TestClass1(52, bytes([1, 2, 3]))
+    # we want to test invalid here, hence the ignore.
+    good2 = TestClass1(52, bytes([1, 2, 3]))  # type: ignore[arg-type]
     assert good2.b == str(bytes([1, 2, 3]))
 
 
-def test_StrictDataClassBad():
+def test_StrictDataClassBad() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClass2(Streamable):
         a: uint8
         b = 0
 
-    assert TestClass2(25)
+    # we want to test invalid here, hence the ignore.
+    assert TestClass2(25)  # type: ignore[arg-type]
 
+    # we want to test invalid here, hence the ignore.
     with raises(TypeError):
-        TestClass2(1, 2)  # pylint: disable=too-many-function-args
+        TestClass2(1, 2)  # type: ignore[call-arg,arg-type] # pylint: disable=too-many-function-args
 
 
-def test_StrictDataClassLists():
+def test_StrictDataClassLists() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClass(Streamable):
         a: List[uint8]
         b: List[List[uint8]]
 
-    assert TestClass([1, 2, 3], [[uint8(200), uint8(25)], [uint8(25)]])
+    # we want to test invalid here, hence the ignore.
+    assert TestClass([1, 2, 3], [[uint8(200), uint8(25)], [uint8(25)]])  # type: ignore[list-item]
 
+    # we want to test invalid here, hence the ignore.
     with raises(ValueError):
-        TestClass({"1": 1}, [[uint8(200), uint8(25)], [uint8(25)]])
+        TestClass({"1": 1}, [[uint8(200), uint8(25)], [uint8(25)]])  # type: ignore[arg-type]
 
+    # we want to test invalid here, hence the ignore.
     with raises(ValueError):
-        TestClass([1, 2, 3], [uint8(200), uint8(25)])
+        TestClass([1, 2, 3], [uint8(200), uint8(25)])  # type: ignore[list-item]
 
 
-def test_StrictDataClassOptional():
+def test_StrictDataClassOptional() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClass(Streamable):
@@ -160,11 +175,12 @@ def test_StrictDataClassOptional():
         c: Optional[Optional[uint8]]
         d: Optional[Optional[uint8]]
 
-    good = TestClass(12, None, 13, None)
+    # we want to test invalid here, hence the ignore.
+    good = TestClass(12, None, 13, None)  # type: ignore[arg-type]
     assert good
 
 
-def test_basic():
+def test_basic() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClass(Streamable):
@@ -176,13 +192,14 @@ def test_basic():
         f: Optional[uint32]
         g: Tuple[uint32, str, bytes]
 
-    a = TestClass(24, 352, [1, 2, 4], [[1, 2, 3], [3, 4]], 728, None, (383, "hello", b"goodbye"))
+    # we want to test invalid here, hence the ignore.
+    a = TestClass(24, 352, [1, 2, 4], [[1, 2, 3], [3, 4]], 728, None, (383, "hello", b"goodbye"))  # type: ignore[arg-type,list-item] # noqa: E501
 
     b: bytes = bytes(a)
     assert a == TestClass.from_bytes(b)
 
 
-def test_variable_size():
+def test_variable_size() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClass2(Streamable):
@@ -201,7 +218,7 @@ def test_variable_size():
             a: int
 
 
-def test_json(bt):
+def test_json(bt: BlockTools) -> None:
     block = bt.create_genesis_block(test_constants, bytes32([0] * 32), uint64(0))
     dict_block = block.to_json_dict()
     assert FullBlock.from_json_dict(dict_block) == block
@@ -226,42 +243,44 @@ class OptionalTestClass(Streamable):
         (None, None, None),
     ],
 )
-def test_optional_json(a: Optional[str], b: Optional[bool], c: Optional[List[Optional[str]]]):
+def test_optional_json(a: Optional[str], b: Optional[bool], c: Optional[List[Optional[str]]]) -> None:
     obj: OptionalTestClass = OptionalTestClass.from_json_dict({"a": a, "b": b, "c": c})
     assert obj.a == a
     assert obj.b == b
     assert obj.c == c
 
 
-def test_recursive_json():
-    @streamable
-    @dataclass(frozen=True)
-    class TestClass1(Streamable):
-        a: List[uint32]
+@streamable
+@dataclass(frozen=True)
+class TestClassRecursive1(Streamable):
+    a: List[uint32]
+
+
+@streamable
+@dataclass(frozen=True)
+class TestClassRecursive2(Streamable):
+    a: uint32
+    b: List[Optional[List[TestClassRecursive1]]]
+    c: bytes32
 
-    @streamable
-    @dataclass(frozen=True)
-    class TestClass2(Streamable):
-        a: uint32
-        b: List[Optional[List[TestClass1]]]
-        c: bytes32
 
-    tc1_a = TestClass1([uint32(1), uint32(2)])
-    tc1_b = TestClass1([uint32(4), uint32(5)])
-    tc1_c = TestClass1([uint32(7), uint32(8)])
+def test_recursive_json() -> None:
+    tc1_a = TestClassRecursive1([uint32(1), uint32(2)])
+    tc1_b = TestClassRecursive1([uint32(4), uint32(5)])
+    tc1_c = TestClassRecursive1([uint32(7), uint32(8)])
 
-    tc2 = TestClass2(uint32(5), [[tc1_a], [tc1_b, tc1_c], None], bytes32(bytes([1] * 32)))
-    assert TestClass2.from_json_dict(tc2.to_json_dict()) == tc2
+    tc2 = TestClassRecursive2(uint32(5), [[tc1_a], [tc1_b, tc1_c], None], bytes32(bytes([1] * 32)))
+    assert TestClassRecursive2.from_json_dict(tc2.to_json_dict()) == tc2
 
 
-def test_recursive_types():
+def test_recursive_types() -> None:
     coin: Optional[Coin] = None
     l1 = [(bytes32([2] * 32), coin)]
     rr = RespondRemovals(uint32(1), bytes32([1] * 32), l1, None)
     RespondRemovals(rr.height, rr.header_hash, rr.coins, rr.proofs)
 
 
-def test_ambiguous_deserialization_optionals():
+def test_ambiguous_deserialization_optionals() -> None:
     with raises(AssertionError):
         SubEpochChallengeSegment.from_bytes(b"\x00\x00\x00\x03\xff\xff\xff\xff")
 
@@ -278,7 +297,7 @@ def test_ambiguous_deserialization_optionals():
     TestClassOptional.from_bytes(bytes([1, 2]))
 
 
-def test_ambiguous_deserialization_int():
+def test_ambiguous_deserialization_int() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClassUint(Streamable):
@@ -289,7 +308,7 @@ def test_ambiguous_deserialization_int():
         TestClassUint.from_bytes(b"\x00\x00")
 
 
-def test_ambiguous_deserialization_list():
+def test_ambiguous_deserialization_list() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClassList(Streamable):
@@ -300,7 +319,7 @@ def test_ambiguous_deserialization_list():
         TestClassList.from_bytes(bytes([0, 0, 100, 24]))
 
 
-def test_ambiguous_deserialization_tuple():
+def test_ambiguous_deserialization_tuple() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClassTuple(Streamable):
@@ -311,7 +330,7 @@ def test_ambiguous_deserialization_tuple():
         TestClassTuple.from_bytes(bytes([0, 0, 100, 24]))
 
 
-def test_ambiguous_deserialization_str():
+def test_ambiguous_deserialization_str() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClassStr(Streamable):
@@ -322,7 +341,7 @@ def test_ambiguous_deserialization_str():
         TestClassStr.from_bytes(bytes([0, 0, 100, 24, 52]))
 
 
-def test_ambiguous_deserialization_bytes():
+def test_ambiguous_deserialization_bytes() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClassBytes(Streamable):
@@ -339,7 +358,7 @@ def test_ambiguous_deserialization_bytes():
     TestClassBytes.from_bytes(bytes([0, 0, 0, 2, 52, 21]))
 
 
-def test_ambiguous_deserialization_bool():
+def test_ambiguous_deserialization_bool() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClassBool(Streamable):
@@ -353,13 +372,13 @@ def test_ambiguous_deserialization_bool():
     TestClassBool.from_bytes(bytes([1]))
 
 
-def test_ambiguous_deserialization_program():
+def test_ambiguous_deserialization_program() -> None:
     @streamable
     @dataclass(frozen=True)
     class TestClassProgram(Streamable):
         a: Program
 
-    program = Program.to(binutils.assemble("()"))
+    program = Program.to(binutils.assemble("()"))  # type: ignore[no-untyped-call]  # TODO, add typing in clvm_tools
 
     TestClassProgram.from_bytes(bytes(program))
 
@@ -367,7 +386,7 @@ def test_ambiguous_deserialization_program():
         TestClassProgram.from_bytes(bytes(program) + b"9")
 
 
-def test_streamable_empty():
+def test_streamable_empty() -> None:
     @streamable
     @dataclass(frozen=True)
     class A(Streamable):
@@ -376,7 +395,7 @@ def test_streamable_empty():
     assert A.from_bytes(bytes(A())) == A()
 
 
-def test_parse_bool():
+def test_parse_bool() -> None:
     assert not parse_bool(io.BytesIO(b"\x00"))
     assert parse_bool(io.BytesIO(b"\x01"))
 
@@ -391,7 +410,7 @@ def test_parse_bool():
         parse_bool(io.BytesIO(b"\x02"))
 
 
-def test_uint32():
+def test_uint32() -> None:
     assert parse_uint32(io.BytesIO(b"\x00\x00\x00\x00")) == 0
     assert parse_uint32(io.BytesIO(b"\x00\x00\x00\x01")) == 1
     assert parse_uint32(io.BytesIO(b"\x00\x00\x00\x01"), "little") == 16777216
@@ -399,7 +418,7 @@ def test_uint32():
     assert parse_uint32(io.BytesIO(b"\x01\x00\x00\x00"), "little") == 1
     assert parse_uint32(io.BytesIO(b"\xff\xff\xff\xff"), "little") == 4294967295
 
-    def test_write(value, byteorder):
+    def test_write(value: int, byteorder: Literal["little", "big"]) -> None:
         f = io.BytesIO()
         write_uint32(f, uint32(value), byteorder)
         f.seek(0)
@@ -420,7 +439,7 @@ def test_uint32():
         parse_uint32(io.BytesIO(b"\x00\x00\x00"))
 
 
-def test_parse_optional():
+def test_parse_optional() -> None:
     assert parse_optional(io.BytesIO(b"\x00"), parse_bool) is None
     assert parse_optional(io.BytesIO(b"\x01\x01"), parse_bool)
     assert not parse_optional(io.BytesIO(b"\x01\x00"), parse_bool)
@@ -437,7 +456,7 @@ def test_parse_optional():
         parse_optional(io.BytesIO(b"\xff\x00"), parse_bool)
 
 
-def test_parse_bytes():
+def test_parse_bytes() -> None:
 
     assert parse_bytes(io.BytesIO(b"\x00\x00\x00\x00")) == b""
     assert parse_bytes(io.BytesIO(b"\x00\x00\x00\x01\xff")) == b"\xff"
@@ -463,7 +482,7 @@ def test_parse_bytes():
         parse_bytes(io.BytesIO(b"\x00\x00\x02\x01" + b"a" * 512))
 
 
-def test_parse_list():
+def test_parse_list() -> None:
 
     assert parse_list(io.BytesIO(b"\x00\x00\x00\x00"), parse_bool) == []
     assert parse_list(io.BytesIO(b"\x00\x00\x00\x01\x01"), parse_bool) == [True]
@@ -484,7 +503,7 @@ def test_parse_list():
         parse_list(io.BytesIO(b"\x00\x00\x00\x01\x02"), parse_bool)
 
 
-def test_parse_tuple():
+def test_parse_tuple() -> None:
 
     assert parse_tuple(io.BytesIO(b""), []) == ()
     assert parse_tuple(io.BytesIO(b"\x00\x00"), [parse_bool, parse_bool]) == (False, False)
@@ -499,33 +518,35 @@ def test_parse_tuple():
         parse_tuple(io.BytesIO(b"\x00"), [parse_bool, parse_bool])
 
 
-def test_parse_size_hints():
-    class TestFromBytes:
-        b: bytes
+class TestFromBytes:
+    b: bytes
 
-        @classmethod
-        def from_bytes(cls, b):
-            ret = TestFromBytes()
-            ret.b = b
-            return ret
+    @classmethod
+    def from_bytes(cls, b: bytes) -> TestFromBytes:
+        ret = TestFromBytes()
+        ret.b = b
+        return ret
 
+
+class FailFromBytes:
+    @classmethod
+    def from_bytes(cls, b: bytes) -> FailFromBytes:
+        raise ValueError()
+
+
+def test_parse_size_hints() -> None:
     assert parse_size_hints(io.BytesIO(b"1337"), TestFromBytes, 4).b == b"1337"
 
     # EOF
     with raises(AssertionError):
         parse_size_hints(io.BytesIO(b"133"), TestFromBytes, 4)
 
-    class FailFromBytes:
-        @classmethod
-        def from_bytes(cls, b):
-            raise ValueError()
-
     # error in underlying type
     with raises(ValueError):
         parse_size_hints(io.BytesIO(b"1337"), FailFromBytes, 4)
 
 
-def test_parse_str():
+def test_parse_str() -> None:
 
     assert parse_str(io.BytesIO(b"\x00\x00\x00\x00")) == ""
     assert parse_str(io.BytesIO(b"\x00\x00\x00\x01a")) == "a"
@@ -551,7 +572,7 @@ def test_parse_str():
         parse_str(io.BytesIO(b"\x00\x00\x02\x01" + b"a" * 512))
 
 
-def test_wrong_decorator_order():
+def test_wrong_decorator_order() -> None:
 
     with raises(DefinitionError):
 
@@ -561,7 +582,7 @@ def test_wrong_decorator_order():
             pass
 
 
-def test_dataclass_not_frozen():
+def test_dataclass_not_frozen() -> None:
 
     with raises(DefinitionError):
 
@@ -571,7 +592,7 @@ def test_dataclass_not_frozen():
             pass
 
 
-def test_dataclass_missing():
+def test_dataclass_missing() -> None:
 
     with raises(DefinitionError):
 
@@ -580,11 +601,11 @@ def test_dataclass_missing():
             pass
 
 
-def test_streamable_inheritance_missing():
+def test_streamable_inheritance_missing() -> None:
 
     with raises(DefinitionError):
-
+        # we want to test invalid here, hence the ignore.
         @streamable
         @dataclass(frozen=True)
-        class StreamableInheritanceMissing:
+        class StreamableInheritanceMissing:  # type: ignore[type-var]
             pass
-- 
2.34.1


From 370ecd4f98513ca9f581aab5ddf0ba693dc56142 Mon Sep 17 00:00:00 2001
From: Florin Chirica <fchirica96@gmail.com>
Date: Wed, 20 Apr 2022 21:10:05 +0300
Subject: [PATCH 08/77] Fix timelord closing. (#10630)

---
 chia/timelord/timelord.py | 23 ++++++++++-------------
 1 file changed, 10 insertions(+), 13 deletions(-)

diff --git a/chia/timelord/timelord.py b/chia/timelord/timelord.py
index 456b6641d..732d90f85 100644
--- a/chia/timelord/timelord.py
+++ b/chia/timelord/timelord.py
@@ -183,25 +183,22 @@ class Timelord:
 
     async def _stop_chain(self, chain: Chain):
         try:
-            while chain not in self.allows_iters:
-                self.lock.release()
-                await asyncio.sleep(0.05)
-                log.error(f"Trying to stop {chain} before its initialization.")
-                await self.lock.acquire()
-                if chain not in self.chain_type_to_stream:
-                    log.warning(f"Trying to stop a crashed chain: {chain}.")
-                    return None
-            stop_ip, _, stop_writer = self.chain_type_to_stream[chain]
-            stop_writer.write(b"010")
-            await stop_writer.drain()
+            _, _, stop_writer = self.chain_type_to_stream[chain]
             if chain in self.allows_iters:
+                stop_writer.write(b"010")
+                await stop_writer.drain()
                 self.allows_iters.remove(chain)
+            else:
+                log.error(f"Trying to stop {chain} before its initialization.")
+                stop_writer.close()
+                await stop_writer.wait_closed()
             if chain not in self.unspawned_chains:
                 self.unspawned_chains.append(chain)
-            if chain in self.chain_type_to_stream:
-                del self.chain_type_to_stream[chain]
+            del self.chain_type_to_stream[chain]
         except ConnectionResetError as e:
             log.error(f"{e}")
+        except Exception as e:
+            log.error(f"Exception in stop chain: {type(e)} {e}")
 
     def _can_infuse_unfinished_block(self, block: timelord_protocol.NewUnfinishedBlockTimelord) -> Optional[uint64]:
         assert self.last_state is not None
-- 
2.34.1


From 743758c788e7386aa8c7c12274273cc4cecb264d Mon Sep 17 00:00:00 2001
From: Arvid Norberg <arvid@libtorrent.org>
Date: Wed, 20 Apr 2022 20:10:30 +0200
Subject: [PATCH 09/77] apply stricter mempool conditions (no garbage at the
 end of condition arguments). Fixup test (#10737)

---
 chia/full_node/mempool_check_conditions.py |   5 +-
 tests/core/full_node/test_mempool.py       | 146 +++++++++++++--------
 2 files changed, 94 insertions(+), 57 deletions(-)

diff --git a/chia/full_node/mempool_check_conditions.py b/chia/full_node/mempool_check_conditions.py
index 1457a29f4..04bae27dd 100644
--- a/chia/full_node/mempool_check_conditions.py
+++ b/chia/full_node/mempool_check_conditions.py
@@ -1,6 +1,6 @@
 import logging
 from typing import Dict, Optional
-from chia_rs import MEMPOOL_MODE, COND_CANON_INTS, NO_NEG_DIV, STRICT_ARGS_COUNT
+from chia_rs import MEMPOOL_MODE, COND_CANON_INTS, NO_NEG_DIV
 
 from chia.consensus.default_constants import DEFAULT_CONSTANTS
 from chia.consensus.cost_calculator import NPCResult
@@ -42,8 +42,7 @@ def get_name_puzzle_conditions(
     assert (MEMPOOL_MODE & NO_NEG_DIV) != 0
 
     if mempool_mode:
-        # Don't apply the strict args count rule yet
-        flags = MEMPOOL_MODE & (~STRICT_ARGS_COUNT)
+        flags = MEMPOOL_MODE
     elif unwrap(height) >= DEFAULT_CONSTANTS.SOFT_FORK_HEIGHT:
         # conditions must use integers in canonical encoding (i.e. no redundant
         # leading zeros)
diff --git a/tests/core/full_node/test_mempool.py b/tests/core/full_node/test_mempool.py
index a05f5b4e3..0d9f4c7e9 100644
--- a/tests/core/full_node/test_mempool.py
+++ b/tests/core/full_node/test_mempool.py
@@ -642,14 +642,15 @@ class TestMempoolManager:
     async def test_block_index_garbage(self, bt, one_node_one_block, wallet_a):
 
         full_node_1, server_1 = one_node_one_block
-        # garbage at the end of the argument list is ignored
+        # garbage at the end of the argument list is ignored in consensus mode,
+        # but not in mempool-mode
         cvp = ConditionWithArgs(ConditionOpcode.ASSERT_HEIGHT_ABSOLUTE, [int_to_bytes(1), b"garbage"])
         dic = {ConditionOpcode.ASSERT_HEIGHT_ABSOLUTE: [cvp]}
         blocks, spend_bundle1, peer, status, err = await self.condition_tester(bt, one_node_one_block, wallet_a, dic)
         sb1 = full_node_1.full_node.mempool_manager.get_spendbundle(spend_bundle1.name())
-        assert err is None
-        assert sb1 is spend_bundle1
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is Err.INVALID_CONDITION
+        assert sb1 is None
+        assert status == MempoolInclusionStatus.FAILED
 
     @pytest.mark.asyncio
     async def test_negative_block_index(self, bt, one_node_one_block, wallet_a):
@@ -708,7 +709,8 @@ class TestMempoolManager:
     async def test_block_age_garbage(self, bt, one_node_one_block, wallet_a):
 
         full_node_1, server_1 = one_node_one_block
-        # garbage at the end of the argument list is ignored
+        # garbage at the end of the argument list is ignored in consensus mode,
+        # but not in mempool mode
         cvp = ConditionWithArgs(ConditionOpcode.ASSERT_HEIGHT_RELATIVE, [int_to_bytes(1), b"garbage"])
         dic = {cvp.opcode: [cvp]}
         blocks, spend_bundle1, peer, status, err = await self.condition_tester(
@@ -716,9 +718,9 @@ class TestMempoolManager:
         )
 
         sb1 = full_node_1.full_node.mempool_manager.get_spendbundle(spend_bundle1.name())
-        assert err is None
-        assert sb1 is spend_bundle1
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is Err.INVALID_CONDITION
+        assert sb1 is None
+        assert status == MempoolInclusionStatus.FAILED
 
     @pytest.mark.asyncio
     async def test_negative_block_age(self, bt, one_node_one_block, wallet_a):
@@ -762,7 +764,8 @@ class TestMempoolManager:
         _ = await next_block(full_node_1, wallet_a, bt)
         _ = await next_block(full_node_1, wallet_a, bt)
         coin = await next_block(full_node_1, wallet_a, bt)
-        # garbage at the end of the argument list is ignored
+        # garbage at the end of the argument list is ignored in consensus mode,
+        # but not in mempool mode
         cvp = ConditionWithArgs(ConditionOpcode.ASSERT_MY_COIN_ID, [coin.name(), b"garbage"])
         dic = {cvp.opcode: [cvp]}
         blocks, spend_bundle1, peer, status, err = await self.condition_tester(
@@ -770,9 +773,9 @@ class TestMempoolManager:
         )
 
         sb1 = full_node_1.full_node.mempool_manager.get_spendbundle(spend_bundle1.name())
-        assert err is None
-        assert sb1 is spend_bundle1
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is Err.INVALID_CONDITION
+        assert sb1 is None
+        assert status == MempoolInclusionStatus.FAILED
 
     @pytest.mark.asyncio
     async def test_invalid_my_id(self, bt, one_node_one_block, wallet_a):
@@ -885,14 +888,15 @@ class TestMempoolManager:
         full_node_1, server_1 = one_node_one_block
         time_now = full_node_1.full_node.blockchain.get_peak().timestamp + 5
 
-        # garbage at the end of the argument list is ignored
+        # garbage at the end of the argument list is ignored in consensus mode,
+        # but not in mempool mode
         cvp = ConditionWithArgs(ConditionOpcode.ASSERT_SECONDS_ABSOLUTE, [int_to_bytes(time_now), b"garbage"])
         dic = {cvp.opcode: [cvp]}
         blocks, spend_bundle1, peer, status, err = await self.condition_tester(bt, one_node_one_block, wallet_a, dic)
         sb1 = full_node_1.full_node.mempool_manager.get_spendbundle(spend_bundle1.name())
-        assert err is None
-        assert sb1 is spend_bundle1
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is Err.INVALID_CONDITION
+        assert sb1 is None
+        assert status == MempoolInclusionStatus.FAILED
 
     @pytest.mark.asyncio
     async def test_assert_time_relative_exceeds(self, bt, one_node_one_block, wallet_a):
@@ -927,15 +931,16 @@ class TestMempoolManager:
         full_node_1, server_1 = one_node_one_block
         time_relative = 0
 
-        # garbage at the end of the arguments is ignored
+        # garbage at the end of the arguments is ignored in consensus mode, but
+        # not in mempool mode
         cvp = ConditionWithArgs(ConditionOpcode.ASSERT_SECONDS_RELATIVE, [int_to_bytes(time_relative), b"garbage"])
         dic = {cvp.opcode: [cvp]}
         blocks, spend_bundle1, peer, status, err = await self.condition_tester(bt, one_node_one_block, wallet_a, dic)
 
         sb1 = full_node_1.full_node.mempool_manager.get_spendbundle(spend_bundle1.name())
-        assert err is None
-        assert sb1 is spend_bundle1
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is Err.INVALID_CONDITION
+        assert sb1 is None
+        assert status == MempoolInclusionStatus.FAILED
 
     @pytest.mark.asyncio
     async def test_assert_time_relative_missing_arg(self, bt, one_node_one_block, wallet_a):
@@ -990,17 +995,34 @@ class TestMempoolManager:
         assert status == MempoolInclusionStatus.SUCCESS
 
     # ensure one spend can assert a coin announcement from another spend, even
-    # though the conditions have garbage (ignored) at the end
+    # though the conditions have garbage at the end
     @pytest.mark.asyncio
-    async def test_coin_announcement_garbage(self, bt, one_node_one_block, wallet_a):
+    @pytest.mark.parametrize(
+        "assert_garbage,announce_garbage,expected,expected_included",
+        [
+            (True, False, Err.INVALID_CONDITION, MempoolInclusionStatus.FAILED),
+            (False, True, Err.INVALID_CONDITION, MempoolInclusionStatus.FAILED),
+            (False, False, None, MempoolInclusionStatus.SUCCESS),
+        ],
+    )
+    async def test_coin_announcement_garbage(
+        self, assert_garbage, announce_garbage, expected, expected_included, bt, one_node_one_block, wallet_a
+    ):
         def test_fun(coin_1: Coin, coin_2: Coin) -> SpendBundle:
             announce = Announcement(coin_2.name(), b"test")
-            # garbage at the end is ignored
-            cvp = ConditionWithArgs(ConditionOpcode.ASSERT_COIN_ANNOUNCEMENT, [announce.name(), b"garbage"])
+            # garbage at the end is ignored in consensus mode, but not in
+            # mempool mode
+            cvp = ConditionWithArgs(
+                ConditionOpcode.ASSERT_COIN_ANNOUNCEMENT,
+                [bytes(announce.name())] + ([b"garbage"] if announce_garbage else []),
+            )
             dic = {cvp.opcode: [cvp]}
 
-            # garbage at the end is ignored
-            cvp2 = ConditionWithArgs(ConditionOpcode.CREATE_COIN_ANNOUNCEMENT, [b"test", b"garbage"])
+            # garbage at the end is ignored in consensus mode, but not in
+            # mempool mode
+            cvp2 = ConditionWithArgs(
+                ConditionOpcode.CREATE_COIN_ANNOUNCEMENT, [b"test"] + ([b"garbage"] if assert_garbage else [])
+            )
             dic2 = {cvp.opcode: [cvp2]}
             spend_bundle1 = generate_test_spend_bundle(wallet_a, coin_1, dic)
             spend_bundle2 = generate_test_spend_bundle(wallet_a, coin_2, dic2)
@@ -1009,11 +1031,9 @@ class TestMempoolManager:
 
         full_node_1, server_1 = one_node_one_block
         blocks, bundle, status, err = await self.condition_tester2(bt, one_node_one_block, wallet_a, test_fun)
-        mempool_bundle = full_node_1.full_node.mempool_manager.get_spendbundle(bundle.name())
 
-        assert err is None
-        assert mempool_bundle is bundle
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is expected
+        assert status == expected_included
 
     @pytest.mark.asyncio
     async def test_coin_announcement_missing_arg(self, bt, one_node_one_block, wallet_a):
@@ -1175,17 +1195,34 @@ class TestMempoolManager:
         assert status == MempoolInclusionStatus.SUCCESS
 
     @pytest.mark.asyncio
-    async def test_puzzle_announcement_garbage(self, bt, one_node_one_block, wallet_a):
+    @pytest.mark.parametrize(
+        "assert_garbage,announce_garbage,expected,expected_included",
+        [
+            (True, False, Err.INVALID_CONDITION, MempoolInclusionStatus.FAILED),
+            (False, True, Err.INVALID_CONDITION, MempoolInclusionStatus.FAILED),
+            (False, False, None, MempoolInclusionStatus.SUCCESS),
+        ],
+    )
+    async def test_puzzle_announcement_garbage(
+        self, assert_garbage, announce_garbage, expected, expected_included, bt, one_node_one_block, wallet_a
+    ):
         full_node_1, server_1 = one_node_one_block
 
         def test_fun(coin_1: Coin, coin_2: Coin):
             announce = Announcement(coin_2.puzzle_hash, bytes(0x80))
 
-            # garbage at the end is ignored
-            cvp = ConditionWithArgs(ConditionOpcode.ASSERT_PUZZLE_ANNOUNCEMENT, [announce.name(), b"garbage"])
+            # garbage at the end is ignored in consensus mode, but not in
+            # mempool mode
+            cvp = ConditionWithArgs(
+                ConditionOpcode.ASSERT_PUZZLE_ANNOUNCEMENT,
+                [bytes(announce.name())] + ([b"garbage"] if assert_garbage else []),
+            )
             dic = {cvp.opcode: [cvp]}
-            # garbage at the end is ignored
-            cvp2 = ConditionWithArgs(ConditionOpcode.CREATE_PUZZLE_ANNOUNCEMENT, [bytes(0x80), b"garbage"])
+            # garbage at the end is ignored in consensus mode, but not in
+            # mempool mode
+            cvp2 = ConditionWithArgs(
+                ConditionOpcode.CREATE_PUZZLE_ANNOUNCEMENT, [bytes(0x80)] + ([b"garbage"] if announce_garbage else [])
+            )
             dic2 = {cvp.opcode: [cvp2]}
             spend_bundle1 = generate_test_spend_bundle(wallet_a, coin_1, dic)
             spend_bundle2 = generate_test_spend_bundle(wallet_a, coin_2, dic2)
@@ -1193,11 +1230,9 @@ class TestMempoolManager:
             return SpendBundle.aggregate([spend_bundle1, spend_bundle2])
 
         blocks, bundle, status, err = await self.condition_tester2(bt, one_node_one_block, wallet_a, test_fun)
-        mempool_bundle = full_node_1.full_node.mempool_manager.get_spendbundle(bundle.name())
 
-        assert err is None
-        assert mempool_bundle is bundle
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is expected
+        assert status == expected_included
 
     @pytest.mark.asyncio
     async def test_puzzle_announcement_missing_arg(self, bt, one_node_one_block, wallet_a):
@@ -1330,7 +1365,8 @@ class TestMempoolManager:
     async def test_assert_fee_condition_garbage(self, bt, one_node_one_block, wallet_a):
 
         full_node_1, server_1 = one_node_one_block
-        # garbage at the end of the arguments is ignored
+        # garbage at the end of the arguments is ignored in consensus mode, but
+        # not in mempool mode
         cvp = ConditionWithArgs(ConditionOpcode.RESERVE_FEE, [int_to_bytes(10), b"garbage"])
         dic = {cvp.opcode: [cvp]}
         blocks, spend_bundle1, peer, status, err = await self.condition_tester(
@@ -1338,9 +1374,9 @@ class TestMempoolManager:
         )
         mempool_bundle = full_node_1.full_node.mempool_manager.get_spendbundle(spend_bundle1.name())
 
-        assert err is None
-        assert mempool_bundle is not None
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is Err.INVALID_CONDITION
+        assert mempool_bundle is None
+        assert status == MempoolInclusionStatus.FAILED
 
     @pytest.mark.asyncio
     async def test_assert_fee_condition_missing_arg(self, bt, one_node_one_block, wallet_a):
@@ -1583,7 +1619,8 @@ class TestMempoolManager:
         _ = await next_block(full_node_1, wallet_a, bt)
         _ = await next_block(full_node_1, wallet_a, bt)
         coin = await next_block(full_node_1, wallet_a, bt)
-        # garbage at the end of the arguments list is allowed but stripped
+        # garbage at the end of the arguments list is allowed in consensus mode,
+        # but not in mempool mode
         cvp = ConditionWithArgs(ConditionOpcode.ASSERT_MY_PARENT_ID, [coin.parent_coin_info, b"garbage"])
         dic = {cvp.opcode: [cvp]}
         blocks, spend_bundle1, peer, status, err = await self.condition_tester(
@@ -1592,9 +1629,9 @@ class TestMempoolManager:
 
         sb1 = full_node_1.full_node.mempool_manager.get_spendbundle(spend_bundle1.name())
 
-        assert err is None
-        assert sb1 is spend_bundle1
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is Err.INVALID_CONDITION
+        assert sb1 is None
+        assert status == MempoolInclusionStatus.FAILED
 
     @pytest.mark.asyncio
     async def test_my_parent_missing_arg(self, bt, one_node_one_block, wallet_a):
@@ -1669,9 +1706,9 @@ class TestMempoolManager:
 
         sb1 = full_node_1.full_node.mempool_manager.get_spendbundle(spend_bundle1.name())
 
-        assert err is None
-        assert sb1 is spend_bundle1
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is Err.INVALID_CONDITION
+        assert sb1 is None
+        assert status == MempoolInclusionStatus.FAILED
 
     @pytest.mark.asyncio
     async def test_my_puzhash_missing_arg(self, bt, one_node_one_block, wallet_a):
@@ -1736,7 +1773,8 @@ class TestMempoolManager:
         _ = await next_block(full_node_1, wallet_a, bt)
         _ = await next_block(full_node_1, wallet_a, bt)
         coin = await next_block(full_node_1, wallet_a, bt)
-        # garbage at the end of the arguments list is allowed but stripped
+        # garbage at the end of the arguments list is allowed in consensus mode,
+        # but not in mempool mode
         cvp = ConditionWithArgs(ConditionOpcode.ASSERT_MY_AMOUNT, [int_to_bytes(coin.amount), b"garbage"])
         dic = {cvp.opcode: [cvp]}
         blocks, spend_bundle1, peer, status, err = await self.condition_tester(
@@ -1745,9 +1783,9 @@ class TestMempoolManager:
 
         sb1 = full_node_1.full_node.mempool_manager.get_spendbundle(spend_bundle1.name())
 
-        assert err is None
-        assert sb1 is spend_bundle1
-        assert status == MempoolInclusionStatus.SUCCESS
+        assert err is Err.INVALID_CONDITION
+        assert sb1 is None
+        assert status == MempoolInclusionStatus.FAILED
 
     @pytest.mark.asyncio
     async def test_my_amount_missing_arg(self, bt, one_node_one_block, wallet_a):
-- 
2.34.1


From cf1a328e0304b18ff09b9787219c43fa49e96f84 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:10:52 +0200
Subject: [PATCH 10/77] wallet: Fix `CATLineageStore` creation in
 `create_new_cat_wallet` (#10791)

* Implement `test_cat_creation_unique_lineage_store()`

Make sure creating CAT wallets leads to unique lineage stores.

* Fix `CATLineageStore` creation in `create_new_cat_wallet`

We currently create the `CATLineageStore` before the new asset id exists
which leads to all CATs created by `create_new_cat_wallet` using the
same lineage store table:
`lineage_proofs_0000000000000000000000000000000000000000`.

* Create `CATLineageStore` in `generate_issuance_bundle`
---
 chia/wallet/cat_wallet/cat_wallet.py       |  2 --
 chia/wallet/puzzles/tails.py               |  7 +++-
 tests/wallet/cat_wallet/test_cat_wallet.py | 40 ++++++++++++++++++++++
 3 files changed, 46 insertions(+), 3 deletions(-)

diff --git a/chia/wallet/cat_wallet/cat_wallet.py b/chia/wallet/cat_wallet/cat_wallet.py
index b58c9b9ce..b8bacf0e2 100644
--- a/chia/wallet/cat_wallet/cat_wallet.py
+++ b/chia/wallet/cat_wallet/cat_wallet.py
@@ -97,8 +97,6 @@ class CATWallet:
 
         self.wallet_info = new_wallet_info
 
-        self.lineage_store = await CATLineageStore.create(self.wallet_state_manager.db_wrapper, self.get_asset_id())
-
         try:
             chia_tx, spend_bundle = await ALL_LIMITATIONS_PROGRAMS[
                 cat_tail_info["identifier"]
diff --git a/chia/wallet/puzzles/tails.py b/chia/wallet/puzzles/tails.py
index 4af3590cb..6aac17354 100644
--- a/chia/wallet/puzzles/tails.py
+++ b/chia/wallet/puzzles/tails.py
@@ -5,6 +5,7 @@ from chia.types.blockchain_format.sized_bytes import bytes32
 from chia.types.spend_bundle import SpendBundle
 from chia.util.ints import uint64
 from chia.util.byte_types import hexstr_to_bytes
+from chia.wallet.cat_wallet.lineage_store import CATLineageStore
 from chia.wallet.lineage_proof import LineageProof
 from chia.wallet.puzzles.load_clvm import load_clvm
 from chia.wallet.cat_wallet.cat_utils import (
@@ -72,9 +73,13 @@ class GenesisById(LimitationsProgram):
         origin_id = origin.name()
 
         cat_inner: Program = await wallet.get_new_inner_puzzle()
-        await wallet.add_lineage(origin_id, LineageProof(), False)
         tail: Program = cls.construct([Program.to(origin_id)])
 
+        wallet.lineage_store = await CATLineageStore.create(
+            wallet.wallet_state_manager.db_wrapper, tail.get_tree_hash().hex()
+        )
+        await wallet.add_lineage(origin_id, LineageProof(), False)
+
         minted_cat_puzzle_hash: bytes32 = construct_cat_puzzle(CAT_MOD, tail.get_tree_hash(), cat_inner).get_tree_hash()
 
         tx_record: TransactionRecord = await wallet.standard_wallet.generate_signed_transaction(
diff --git a/tests/wallet/cat_wallet/test_cat_wallet.py b/tests/wallet/cat_wallet/test_cat_wallet.py
index a8c57100a..bfde40d42 100644
--- a/tests/wallet/cat_wallet/test_cat_wallet.py
+++ b/tests/wallet/cat_wallet/test_cat_wallet.py
@@ -98,6 +98,46 @@ class TestCATWallet:
         assert new_cat_wallet.cat_info.my_tail == cat_wallet.cat_info.my_tail
         assert await cat_wallet.lineage_store.get_all_lineage_proofs() == all_lineage
 
+    @pytest.mark.asyncio
+    async def test_cat_creation_unique_lineage_store(self, self_hostname, two_wallet_nodes):
+        num_blocks = 3
+        full_nodes, wallets = two_wallet_nodes
+        full_node_api = full_nodes[0]
+        full_node_server = full_node_api.server
+        wallet_node, wallet_server = wallets[0]
+        wallet = wallet_node.wallet_state_manager.main_wallet
+        ph = await wallet.get_new_puzzlehash()
+        wallet_node.config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
+
+        await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
+        for i in range(0, num_blocks):
+            await full_node_api.farm_new_transaction_block(FarmNewBlockProtocol(ph))
+        await full_node_api.farm_new_transaction_block(FarmNewBlockProtocol(32 * b"0"))
+
+        funds = sum(
+            [
+                calculate_pool_reward(uint32(i)) + calculate_base_farmer_reward(uint32(i))
+                for i in range(1, num_blocks + 1)
+            ]
+        )
+
+        await time_out_assert(15, wallet.get_confirmed_balance, funds)
+        await time_out_assert(10, wallet_is_synced, True, wallet_node, full_node_api)
+
+        async with wallet_node.wallet_state_manager.lock:
+            cat_wallet_1: CATWallet = await CATWallet.create_new_cat_wallet(
+                wallet_node.wallet_state_manager, wallet, {"identifier": "genesis_by_id"}, uint64(100)
+            )
+            cat_wallet_2: CATWallet = await CATWallet.create_new_cat_wallet(
+                wallet_node.wallet_state_manager, wallet, {"identifier": "genesis_by_id"}, uint64(200)
+            )
+
+        proofs_1 = await cat_wallet_1.lineage_store.get_all_lineage_proofs()
+        proofs_2 = await cat_wallet_2.lineage_store.get_all_lineage_proofs()
+        assert len(proofs_1) == len(proofs_2)
+        assert proofs_1 != proofs_2
+        assert cat_wallet_1.lineage_store.table_name != cat_wallet_2.lineage_store.table_name
+
     @pytest.mark.parametrize(
         "trusted",
         [True, False],
-- 
2.34.1


From b9c9727b75bb4904028dd76790f662c2d6817665 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 20 Apr 2022 11:11:08 -0700
Subject: [PATCH 11/77] --module pytest (#10940)

---
 .github/workflows/build-test-macos-blockchain.yml               | 2 +-
 .github/workflows/build-test-macos-clvm.yml                     | 2 +-
 .github/workflows/build-test-macos-core-cmds.yml                | 2 +-
 .github/workflows/build-test-macos-core-consensus.yml           | 2 +-
 .github/workflows/build-test-macos-core-custom_types.yml        | 2 +-
 .github/workflows/build-test-macos-core-daemon.yml              | 2 +-
 .github/workflows/build-test-macos-core-full_node-full_sync.yml | 2 +-
 .github/workflows/build-test-macos-core-full_node-stores.yml    | 2 +-
 .github/workflows/build-test-macos-core-full_node.yml           | 2 +-
 .github/workflows/build-test-macos-core-server.yml              | 2 +-
 .github/workflows/build-test-macos-core-ssl.yml                 | 2 +-
 .github/workflows/build-test-macos-core-util.yml                | 2 +-
 .github/workflows/build-test-macos-core.yml                     | 2 +-
 .github/workflows/build-test-macos-farmer_harvester.yml         | 2 +-
 .github/workflows/build-test-macos-generator.yml                | 2 +-
 .github/workflows/build-test-macos-plotting.yml                 | 2 +-
 .github/workflows/build-test-macos-pools.yml                    | 2 +-
 .github/workflows/build-test-macos-simulation.yml               | 2 +-
 .github/workflows/build-test-macos-tools.yml                    | 2 +-
 .github/workflows/build-test-macos-util.yml                     | 2 +-
 .github/workflows/build-test-macos-wallet-cat_wallet.yml        | 2 +-
 .github/workflows/build-test-macos-wallet-did_wallet.yml        | 2 +-
 .github/workflows/build-test-macos-wallet-rl_wallet.yml         | 2 +-
 .github/workflows/build-test-macos-wallet-rpc.yml               | 2 +-
 .github/workflows/build-test-macos-wallet-simple_sync.yml       | 2 +-
 .github/workflows/build-test-macos-wallet-sync.yml              | 2 +-
 .github/workflows/build-test-macos-wallet.yml                   | 2 +-
 .github/workflows/build-test-macos-weight_proof.yml             | 2 +-
 .github/workflows/build-test-ubuntu-blockchain.yml              | 2 +-
 .github/workflows/build-test-ubuntu-clvm.yml                    | 2 +-
 .github/workflows/build-test-ubuntu-core-cmds.yml               | 2 +-
 .github/workflows/build-test-ubuntu-core-consensus.yml          | 2 +-
 .github/workflows/build-test-ubuntu-core-custom_types.yml       | 2 +-
 .github/workflows/build-test-ubuntu-core-daemon.yml             | 2 +-
 .../workflows/build-test-ubuntu-core-full_node-full_sync.yml    | 2 +-
 .github/workflows/build-test-ubuntu-core-full_node-stores.yml   | 2 +-
 .github/workflows/build-test-ubuntu-core-full_node.yml          | 2 +-
 .github/workflows/build-test-ubuntu-core-server.yml             | 2 +-
 .github/workflows/build-test-ubuntu-core-ssl.yml                | 2 +-
 .github/workflows/build-test-ubuntu-core-util.yml               | 2 +-
 .github/workflows/build-test-ubuntu-core.yml                    | 2 +-
 .github/workflows/build-test-ubuntu-farmer_harvester.yml        | 2 +-
 .github/workflows/build-test-ubuntu-generator.yml               | 2 +-
 .github/workflows/build-test-ubuntu-plotting.yml                | 2 +-
 .github/workflows/build-test-ubuntu-pools.yml                   | 2 +-
 .github/workflows/build-test-ubuntu-simulation.yml              | 2 +-
 .github/workflows/build-test-ubuntu-tools.yml                   | 2 +-
 .github/workflows/build-test-ubuntu-util.yml                    | 2 +-
 .github/workflows/build-test-ubuntu-wallet-cat_wallet.yml       | 2 +-
 .github/workflows/build-test-ubuntu-wallet-did_wallet.yml       | 2 +-
 .github/workflows/build-test-ubuntu-wallet-rl_wallet.yml        | 2 +-
 .github/workflows/build-test-ubuntu-wallet-rpc.yml              | 2 +-
 .github/workflows/build-test-ubuntu-wallet-simple_sync.yml      | 2 +-
 .github/workflows/build-test-ubuntu-wallet-sync.yml             | 2 +-
 .github/workflows/build-test-ubuntu-wallet.yml                  | 2 +-
 .github/workflows/build-test-ubuntu-weight_proof.yml            | 2 +-
 tests/runner_templates/build-test-macos                         | 2 +-
 tests/runner_templates/build-test-ubuntu                        | 2 +-
 58 files changed, 58 insertions(+), 58 deletions(-)

diff --git a/.github/workflows/build-test-macos-blockchain.yml b/.github/workflows/build-test-macos-blockchain.yml
index a816459ff..818e10a1a 100644
--- a/.github/workflows/build-test-macos-blockchain.yml
+++ b/.github/workflows/build-test-macos-blockchain.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test blockchain code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/blockchain/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/blockchain/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-clvm.yml b/.github/workflows/build-test-macos-clvm.yml
index f2d496da9..6e945fee8 100644
--- a/.github/workflows/build-test-macos-clvm.yml
+++ b/.github/workflows/build-test-macos-clvm.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test clvm code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/clvm/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/clvm/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-cmds.yml b/.github/workflows/build-test-macos-core-cmds.yml
index 687ae6c94..b59975bb6 100644
--- a/.github/workflows/build-test-macos-core-cmds.yml
+++ b/.github/workflows/build-test-macos-core-cmds.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test core-cmds code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/cmds/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/cmds/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-consensus.yml b/.github/workflows/build-test-macos-core-consensus.yml
index f5cd79898..70f080739 100644
--- a/.github/workflows/build-test-macos-core-consensus.yml
+++ b/.github/workflows/build-test-macos-core-consensus.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test core-consensus code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/consensus/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/consensus/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-custom_types.yml b/.github/workflows/build-test-macos-core-custom_types.yml
index 130d15420..24111f0ea 100644
--- a/.github/workflows/build-test-macos-core-custom_types.yml
+++ b/.github/workflows/build-test-macos-core-custom_types.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test core-custom_types code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/custom_types/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/custom_types/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-daemon.yml b/.github/workflows/build-test-macos-core-daemon.yml
index 7ab9dc765..521c76932 100644
--- a/.github/workflows/build-test-macos-core-daemon.yml
+++ b/.github/workflows/build-test-macos-core-daemon.yml
@@ -97,7 +97,7 @@ jobs:
     - name: Test core-daemon code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/daemon/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/daemon/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-full_node-full_sync.yml b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
index fd8e5da8d..d7ac33bea 100644
--- a/.github/workflows/build-test-macos-core-full_node-full_sync.yml
+++ b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-full_node-full_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/full_node/full_sync/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/full_sync/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-full_node-stores.yml b/.github/workflows/build-test-macos-core-full_node-stores.yml
index 72a06b6ca..b9695515b 100644
--- a/.github/workflows/build-test-macos-core-full_node-stores.yml
+++ b/.github/workflows/build-test-macos-core-full_node-stores.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-full_node-stores code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/full_node/stores/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/stores/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-full_node.yml b/.github/workflows/build-test-macos-core-full_node.yml
index 83d6cb015..51fa84a3b 100644
--- a/.github/workflows/build-test-macos-core-full_node.yml
+++ b/.github/workflows/build-test-macos-core-full_node.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-full_node code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/full_node/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-server.yml b/.github/workflows/build-test-macos-core-server.yml
index e93f23b2f..95857e0c6 100644
--- a/.github/workflows/build-test-macos-core-server.yml
+++ b/.github/workflows/build-test-macos-core-server.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-server code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/server/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/server/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-ssl.yml b/.github/workflows/build-test-macos-core-ssl.yml
index db9903634..c1b0bf96c 100644
--- a/.github/workflows/build-test-macos-core-ssl.yml
+++ b/.github/workflows/build-test-macos-core-ssl.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-ssl code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/ssl/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/ssl/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-util.yml b/.github/workflows/build-test-macos-core-util.yml
index 0935d2d54..3900c066a 100644
--- a/.github/workflows/build-test-macos-core-util.yml
+++ b/.github/workflows/build-test-macos-core-util.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-util code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/util/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/util/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core.yml b/.github/workflows/build-test-macos-core.yml
index 4fe7cab24..1b84573b8 100644
--- a/.github/workflows/build-test-macos-core.yml
+++ b/.github/workflows/build-test-macos-core.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-farmer_harvester.yml b/.github/workflows/build-test-macos-farmer_harvester.yml
index 9c9f2b473..011b077ba 100644
--- a/.github/workflows/build-test-macos-farmer_harvester.yml
+++ b/.github/workflows/build-test-macos-farmer_harvester.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test farmer_harvester code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/farmer_harvester/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/farmer_harvester/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-generator.yml b/.github/workflows/build-test-macos-generator.yml
index e695c65e9..e3aca9c35 100644
--- a/.github/workflows/build-test-macos-generator.yml
+++ b/.github/workflows/build-test-macos-generator.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test generator code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/generator/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/generator/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-plotting.yml b/.github/workflows/build-test-macos-plotting.yml
index 30d44782f..8468bfd97 100644
--- a/.github/workflows/build-test-macos-plotting.yml
+++ b/.github/workflows/build-test-macos-plotting.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test plotting code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/plotting/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/plotting/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-pools.yml b/.github/workflows/build-test-macos-pools.yml
index 9279455da..3b2dd413c 100644
--- a/.github/workflows/build-test-macos-pools.yml
+++ b/.github/workflows/build-test-macos-pools.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test pools code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/pools/test_*.py --durations=10  -n 2 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/pools/test_*.py --durations=10  -n 2 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-simulation.yml b/.github/workflows/build-test-macos-simulation.yml
index 9d8e1f57e..d8f78d913 100644
--- a/.github/workflows/build-test-macos-simulation.yml
+++ b/.github/workflows/build-test-macos-simulation.yml
@@ -97,7 +97,7 @@ jobs:
     - name: Test simulation code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/simulation/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/simulation/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-tools.yml b/.github/workflows/build-test-macos-tools.yml
index e0a4396b6..b615d40a0 100644
--- a/.github/workflows/build-test-macos-tools.yml
+++ b/.github/workflows/build-test-macos-tools.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test tools code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/tools/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/tools/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-util.yml b/.github/workflows/build-test-macos-util.yml
index f0f2334a0..adda26ace 100644
--- a/.github/workflows/build-test-macos-util.yml
+++ b/.github/workflows/build-test-macos-util.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test util code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/util/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/util/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-cat_wallet.yml b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
index 70858e93b..0e9c3e86d 100644
--- a/.github/workflows/build-test-macos-wallet-cat_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet-cat_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/cat_wallet/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/cat_wallet/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-did_wallet.yml b/.github/workflows/build-test-macos-wallet-did_wallet.yml
index 4f97d0ea2..4601927e1 100644
--- a/.github/workflows/build-test-macos-wallet-did_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-did_wallet.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test wallet-did_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/did_wallet/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/did_wallet/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-rl_wallet.yml b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
index 1e1951626..2c5987b75 100644
--- a/.github/workflows/build-test-macos-wallet-rl_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test wallet-rl_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/rl_wallet/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/rl_wallet/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-rpc.yml b/.github/workflows/build-test-macos-wallet-rpc.yml
index 68a95ea7a..ad54fff9c 100644
--- a/.github/workflows/build-test-macos-wallet-rpc.yml
+++ b/.github/workflows/build-test-macos-wallet-rpc.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet-rpc code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/rpc/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/rpc/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-simple_sync.yml b/.github/workflows/build-test-macos-wallet-simple_sync.yml
index 0a1a359b3..9c2e907ca 100644
--- a/.github/workflows/build-test-macos-wallet-simple_sync.yml
+++ b/.github/workflows/build-test-macos-wallet-simple_sync.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet-simple_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/simple_sync/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/simple_sync/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-sync.yml b/.github/workflows/build-test-macos-wallet-sync.yml
index c92ca8e21..d0d4b945a 100644
--- a/.github/workflows/build-test-macos-wallet-sync.yml
+++ b/.github/workflows/build-test-macos-wallet-sync.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet-sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/sync/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/sync/test_*.py --durations=10  -n 0 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet.yml b/.github/workflows/build-test-macos-wallet.yml
index 0a7124880..a02077424 100644
--- a/.github/workflows/build-test-macos-wallet.yml
+++ b/.github/workflows/build-test-macos-wallet.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-weight_proof.yml b/.github/workflows/build-test-macos-weight_proof.yml
index 9b737c31e..1132955ba 100644
--- a/.github/workflows/build-test-macos-weight_proof.yml
+++ b/.github/workflows/build-test-macos-weight_proof.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test weight_proof code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/weight_proof/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/weight_proof/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-blockchain.yml b/.github/workflows/build-test-ubuntu-blockchain.yml
index 60dbb4516..110949da8 100644
--- a/.github/workflows/build-test-ubuntu-blockchain.yml
+++ b/.github/workflows/build-test-ubuntu-blockchain.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test blockchain code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/blockchain/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/blockchain/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-clvm.yml b/.github/workflows/build-test-ubuntu-clvm.yml
index 35275d29e..57d505656 100644
--- a/.github/workflows/build-test-ubuntu-clvm.yml
+++ b/.github/workflows/build-test-ubuntu-clvm.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test clvm code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/clvm/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/clvm/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-cmds.yml b/.github/workflows/build-test-ubuntu-core-cmds.yml
index f5f8ed214..9305933f7 100644
--- a/.github/workflows/build-test-ubuntu-core-cmds.yml
+++ b/.github/workflows/build-test-ubuntu-core-cmds.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test core-cmds code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/cmds/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/cmds/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-consensus.yml b/.github/workflows/build-test-ubuntu-core-consensus.yml
index f9045c31b..3f373ff0d 100644
--- a/.github/workflows/build-test-ubuntu-core-consensus.yml
+++ b/.github/workflows/build-test-ubuntu-core-consensus.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test core-consensus code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/consensus/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/consensus/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-custom_types.yml b/.github/workflows/build-test-ubuntu-core-custom_types.yml
index 447a28627..5abe34e11 100644
--- a/.github/workflows/build-test-ubuntu-core-custom_types.yml
+++ b/.github/workflows/build-test-ubuntu-core-custom_types.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test core-custom_types code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/custom_types/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/custom_types/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-daemon.yml b/.github/workflows/build-test-ubuntu-core-daemon.yml
index 1992c859f..1141c268d 100644
--- a/.github/workflows/build-test-ubuntu-core-daemon.yml
+++ b/.github/workflows/build-test-ubuntu-core-daemon.yml
@@ -96,7 +96,7 @@ jobs:
     - name: Test core-daemon code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/daemon/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/daemon/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml b/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
index a2295de7e..2873ca064 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-full_node-full_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/full_node/full_sync/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/full_sync/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-full_node-stores.yml b/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
index fbcf34703..08d4348bf 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-full_node-stores code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/full_node/stores/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/stores/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-full_node.yml b/.github/workflows/build-test-ubuntu-core-full_node.yml
index 97208996a..5258828a6 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-full_node code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/full_node/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-server.yml b/.github/workflows/build-test-ubuntu-core-server.yml
index c96f2e13f..a996862f5 100644
--- a/.github/workflows/build-test-ubuntu-core-server.yml
+++ b/.github/workflows/build-test-ubuntu-core-server.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-server code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/server/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/server/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-ssl.yml b/.github/workflows/build-test-ubuntu-core-ssl.yml
index 0edc22b10..ea6e3f19e 100644
--- a/.github/workflows/build-test-ubuntu-core-ssl.yml
+++ b/.github/workflows/build-test-ubuntu-core-ssl.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-ssl code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/ssl/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/ssl/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-util.yml b/.github/workflows/build-test-ubuntu-core-util.yml
index 2e5c699cb..b2bc91886 100644
--- a/.github/workflows/build-test-ubuntu-core-util.yml
+++ b/.github/workflows/build-test-ubuntu-core-util.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-util code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/util/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/util/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core.yml b/.github/workflows/build-test-ubuntu-core.yml
index ed717b529..e45dcea4c 100644
--- a/.github/workflows/build-test-ubuntu-core.yml
+++ b/.github/workflows/build-test-ubuntu-core.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/core/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-farmer_harvester.yml b/.github/workflows/build-test-ubuntu-farmer_harvester.yml
index 03a305023..de87b70fb 100644
--- a/.github/workflows/build-test-ubuntu-farmer_harvester.yml
+++ b/.github/workflows/build-test-ubuntu-farmer_harvester.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test farmer_harvester code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/farmer_harvester/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/farmer_harvester/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-generator.yml b/.github/workflows/build-test-ubuntu-generator.yml
index 3f928e2c0..a8ac14944 100644
--- a/.github/workflows/build-test-ubuntu-generator.yml
+++ b/.github/workflows/build-test-ubuntu-generator.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test generator code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/generator/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/generator/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-plotting.yml b/.github/workflows/build-test-ubuntu-plotting.yml
index 882d0b0c1..974aff32b 100644
--- a/.github/workflows/build-test-ubuntu-plotting.yml
+++ b/.github/workflows/build-test-ubuntu-plotting.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test plotting code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/plotting/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/plotting/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-pools.yml b/.github/workflows/build-test-ubuntu-pools.yml
index d2671e3a1..7e4a705b5 100644
--- a/.github/workflows/build-test-ubuntu-pools.yml
+++ b/.github/workflows/build-test-ubuntu-pools.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test pools code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/pools/test_*.py --durations=10  -n 2 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/pools/test_*.py --durations=10  -n 2 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-simulation.yml b/.github/workflows/build-test-ubuntu-simulation.yml
index 06435f947..60c7de4b1 100644
--- a/.github/workflows/build-test-ubuntu-simulation.yml
+++ b/.github/workflows/build-test-ubuntu-simulation.yml
@@ -96,7 +96,7 @@ jobs:
     - name: Test simulation code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/simulation/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/simulation/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-tools.yml b/.github/workflows/build-test-ubuntu-tools.yml
index 97877660b..f8b84c1d9 100644
--- a/.github/workflows/build-test-ubuntu-tools.yml
+++ b/.github/workflows/build-test-ubuntu-tools.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test tools code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/tools/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/tools/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-util.yml b/.github/workflows/build-test-ubuntu-util.yml
index 1d0567e62..44fb561fa 100644
--- a/.github/workflows/build-test-ubuntu-util.yml
+++ b/.github/workflows/build-test-ubuntu-util.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test util code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/util/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/util/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
index af979fc0f..f17cdd36c 100644
--- a/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet-cat_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/cat_wallet/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/cat_wallet/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
index 06bf1ad15..2dbf05eb7 100644
--- a/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test wallet-did_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/did_wallet/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/did_wallet/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
index c791e3f32..c85ddec93 100644
--- a/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test wallet-rl_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/rl_wallet/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/rl_wallet/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-rpc.yml b/.github/workflows/build-test-ubuntu-wallet-rpc.yml
index bdeb794df..f417f1ce9 100644
--- a/.github/workflows/build-test-ubuntu-wallet-rpc.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-rpc.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet-rpc code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/rpc/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/rpc/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml b/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
index 7a9585c71..785d5fa81 100644
--- a/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet-simple_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/simple_sync/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/simple_sync/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-sync.yml b/.github/workflows/build-test-ubuntu-wallet-sync.yml
index ceb86d8b4..15eeacf1f 100644
--- a/.github/workflows/build-test-ubuntu-wallet-sync.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-sync.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet-sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/sync/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/sync/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet.yml b/.github/workflows/build-test-ubuntu-wallet.yml
index 0e88ee66d..dd5a55b60 100644
--- a/.github/workflows/build-test-ubuntu-wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/wallet/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-weight_proof.yml b/.github/workflows/build-test-ubuntu-weight_proof.yml
index 041aaef86..9a8044617 100644
--- a/.github/workflows/build-test-ubuntu-weight_proof.yml
+++ b/.github/workflows/build-test-ubuntu-weight_proof.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test weight_proof code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/weight_proof/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/weight_proof/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
diff --git a/tests/runner_templates/build-test-macos b/tests/runner_templates/build-test-macos
index 536ab47fc..255b2b8d8 100644
--- a/tests/runner_templates/build-test-macos
+++ b/tests/runner_templates/build-test-macos
@@ -79,7 +79,7 @@ INSTALL_TIMELORD
     - name: Test TEST_NAME code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test TEST_DIR --durations=10 PYTEST_PARALLEL_ARGS -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest TEST_DIR --durations=10 PYTEST_PARALLEL_ARGS -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/tests/runner_templates/build-test-ubuntu b/tests/runner_templates/build-test-ubuntu
index bc587a89a..9a765ac43 100644
--- a/tests/runner_templates/build-test-ubuntu
+++ b/tests/runner_templates/build-test-ubuntu
@@ -78,7 +78,7 @@ INSTALL_TIMELORD
     - name: Test TEST_NAME code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test TEST_DIR --durations=10 PYTEST_PARALLEL_ARGS -m "not benchmark" DISABLE_PYTEST_MONITOR
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest TEST_DIR --durations=10 PYTEST_PARALLEL_ARGS -m "not benchmark" DISABLE_PYTEST_MONITOR
 
     - name: Process coverage data
       run: |
-- 
2.34.1


From ca4881ff3e0fd86c79b9ea31e8347f6bf1663d4f Mon Sep 17 00:00:00 2001
From: Jack Nelson <jack@jacknelson.xyz>
Date: Wed, 20 Apr 2022 14:12:00 -0400
Subject: [PATCH 12/77] Fix incorrect return in "rollback_to_block" (#10954)

* Add comments and fix a coin subscription bug

* Updated rollback test

* simplify test

* expand test

Co-authored-by: Mariano Sorgente <sorgente711@gmail.com>
---
 chia/full_node/coin_store.py                  |  6 +-
 .../core/full_node/stores/test_coin_store.py  | 76 +++++++++++++------
 2 files changed, 58 insertions(+), 24 deletions(-)

diff --git a/chia/full_node/coin_store.py b/chia/full_node/coin_store.py
index 9f24e68e4..0013e9df0 100644
--- a/chia/full_node/coin_store.py
+++ b/chia/full_node/coin_store.py
@@ -428,6 +428,7 @@ class CoinStore:
             self.coin_record_cache.remove(coin_name)
 
         coin_changes: Dict[bytes32, CoinRecord] = {}
+        # Add coins that are confirmed in the reverted blocks to the list of updated coins.
         async with self.db_wrapper.write_db() as conn:
             async with conn.execute(
                 "SELECT confirmed_index, spent_index, coinbase, puzzle_hash, "
@@ -439,12 +440,13 @@ class CoinStore:
                     record = CoinRecord(coin, uint32(0), row[1], row[2], uint64(0))
                     coin_changes[record.name] = record
 
-            # Delete from storage
+            # Delete reverted blocks from storage
             await conn.execute("DELETE FROM coin_record WHERE confirmed_index>?", (block_index,))
 
+            # Add coins that are confirmed in the reverted blocks to the list of changed coins.
             async with conn.execute(
                 "SELECT confirmed_index, spent_index, coinbase, puzzle_hash, "
-                "coin_parent, amount, timestamp FROM coin_record WHERE confirmed_index>?",
+                "coin_parent, amount, timestamp FROM coin_record WHERE spent_index>?",
                 (block_index,),
             ) as cursor:
                 for row in await cursor.fetchall():
diff --git a/tests/core/full_node/stores/test_coin_store.py b/tests/core/full_node/stores/test_coin_store.py
index 169ce6621..47c27bae6 100644
--- a/tests/core/full_node/stores/test_coin_store.py
+++ b/tests/core/full_node/stores/test_coin_store.py
@@ -23,7 +23,6 @@ from tests.setup_nodes import test_constants
 from chia.types.blockchain_format.sized_bytes import bytes32
 from tests.util.db_connection import DBConnection
 
-
 constants = test_constants
 
 WALLET_A = WalletTool(constants)
@@ -238,36 +237,69 @@ class TestCoinStoreWithBlocks:
         async with DBConnection(db_version) as db_wrapper:
             coin_store = await CoinStore.create(db_wrapper, cache_size=uint32(cache_size))
 
-            records: List[CoinRecord] = []
+            selected_coin: Optional[CoinRecord] = None
+            all_coins: List[Coin] = []
 
             for block in blocks:
+                all_coins += list(block.get_included_reward_coins())
                 if block.is_transaction_block():
                     removals: List[bytes32] = []
                     additions: List[Coin] = []
+                    assert block.foliage_transaction_block is not None
+                    await coin_store.new_block(
+                        block.height,
+                        block.foliage_transaction_block.timestamp,
+                        block.get_included_reward_coins(),
+                        additions,
+                        removals,
+                    )
+                    coins = list(block.get_included_reward_coins())
+                    records: List[CoinRecord] = [await coin_store.get_coin_record(coin.name()) for coin in coins]
+
+                    spend_selected_coin = selected_coin is not None
+                    if block.height != 0 and selected_coin is None:
+                        # Select the first CoinRecord which will be spent at the next transaction block.
+                        selected_coin = records[0]
+                        await coin_store._set_spent([r.name for r in records[1:]], block.height)
+                    else:
+                        await coin_store._set_spent([r.name for r in records], block.height)
 
-                    if block.is_transaction_block():
-                        assert block.foliage_transaction_block is not None
-                        await coin_store.new_block(
-                            block.height,
-                            block.foliage_transaction_block.timestamp,
-                            block.get_included_reward_coins(),
-                            additions,
-                            removals,
-                        )
-
-                    coins = block.get_included_reward_coins()
-                    records = [await coin_store.get_coin_record(coin.name()) for coin in coins]
-
-                    await coin_store._set_spent([r.name for r in records], block.height)
+                    if spend_selected_coin:
+                        assert selected_coin is not None
+                        await coin_store._set_spent([selected_coin.name], block.height)
 
-                    records = [await coin_store.get_coin_record(coin.name()) for coin in coins]
+                    records = [await coin_store.get_coin_record(coin.name()) for coin in coins]  # update coin records
                     for record in records:
                         assert record is not None
-                        assert record.spent
-                        assert record.spent_block_index == block.height
+                        if (
+                            selected_coin is not None
+                            and selected_coin.name == record.name
+                            and not selected_coin.confirmed_block_index < block.height
+                        ):
+                            assert not record.spent
+                        else:
+                            assert record.spent
+                            assert record.spent_block_index == block.height
+
+                    if spend_selected_coin:
+                        break
 
-            reorg_index = 8
-            await coin_store.rollback_to_block(reorg_index)
+            assert selected_coin is not None
+            reorg_index = selected_coin.confirmed_block_index
+
+            # Get all CoinRecords.
+            all_records: List[CoinRecord] = [await coin_store.get_coin_record(coin.name()) for coin in all_coins]
+
+            # The reorg will revert the creation and spend of many coins. It will also revert the spend (but not the
+            # creation) of the selected coin.
+            changed_records = await coin_store.rollback_to_block(reorg_index)
+            changed_coin_records = [cr.coin for cr in changed_records]
+            assert selected_coin in changed_records
+            for coin_record in all_records:
+                if coin_record.confirmed_block_index > reorg_index:
+                    assert coin_record.coin in changed_coin_records
+                if coin_record.spent_block_index > reorg_index:
+                    assert coin_record.coin in changed_coin_records
 
             for block in blocks:
                 if block.is_transaction_block():
@@ -277,7 +309,7 @@ class TestCoinStoreWithBlocks:
                     if block.height <= reorg_index:
                         for record in records:
                             assert record is not None
-                            assert record.spent
+                            assert record.spent == (record.name != selected_coin.name)
                     else:
                         for record in records:
                             assert record is None
-- 
2.34.1


From 6287c839286763e948ba2538a091ab818cd6150f Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 20 Apr 2022 11:12:32 -0700
Subject: [PATCH 13/77] Correct wallet CLI sent/received indication (#11006)

* Correct wallet CLI sent/received indication

* extract dict to reusable global scope, plus a function
---
 chia/cmds/wallet_funcs.py | 18 +++++++++++++++++-
 1 file changed, 17 insertions(+), 1 deletion(-)

diff --git a/chia/cmds/wallet_funcs.py b/chia/cmds/wallet_funcs.py
index 5f5effbad..ff6bfb5d6 100644
--- a/chia/cmds/wallet_funcs.py
+++ b/chia/cmds/wallet_funcs.py
@@ -22,11 +22,26 @@ from chia.wallet.trade_record import TradeRecord
 from chia.wallet.trading.offer import Offer
 from chia.wallet.trading.trade_status import TradeStatus
 from chia.wallet.transaction_record import TransactionRecord
+from chia.wallet.util.transaction_type import TransactionType
 from chia.wallet.util.wallet_types import WalletType
 
 CATNameResolver = Callable[[bytes32], Awaitable[Optional[Tuple[Optional[uint32], str]]]]
 
 
+transaction_type_descriptions = {
+    TransactionType.INCOMING_TX: "received",
+    TransactionType.OUTGOING_TX: "sent",
+    TransactionType.COINBASE_REWARD: "rewarded",
+    TransactionType.FEE_REWARD: "rewarded",
+    TransactionType.INCOMING_TRADE: "received in trade",
+    TransactionType.OUTGOING_TRADE: "sent in trade",
+}
+
+
+def transaction_description_from_type(tx: TransactionRecord) -> str:
+    return transaction_type_descriptions.get(TransactionType(tx.type), "(unknown reason)")
+
+
 def print_transaction(tx: TransactionRecord, verbose: bool, name, address_prefix: str, mojo_per_unit: int) -> None:
     if verbose:
         print(tx)
@@ -35,7 +50,8 @@ def print_transaction(tx: TransactionRecord, verbose: bool, name, address_prefix
         to_address = encode_puzzle_hash(tx.to_puzzle_hash, address_prefix)
         print(f"Transaction {tx.name}")
         print(f"Status: {'Confirmed' if tx.confirmed else ('In mempool' if tx.is_in_mempool() else 'Pending')}")
-        print(f"Amount {'sent' if tx.sent else 'received'}: {chia_amount} {name}")
+        description = transaction_description_from_type(tx)
+        print(f"Amount {description}: {chia_amount} {name}")
         print(f"To address: {to_address}")
         print("Created at:", datetime.fromtimestamp(tx.created_at_time).strftime("%Y-%m-%d %H:%M:%S"))
         print("")
-- 
2.34.1


From f27cba07b0f1c6f21bab7c5cfda0cfdb90b71182 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:13:07 +0200
Subject: [PATCH 14/77] farmer: Introduce
 `UPDATE_POOL_INFO_FAILURE_RETRY_INTERVAL` (#11076)

Retry to load the pool info with a 2 minutes interval if it failed.
---
 chia/farmer/farmer.py | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/chia/farmer/farmer.py b/chia/farmer/farmer.py
index f7e50e9ed..ab3a24f46 100644
--- a/chia/farmer/farmer.py
+++ b/chia/farmer/farmer.py
@@ -60,6 +60,7 @@ singleton_mod_hash = SINGLETON_MOD.get_tree_hash()
 log = logging.getLogger(__name__)
 
 UPDATE_POOL_INFO_INTERVAL: int = 3600
+UPDATE_POOL_INFO_FAILURE_RETRY_INTERVAL: int = 120
 UPDATE_POOL_FARMER_INFO_INTERVAL: int = 300
 
 """
@@ -468,6 +469,8 @@ class Farmer:
                         # Only update the first time from GET /pool_info, gets updated from GET /farmer later
                         if pool_state["current_difficulty"] is None:
                             pool_state["current_difficulty"] = pool_info["minimum_difficulty"]
+                    else:
+                        pool_state["next_pool_info_update"] = time.time() + UPDATE_POOL_INFO_FAILURE_RETRY_INTERVAL
 
                 if time.time() >= pool_state["next_farmer_update"]:
                     pool_state["next_farmer_update"] = time.time() + UPDATE_POOL_FARMER_INFO_INTERVAL
-- 
2.34.1


From a0c3c31125bd52c0d7bd4d7dd6db97202bea9c34 Mon Sep 17 00:00:00 2001
From: Earle Lowe <30607889+emlowe@users.noreply.github.com>
Date: Wed, 20 Apr 2022 11:13:26 -0700
Subject: [PATCH 15/77] Expose transaction sorting options to CLI (#11090)

---
 chia/cmds/wallet.py       | 33 ++++++++++++++++++++++++++++++++-
 chia/cmds/wallet_funcs.py |  6 +++++-
 2 files changed, 37 insertions(+), 2 deletions(-)

diff --git a/chia/cmds/wallet.py b/chia/cmds/wallet.py
index b2e939540..9486e3947 100644
--- a/chia/cmds/wallet.py
+++ b/chia/cmds/wallet.py
@@ -4,6 +4,7 @@ from typing import Any, Dict, Optional, Tuple
 import click
 
 from chia.wallet.util.wallet_types import WalletType
+from chia.wallet.transaction_sorting import SortKey
 
 
 @click.group("wallet", short_help="Manage your wallet")
@@ -65,6 +66,25 @@ def get_transaction_cmd(wallet_rpc_port: Optional[int], fingerprint: int, id: in
     default=None,
     help="Prompt for each page of data.  Defaults to true for interactive consoles, otherwise false.",
 )
+@click.option(
+    "--sort-by-height",
+    "sort_key",
+    flag_value=SortKey.CONFIRMED_AT_HEIGHT,
+    help="Sort transactions by height",
+)
+@click.option(
+    "--sort-by-relevance",
+    "sort_key",
+    flag_value=SortKey.RELEVANCE,
+    default=True,
+    help="Sort transactions by {confirmed, height, time}",
+)
+@click.option(
+    "--reverse",
+    is_flag=True,
+    default=False,
+    help="Reverse the transaction ordering",
+)
 def get_transactions_cmd(
     wallet_rpc_port: Optional[int],
     fingerprint: int,
@@ -73,8 +93,19 @@ def get_transactions_cmd(
     limit: int,
     verbose: bool,
     paginate: Optional[bool],
+    sort_key: SortKey,
+    reverse: bool,
 ) -> None:
-    extra_params = {"id": id, "verbose": verbose, "offset": offset, "paginate": paginate, "limit": limit}
+    extra_params = {
+        "id": id,
+        "verbose": verbose,
+        "offset": offset,
+        "paginate": paginate,
+        "limit": limit,
+        "sort_key": sort_key,
+        "reverse": reverse,
+    }
+
     import asyncio
     from .wallet_funcs import execute_with_wallet, get_transactions
 
diff --git a/chia/cmds/wallet_funcs.py b/chia/cmds/wallet_funcs.py
index ff6bfb5d6..c6b074e48 100644
--- a/chia/cmds/wallet_funcs.py
+++ b/chia/cmds/wallet_funcs.py
@@ -131,9 +131,13 @@ async def get_transactions(args: dict, wallet_client: WalletRpcClient, fingerpri
         paginate = sys.stdout.isatty()
     offset = args["offset"]
     limit = args["limit"]
+    sort_key = args["sort_key"]
+    reverse = args["reverse"]
+
     txs: List[TransactionRecord] = await wallet_client.get_transactions(
-        wallet_id, start=offset, end=(offset + limit), reverse=True
+        wallet_id, start=offset, end=(offset + limit), sort_key=sort_key, reverse=reverse
     )
+
     config = load_config(DEFAULT_ROOT_PATH, "config.yaml", SERVICE_NAME)
     address_prefix = config["network_overrides"]["config"][config["selected_network"]]["address_prefix"]
     if len(txs) == 0:
-- 
2.34.1


From f7e9e83e694c349610c4cc75956af5b6ce47906b Mon Sep 17 00:00:00 2001
From: Mariano Sorgente <3069354+mariano54@users.noreply.github.com>
Date: Wed, 20 Apr 2022 14:13:55 -0400
Subject: [PATCH 16/77] Optimize test_wallet_sync (#11103)

* Optimize test_wallet_sync

* Update tests/wallet/sync/test_wallet_sync.py

Co-authored-by: Kyle Altendorf <sda@fstab.net>

* Fix test

Co-authored-by: Kyle Altendorf <sda@fstab.net>
---
 tests/wallet/sync/test_wallet_sync.py | 310 +++++++++++++-------------
 1 file changed, 157 insertions(+), 153 deletions(-)

diff --git a/tests/wallet/sync/test_wallet_sync.py b/tests/wallet/sync/test_wallet_sync.py
index c98f78354..43e7fcd4b 100644
--- a/tests/wallet/sync/test_wallet_sync.py
+++ b/tests/wallet/sync/test_wallet_sync.py
@@ -27,27 +27,26 @@ log = getLogger(__name__)
 
 
 class TestWalletSync:
-    @pytest.mark.parametrize(
-        "trusted",
-        [True, False],
-    )
     @pytest.mark.asyncio
-    async def test_basic_sync_wallet(self, bt, wallet_node, default_400_blocks, trusted, self_hostname):
+    async def test_basic_sync_wallet(self, bt, two_wallet_nodes, default_400_blocks, self_hostname):
+        full_nodes, wallets = two_wallet_nodes
+        full_node_api = full_nodes[0]
+        full_node_server = full_node_api.full_node.server
+
+        # Trusted node sync
+        wallets[0][0].config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
 
-        full_node_api, wallet_node, full_node_server, wallet_server = wallet_node
+        # Untrusted node sync
+        wallets[1][0].config["trusted_peers"] = {}
 
         for block in default_400_blocks:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
 
-        if trusted:
-            wallet_node.config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
-        else:
-            wallet_node.config["trusted_peers"] = {}
-        await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
+        for wallet_node, wallet_server in wallets:
+            await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
 
-        # The second node should eventually catch up to the first one, and have the
-        # same tip at height num_blocks - 1.
-        await time_out_assert(100, wallet_height_at_least, True, wallet_node, len(default_400_blocks) - 1)
+        for wallet_node, wallet_server in wallets:
+            await time_out_assert(100, wallet_height_at_least, True, wallet_node, len(default_400_blocks) - 1)
 
         # Tests a reorg with the wallet
         num_blocks = 30
@@ -55,181 +54,185 @@ class TestWalletSync:
         for i in range(1, len(blocks_reorg)):
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(blocks_reorg[i]))
 
-        await disconnect_all_and_reconnect(wallet_server, full_node_server, self_hostname)
+        for wallet_node, wallet_server in wallets:
+            await disconnect_all_and_reconnect(wallet_server, full_node_server, self_hostname)
 
-        await time_out_assert(
-            100, wallet_height_at_least, True, wallet_node, len(default_400_blocks) + num_blocks - 5 - 1
-        )
+        for wallet_node, wallet_server in wallets:
+            await time_out_assert(
+                100, wallet_height_at_least, True, wallet_node, len(default_400_blocks) + num_blocks - 5 - 1
+            )
 
-    @pytest.mark.parametrize(
-        "trusted",
-        [True, False],
-    )
     @pytest.mark.asyncio
-    async def test_almost_recent(self, bt, wallet_node, default_1000_blocks, trusted, self_hostname):
+    async def test_almost_recent(self, bt, two_wallet_nodes, default_400_blocks, self_hostname):
         # Tests the edge case of receiving funds right before the recent blocks  in weight proof
-        full_node_api, wallet_node, full_node_server, wallet_server = wallet_node
+        full_nodes, wallets = two_wallet_nodes
+        full_node_api = full_nodes[0]
+        full_node_server = full_node_api.full_node.server
 
-        for block in default_1000_blocks:
+        # Trusted node sync
+        wallets[0][0].config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
+
+        # Untrusted node sync
+        wallets[1][0].config["trusted_peers"] = {}
+
+        base_num_blocks = 400
+        for block in default_400_blocks:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
 
-        wallet = wallet_node.wallet_state_manager.main_wallet
-        ph = await wallet.get_new_puzzlehash()
+        all_blocks = default_400_blocks
+        both_phs = []
+        for wallet_node, wallet_server in wallets:
+            wallet = wallet_node.wallet_state_manager.main_wallet
+            both_phs.append(await wallet.get_new_puzzlehash())
 
-        if trusted:
-            wallet_node.config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
-        else:
-            wallet_node.config["trusted_peers"] = {}
+        for i in range(20):
+            # Tests a reorg with the wallet
+            ph = both_phs[i % 2]
+            all_blocks = bt.get_consecutive_blocks(1, block_list_input=all_blocks, pool_reward_puzzle_hash=ph)
+            await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(all_blocks[-1]))
 
-        # Tests a reorg with the wallet
-        num_blocks = 20
         new_blocks = bt.get_consecutive_blocks(
-            num_blocks, block_list_input=default_1000_blocks, pool_reward_puzzle_hash=ph
+            test_constants.WEIGHT_PROOF_RECENT_BLOCKS + 10, block_list_input=all_blocks
         )
-        for i in range(1000, len(new_blocks)):
+        for i in range(base_num_blocks + 20, len(new_blocks)):
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(new_blocks[i]))
 
-        new_blocks = bt.get_consecutive_blocks(
-            test_constants.WEIGHT_PROOF_RECENT_BLOCKS + 10, block_list_input=new_blocks
-        )
-        for i in range(1020, len(new_blocks)):
-            await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(new_blocks[i]))
+        for wallet_node, wallet_server in wallets:
+            wallet = wallet_node.wallet_state_manager.main_wallet
+            await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
+            await time_out_assert(30, wallet.get_confirmed_balance, 10 * calculate_pool_reward(uint32(1000)))
 
-        await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
+    @pytest.mark.asyncio
+    async def test_backtrack_sync_wallet(self, two_wallet_nodes, default_400_blocks, self_hostname):
+        full_nodes, wallets = two_wallet_nodes
+        full_node_api = full_nodes[0]
+        full_node_server = full_node_api.full_node.server
 
-        await time_out_assert(30, wallet.get_confirmed_balance, 20 * calculate_pool_reward(uint32(1000)))
+        # Trusted node sync
+        wallets[0][0].config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
+
+        # Untrusted node sync
+        wallets[1][0].config["trusted_peers"] = {}
 
-    @pytest.mark.parametrize(
-        "trusted",
-        [True, False],
-    )
-    @pytest.mark.asyncio
-    async def test_backtrack_sync_wallet(self, wallet_node, default_400_blocks, trusted, self_hostname):
-        full_node_api, wallet_node, full_node_server, wallet_server = wallet_node
         for block in default_400_blocks[:20]:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
 
-        if trusted:
-            wallet_node.config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
-        else:
-            wallet_node.config["trusted_peers"] = {}
-        await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
+        for wallet_node, wallet_server in wallets:
+            await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
 
-        # The second node should eventually catch up to the first one, and have the
-        # same tip at height num_blocks - 1.
-        await time_out_assert(100, wallet_height_at_least, True, wallet_node, 19)
+        for wallet_node, wallet_server in wallets:
+            await time_out_assert(100, wallet_height_at_least, True, wallet_node, 19)
 
     # Tests a reorg with the wallet
-    @pytest.mark.parametrize(
-        "trusted",
-        [True, False],
-    )
     @pytest.mark.asyncio
-    async def test_short_batch_sync_wallet(self, wallet_node, default_400_blocks, trusted, self_hostname):
-        full_node_api, wallet_node, full_node_server, wallet_server = wallet_node
+    async def test_short_batch_sync_wallet(self, two_wallet_nodes, default_400_blocks, self_hostname):
+        full_nodes, wallets = two_wallet_nodes
+        full_node_api = full_nodes[0]
+        full_node_server = full_node_api.full_node.server
+
+        # Trusted node sync
+        wallets[0][0].config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
+
+        # Untrusted node sync
+        wallets[1][0].config["trusted_peers"] = {}
 
         for block in default_400_blocks[:200]:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
-        if trusted:
-            wallet_node.config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
-        else:
-            wallet_node.config["trusted_peers"] = {}
 
-        await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
+        for wallet_node, wallet_server in wallets:
+            await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
 
-        # The second node should eventually catch up to the first one, and have the
-        # same tip at height num_blocks - 1.
-        await time_out_assert(100, wallet_height_at_least, True, wallet_node, 199)
-        # Tests a reorg with the wallet
+        for wallet_node, wallet_server in wallets:
+            await time_out_assert(100, wallet_height_at_least, True, wallet_node, 199)
 
-    @pytest.mark.parametrize(
-        "trusted",
-        [True, False],
-    )
     @pytest.mark.asyncio
-    async def test_long_sync_wallet(
-        self, bt, wallet_node, default_1000_blocks, default_400_blocks, trusted, self_hostname
-    ):
+    async def test_long_sync_wallet(self, bt, two_wallet_nodes, default_1000_blocks, default_400_blocks, self_hostname):
+        full_nodes, wallets = two_wallet_nodes
+        full_node_api = full_nodes[0]
+        full_node_server = full_node_api.full_node.server
 
-        full_node_api, wallet_node, full_node_server, wallet_server = wallet_node
+        # Trusted node sync
+        wallets[0][0].config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
+
+        # Untrusted node sync
+        wallets[1][0].config["trusted_peers"] = {}
 
         for block in default_400_blocks:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
-        if trusted:
-            wallet_node.config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
-        else:
-            wallet_node.config["trusted_peers"] = {}
 
-        await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
+        for wallet_node, wallet_server in wallets:
+            await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
 
-        # The second node should eventually catch up to the first one, and have the
-        # same tip at height num_blocks - 1.
-        await time_out_assert(600, wallet_height_at_least, True, wallet_node, len(default_400_blocks) - 1)
+        for wallet_node, wallet_server in wallets:
+            await time_out_assert(600, wallet_height_at_least, True, wallet_node, len(default_400_blocks) - 1)
 
         # Tests a long reorg
         for block in default_1000_blocks:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
 
-        await disconnect_all_and_reconnect(wallet_server, full_node_server, self_hostname)
+        for wallet_node, wallet_server in wallets:
+            await disconnect_all_and_reconnect(wallet_server, full_node_server, self_hostname)
 
-        log.info(f"wallet node height is {wallet_node.wallet_state_manager.blockchain.get_peak_height()}")
-        await time_out_assert(600, wallet_height_at_least, True, wallet_node, len(default_1000_blocks) - 1)
+            log.info(f"wallet node height is {wallet_node.wallet_state_manager.blockchain.get_peak_height()}")
+            await time_out_assert(600, wallet_height_at_least, True, wallet_node, len(default_1000_blocks) - 1)
 
-        await disconnect_all_and_reconnect(wallet_server, full_node_server, self_hostname)
+            await disconnect_all_and_reconnect(wallet_server, full_node_server, self_hostname)
 
         # Tests a short reorg
         num_blocks = 30
         blocks_reorg = bt.get_consecutive_blocks(num_blocks, block_list_input=default_1000_blocks[:-5])
 
-        for i in range(1, len(blocks_reorg)):
+        for i in range(len(blocks_reorg) - num_blocks - 10, len(blocks_reorg)):
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(blocks_reorg[i]))
 
-        await time_out_assert(
-            600, wallet_height_at_least, True, wallet_node, len(default_1000_blocks) + num_blocks - 5 - 1
-        )
+        for wallet_node, wallet_server in wallets:
+            await time_out_assert(
+                600, wallet_height_at_least, True, wallet_node, len(default_1000_blocks) + num_blocks - 5 - 1
+            )
 
-    @pytest.mark.parametrize(
-        "trusted",
-        [True, False],
-    )
     @pytest.mark.asyncio
-    async def test_wallet_reorg_sync(self, bt, wallet_node_simulator, default_400_blocks, trusted, self_hostname):
+    async def test_wallet_reorg_sync(self, bt, two_wallet_nodes, default_400_blocks, self_hostname):
         num_blocks = 5
-        full_nodes, wallets = wallet_node_simulator
+        full_nodes, wallets = two_wallet_nodes
         full_node_api = full_nodes[0]
-        wallet_node, server_2 = wallets[0]
-        fn_server = full_node_api.full_node.server
-        wsm: WalletStateManager = wallet_node.wallet_state_manager
-        wallet = wsm.main_wallet
-        ph = await wallet.get_new_puzzlehash()
+        full_node_server = full_node_api.full_node.server
+
+        # Trusted node sync
+        wallets[0][0].config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
 
-        if trusted:
-            wallet_node.config["trusted_peers"] = {fn_server.node_id.hex(): fn_server.node_id.hex()}
-        else:
-            wallet_node.config["trusted_peers"] = {}
+        # Untrusted node sync
+        wallets[1][0].config["trusted_peers"] = {}
 
-        await server_2.start_client(PeerInfo(self_hostname, uint16(fn_server._port)), None)
+        phs = []
+        for wallet_node, wallet_server in wallets:
+            wallet = wallet_node.wallet_state_manager.main_wallet
+            phs.append(await wallet.get_new_puzzlehash())
+            await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
 
         # Insert 400 blocks
         for block in default_400_blocks:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
 
         # Farm few more with reward
+        for i in range(0, num_blocks - 1):
+            await full_node_api.farm_new_transaction_block(FarmNewBlockProtocol(phs[0]))
+
         for i in range(0, num_blocks):
-            await full_node_api.farm_new_transaction_block(FarmNewBlockProtocol(ph))
+            await full_node_api.farm_new_transaction_block(FarmNewBlockProtocol(phs[1]))
 
         # Confirm we have the funds
         funds = sum(
             [calculate_pool_reward(uint32(i)) + calculate_base_farmer_reward(uint32(i)) for i in range(1, num_blocks)]
         )
 
-        await time_out_assert(5, wallet.get_confirmed_balance, funds)
-
-        async def get_tx_count(wallet_id):
+        async def get_tx_count(wsm, wallet_id):
             txs = await wsm.get_all_transactions(wallet_id)
             return len(txs)
 
-        await time_out_assert(5, get_tx_count, 2 * (num_blocks - 1), 1)
+        for wallet_node, wallet_server in wallets:
+            wallet = wallet_node.wallet_state_manager.main_wallet
+            await time_out_assert(5, wallet.get_confirmed_balance, funds)
+            await time_out_assert(5, get_tx_count, 2 * (num_blocks - 1), wallet_node.wallet_state_manager, 1)
 
         # Reorg blocks that carry reward
         num_blocks = 30
@@ -238,31 +241,25 @@ class TestWalletSync:
         for block in blocks_reorg[-30:]:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
 
-        await time_out_assert(5, get_tx_count, 0, 1)
-        await time_out_assert(5, wallet.get_confirmed_balance, 0)
+        for wallet_node, wallet_server in wallets:
+            wallet = wallet_node.wallet_state_manager.main_wallet
+            await time_out_assert(5, get_tx_count, 0, wallet_node.wallet_state_manager, 1)
+            await time_out_assert(5, wallet.get_confirmed_balance, 0)
 
-    @pytest.mark.parametrize(
-        "trusted",
-        [False],
-    )
     @pytest.mark.asyncio
-    async def test_wallet_reorg_get_coinbase(
-        self, bt, wallet_node_simulator, default_400_blocks, trusted, self_hostname
-    ):
-        full_nodes, wallets = wallet_node_simulator
+    async def test_wallet_reorg_get_coinbase(self, bt, two_wallet_nodes, default_400_blocks, self_hostname):
+        full_nodes, wallets = two_wallet_nodes
         full_node_api = full_nodes[0]
-        wallet_node, server_2 = wallets[0]
-        fn_server = full_node_api.full_node.server
-        wsm = wallet_node.wallet_state_manager
-        wallet = wallet_node.wallet_state_manager.main_wallet
-        ph = await wallet.get_new_puzzlehash()
+        full_node_server = full_node_api.full_node.server
 
-        if trusted:
-            wallet_node.config["trusted_peers"] = {fn_server.node_id.hex(): fn_server.node_id.hex()}
-        else:
-            wallet_node.config["trusted_peers"] = {}
+        # Trusted node sync
+        wallets[0][0].config["trusted_peers"] = {full_node_server.node_id.hex(): full_node_server.node_id.hex()}
 
-        await server_2.start_client(PeerInfo(self_hostname, uint16(fn_server._port)), None)
+        # Untrusted node sync
+        wallets[1][0].config["trusted_peers"] = {}
+
+        for wallet_node, wallet_server in wallets:
+            await wallet_server.start_client(PeerInfo(self_hostname, uint16(full_node_server._port)), None)
 
         # Insert 400 blocks
         for block in default_400_blocks:
@@ -275,30 +272,37 @@ class TestWalletSync:
         for block in blocks_reorg[:-5]:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
 
-        async def get_tx_count(wallet_id):
+        async def get_tx_count(wsm, wallet_id):
             txs = await wsm.get_all_transactions(wallet_id)
             return len(txs)
 
-        await time_out_assert(10, get_tx_count, 0, 1)
-        await time_out_assert(30, wallet_is_synced, True, wallet_node, full_node_api)
+        for wallet_node, wallet_server in wallets:
+            await time_out_assert(10, get_tx_count, 0, wallet_node.wallet_state_manager, 1)
+            await time_out_assert(30, wallet_is_synced, True, wallet_node, full_node_api)
 
         num_blocks_reorg_1 = 40
-        blocks_reorg_1 = bt.get_consecutive_blocks(
-            1, pool_reward_puzzle_hash=ph, farmer_reward_puzzle_hash=ph, block_list_input=blocks_reorg[:-30]
-        )
-        blocks_reorg_2 = bt.get_consecutive_blocks(num_blocks_reorg_1, block_list_input=blocks_reorg_1)
-
-        for block in blocks_reorg_2[-41:]:
-            await asyncio.sleep(0.4)
+        all_blocks_reorg_2 = blocks_reorg[:-30]
+        for wallet_node, wallet_server in wallets:
+            wallet = wallet_node.wallet_state_manager.main_wallet
+            ph = await wallet.get_new_puzzlehash()
+            all_blocks_reorg_2 = bt.get_consecutive_blocks(
+                1, pool_reward_puzzle_hash=ph, farmer_reward_puzzle_hash=ph, block_list_input=all_blocks_reorg_2
+            )
+        blocks_reorg_2 = bt.get_consecutive_blocks(num_blocks_reorg_1, block_list_input=all_blocks_reorg_2)
+
+        for block in blocks_reorg_2[-44:]:
             await full_node_api.full_node.respond_block(full_node_protocol.RespondBlock(block))
 
-        await disconnect_all_and_reconnect(server_2, fn_server, self_hostname)
+        for wallet_node, wallet_server in wallets:
+            await disconnect_all_and_reconnect(wallet_server, full_node_server, self_hostname)
 
         # Confirm we have the funds
-        funds = calculate_pool_reward(uint32(len(blocks_reorg_1))) + calculate_base_farmer_reward(
-            uint32(len(blocks_reorg_1))
+        funds = calculate_pool_reward(uint32(len(all_blocks_reorg_2))) + calculate_base_farmer_reward(
+            uint32(len(all_blocks_reorg_2))
         )
 
-        await time_out_assert(60, wallet_is_synced, True, wallet_node, full_node_api)
-        await time_out_assert(20, get_tx_count, 2, 1)
-        await time_out_assert(20, wallet.get_confirmed_balance, funds)
+        for wallet_node, wallet_server in wallets:
+            wallet = wallet_node.wallet_state_manager.main_wallet
+            await time_out_assert(60, wallet_is_synced, True, wallet_node, full_node_api)
+            await time_out_assert(20, get_tx_count, 2, wallet_node.wallet_state_manager, 1)
+            await time_out_assert(20, wallet.get_confirmed_balance, funds)
-- 
2.34.1


From 93da3b727b5ee75b73df0966d6c9f4c3be844b67 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 20 Apr 2022 11:14:20 -0700
Subject: [PATCH 17/77] Up Windows installer build timeout to 50 minutes
 (#11107)

Recent runs are mostly low 30s but some are close to 40 and one just timed out.
---
 .github/workflows/build-windows-installer.yml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/.github/workflows/build-windows-installer.yml b/.github/workflows/build-windows-installer.yml
index 22abcf919..5ae996af6 100644
--- a/.github/workflows/build-windows-installer.yml
+++ b/.github/workflows/build-windows-installer.yml
@@ -19,7 +19,7 @@ jobs:
   build:
     name: Windows Installer on Windows 10 and Python 3.9
     runs-on: [windows-2019]
-    timeout-minutes: 40
+    timeout-minutes: 50
 
     steps:
     - name: Checkout Code
-- 
2.34.1


From ab282b528256617defa70b60007e31f0e61e743d Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:14:48 +0200
Subject: [PATCH 18/77] wallet: Drop unused
 `WalletStateManager.get_derivation_index` (#11110)

---
 chia/wallet/wallet_state_manager.py | 10 ----------
 1 file changed, 10 deletions(-)

diff --git a/chia/wallet/wallet_state_manager.py b/chia/wallet/wallet_state_manager.py
index 01282e329..f6a2a037f 100644
--- a/chia/wallet/wallet_state_manager.py
+++ b/chia/wallet/wallet_state_manager.py
@@ -207,16 +207,6 @@ class WalletStateManager:
 
         return self
 
-    def get_derivation_index(self, pubkey: G1Element, max_depth: int = 1000) -> int:
-        for i in range(0, max_depth):
-            derived = self.get_public_key(uint32(i))
-            if derived == pubkey:
-                return i
-            derived = self.get_public_key_unhardened(uint32(i))
-            if derived == pubkey:
-                return i
-        return -1
-
     def get_public_key(self, index: uint32) -> G1Element:
         return master_sk_to_wallet_sk(self.private_key, index).get_g1()
 
-- 
2.34.1


From 5b044ea497735ac3135068df0337ce8cd7331aa6 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 20 Apr 2022 11:16:53 -0700
Subject: [PATCH 19/77] locate pyinstaller in dev deps rather than build
 scripts (#11118)

---
 .github/workflows/build-linux-arm64-installer.yml | 2 +-
 .github/workflows/build-linux-installer-deb.yml   | 2 +-
 .github/workflows/build-linux-installer-rpm.yml   | 2 +-
 .github/workflows/build-macos-installer.yml       | 2 +-
 .github/workflows/build-macos-m1-installer.yml    | 2 +-
 build_scripts/build_linux_deb.sh                  | 1 -
 build_scripts/build_linux_rpm.sh                  | 1 -
 build_scripts/build_macos.sh                      | 1 -
 build_scripts/build_macos_m1.sh                   | 3 ---
 setup.py                                          | 1 +
 10 files changed, 6 insertions(+), 11 deletions(-)

diff --git a/.github/workflows/build-linux-arm64-installer.yml b/.github/workflows/build-linux-arm64-installer.yml
index 57d3275c3..5cb8cf4ca 100644
--- a/.github/workflows/build-linux-arm64-installer.yml
+++ b/.github/workflows/build-linux-arm64-installer.yml
@@ -106,7 +106,7 @@ jobs:
       env:
         INSTALL_PYTHON_VERSION: ${{ matrix.python-version }}
       run: |
-        sh install.sh
+        sh install.sh -d
 
     - name: Build arm64 .deb package
       env:
diff --git a/.github/workflows/build-linux-installer-deb.yml b/.github/workflows/build-linux-installer-deb.yml
index 2efa7e517..43d5fe7e5 100644
--- a/.github/workflows/build-linux-installer-deb.yml
+++ b/.github/workflows/build-linux-installer-deb.yml
@@ -140,7 +140,7 @@ jobs:
       env:
         INSTALL_PYTHON_VERSION: ${{ matrix.python-version }}
       run: |
-        sh install.sh
+        sh install.sh -d
 
     - name: Setup Node 16.x
       uses: actions/setup-node@v3
diff --git a/.github/workflows/build-linux-installer-rpm.yml b/.github/workflows/build-linux-installer-rpm.yml
index 16d8378fb..64309818e 100644
--- a/.github/workflows/build-linux-installer-rpm.yml
+++ b/.github/workflows/build-linux-installer-rpm.yml
@@ -109,7 +109,7 @@ jobs:
       env:
         INSTALL_PYTHON_VERSION: ${{ matrix.python-version }}
       run: |
-        sh install.sh
+        sh install.sh -d
 
     - name: Build .rpm package
       env:
diff --git a/.github/workflows/build-macos-installer.yml b/.github/workflows/build-macos-installer.yml
index e7cd7e639..a2b590b9c 100644
--- a/.github/workflows/build-macos-installer.yml
+++ b/.github/workflows/build-macos-installer.yml
@@ -128,7 +128,7 @@ jobs:
       env:
         INSTALL_PYTHON_VERSION: ${{ matrix.python-version }}
       run: |
-        sh install.sh
+        sh install.sh -d
 
     - name: Setup Node 16.x
       uses: actions/setup-node@v3
diff --git a/.github/workflows/build-macos-m1-installer.yml b/.github/workflows/build-macos-m1-installer.yml
index 92c118120..0f5870ff1 100644
--- a/.github/workflows/build-macos-m1-installer.yml
+++ b/.github/workflows/build-macos-m1-installer.yml
@@ -102,7 +102,7 @@ jobs:
         env:
           INSTALL_PYTHON_VERSION: ${{ matrix.python-version }}
         run: |
-          arch -arm64 sh install.sh
+          arch -arm64 sh install.sh -d
 
       - name: Install node 16.x
         run: |
diff --git a/build_scripts/build_linux_deb.sh b/build_scripts/build_linux_deb.sh
index 628340201..ba74d7b46 100644
--- a/build_scripts/build_linux_deb.sh
+++ b/build_scripts/build_linux_deb.sh
@@ -35,7 +35,6 @@ rm -rf dist
 mkdir dist
 
 echo "Create executables with pyinstaller"
-pip install pyinstaller==4.9
 SPEC_FILE=$(python -c 'import chia; print(chia.PYINSTALLER_SPEC_PATH)')
 pyinstaller --log-level=INFO "$SPEC_FILE"
 LAST_EXIT_CODE=$?
diff --git a/build_scripts/build_linux_rpm.sh b/build_scripts/build_linux_rpm.sh
index 7ec656eee..21db74f43 100644
--- a/build_scripts/build_linux_rpm.sh
+++ b/build_scripts/build_linux_rpm.sh
@@ -35,7 +35,6 @@ rm -rf dist
 mkdir dist
 
 echo "Create executables with pyinstaller"
-pip install pyinstaller==4.9
 SPEC_FILE=$(python -c 'import chia; print(chia.PYINSTALLER_SPEC_PATH)')
 pyinstaller --log-level=INFO "$SPEC_FILE"
 LAST_EXIT_CODE=$?
diff --git a/build_scripts/build_macos.sh b/build_scripts/build_macos.sh
index 2cacc4d9f..35aedaef9 100644
--- a/build_scripts/build_macos.sh
+++ b/build_scripts/build_macos.sh
@@ -22,7 +22,6 @@ sudo rm -rf dist
 mkdir dist
 
 echo "Create executables with pyinstaller"
-pip install pyinstaller==4.9
 SPEC_FILE=$(python -c 'import chia; print(chia.PYINSTALLER_SPEC_PATH)')
 pyinstaller --log-level=INFO "$SPEC_FILE"
 LAST_EXIT_CODE=$?
diff --git a/build_scripts/build_macos_m1.sh b/build_scripts/build_macos_m1.sh
index 45f063373..95582cb9f 100644
--- a/build_scripts/build_macos_m1.sh
+++ b/build_scripts/build_macos_m1.sh
@@ -21,9 +21,6 @@ echo "Create dist/"
 sudo rm -rf dist
 mkdir dist
 
-echo "Install pyinstaller and build bootloaders for M1"
-pip install pyinstaller==4.9
-
 echo "Create executables with pyinstaller"
 SPEC_FILE=$(python -c 'import chia; print(chia.PYINSTALLER_SPEC_PATH)')
 pyinstaller --log-level=INFO "$SPEC_FILE"
diff --git a/setup.py b/setup.py
index 5bd1599eb..2792f953c 100644
--- a/setup.py
+++ b/setup.py
@@ -57,6 +57,7 @@ dev_dependencies = [
     "black==21.12b0",
     "aiohttp_cors",  # For blackd
     "ipython",  # For asyncio debugging
+    "pyinstaller==4.9",
     "types-aiofiles",
     "types-click",
     "types-cryptography",
-- 
2.34.1


From 6c8fa52dafc018371c4847b66094422b7ee5d423 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 20 Apr 2022 11:17:51 -0700
Subject: [PATCH 20/77] remove setting of SCM_VERSION in install-version.py
 (#11119)

---
 build_scripts/installer-version.py | 2 --
 1 file changed, 2 deletions(-)

diff --git a/build_scripts/installer-version.py b/build_scripts/installer-version.py
index d9d71e02e..12e13b0d9 100644
--- a/build_scripts/installer-version.py
+++ b/build_scripts/installer-version.py
@@ -1,4 +1,3 @@
-import os
 import sys
 
 from setuptools_scm import get_version
@@ -10,7 +9,6 @@ def main():
 
     scm_full_version = get_version(root="..", relative_to=__file__)
     # scm_full_version = "1.0.5.dev22"
-    os.environ["SCM_VERSION"] = scm_full_version
 
     left_full_version = scm_full_version.split("+")
     version = left_full_version[0].split(".")
-- 
2.34.1


From 1088801e73b40785e3ba64e82e28bb0c9cbbcd04 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 20 Apr 2022 11:18:42 -0700
Subject: [PATCH 21/77] Remove code related to no-longer-used websockets
 library (#11123)

* Remove logging tweak for no-longer-used websockets library

Follow up after https://github.com/Chia-Network/chia-blockchain/pull/10611.

* Update pylintrc

* Update test_daemon.py
---
 chia/util/chia_logging.py        | 1 -
 pylintrc                         | 1 -
 tests/core/daemon/test_daemon.py | 6 ------
 3 files changed, 8 deletions(-)

diff --git a/chia/util/chia_logging.py b/chia/util/chia_logging.py
index 2bb62de97..4f033557f 100644
--- a/chia/util/chia_logging.py
+++ b/chia/util/chia_logging.py
@@ -61,7 +61,6 @@ def initialize_logging(service_name: str, logging_config: Dict, root_path: Path)
         elif logging_config["log_level"] == "DEBUG":
             logger.setLevel(logging.DEBUG)
             logging.getLogger("aiosqlite").setLevel(logging.INFO)  # Too much logging on debug level
-            logging.getLogger("websockets").setLevel(logging.INFO)  # Too much logging on debug level
         else:
             logger.setLevel(logging.INFO)
     else:
diff --git a/pylintrc b/pylintrc
index 0e6ea29a8..c109b2465 100644
--- a/pylintrc
+++ b/pylintrc
@@ -250,7 +250,6 @@ ignored-modules=blspy,
                 chiavdf,
                 cryptography,
                 aiohttp,
-                websockets,
                 keyring,
                 keyrings.cryptfile,
                 bitstring,
diff --git a/tests/core/daemon/test_daemon.py b/tests/core/daemon/test_daemon.py
index 28d4226d5..6218c6933 100644
--- a/tests/core/daemon/test_daemon.py
+++ b/tests/core/daemon/test_daemon.py
@@ -85,9 +85,6 @@ class TestDaemon:
         read_handler.cancel()
         assert blockchain_state_found
 
-    # Suppress warning: "The explicit passing of coroutine objects to asyncio.wait() is deprecated since Python 3.8..."
-    # Can be removed when we upgrade to a newer version of websockets (9.1 works)
-    @pytest.mark.filterwarnings("ignore::DeprecationWarning:websockets.*")
     @pytest.mark.asyncio
     async def test_validate_keyring_passphrase_rpc(self, get_daemon_with_temp_keyring):
         local_b_tools: BlockTools = get_daemon_with_temp_keyring[0]
@@ -169,9 +166,6 @@ class TestDaemon:
                 # Expect: validation failure
                 await check_empty_passphrase_case(await ws.receive())
 
-    # Suppress warning: "The explicit passing of coroutine objects to asyncio.wait() is deprecated since Python 3.8..."
-    # Can be removed when we upgrade to a newer version of websockets (9.1 works)
-    @pytest.mark.filterwarnings("ignore::DeprecationWarning:websockets.*")
     @pytest.mark.asyncio
     async def test_add_private_key(self, get_daemon_with_temp_keyring):
         local_b_tools: BlockTools = get_daemon_with_temp_keyring[0]
-- 
2.34.1


From 38cc36ca5f4ea66b3ceae94d9ac975eb9b25dbb7 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:37:05 +0200
Subject: [PATCH 22/77] harvester: Enable `isort` (#11127)

---
 .isort.cfg                           | 3 ---
 chia/harvester/harvester.py          | 8 ++++----
 chia/harvester/harvester_api.py      | 2 +-
 chia/protocols/harvester_protocol.py | 2 +-
 4 files changed, 6 insertions(+), 9 deletions(-)

diff --git a/.isort.cfg b/.isort.cfg
index c96731587..f63029db4 100644
--- a/.isort.cfg
+++ b/.isort.cfg
@@ -45,8 +45,6 @@ extend_skip=
     chia/full_node/mempool_check_conditions.py
     chia/full_node/mempool_manager.py
     chia/full_node/weight_proof.py
-    chia/harvester/harvester_api.py
-    chia/harvester/harvester.py
     chia/introducer/introducer.py
     chia/plotters/bladebit.py
     chia/plotters/chiapos.py
@@ -60,7 +58,6 @@ extend_skip=
     chia/pools/pool_puzzles.py
     chia/pools/pool_wallet_info.py
     chia/pools/pool_wallet.py
-    chia/protocols/harvester_protocol.py
     chia/protocols/pool_protocol.py
     chia/protocols/protocol_state_machine.py
     chia/rpc/farmer_rpc_client.py
diff --git a/chia/harvester/harvester.py b/chia/harvester/harvester.py
index fab6a77da..ff5ba444f 100644
--- a/chia/harvester/harvester.py
+++ b/chia/harvester/harvester.py
@@ -11,13 +11,13 @@ from chia.consensus.constants import ConsensusConstants
 from chia.plot_sync.sender import Sender
 from chia.plotting.manager import PlotManager
 from chia.plotting.util import (
+    PlotRefreshEvents,
+    PlotRefreshResult,
+    PlotsRefreshParameter,
     add_plot_directory,
     get_plot_directories,
-    remove_plot_directory,
     remove_plot,
-    PlotsRefreshParameter,
-    PlotRefreshResult,
-    PlotRefreshEvents,
+    remove_plot_directory,
 )
 from chia.util.streamable import dataclass_from_dict
 
diff --git a/chia/harvester/harvester_api.py b/chia/harvester/harvester_api.py
index 885286785..26197d7d5 100644
--- a/chia/harvester/harvester_api.py
+++ b/chia/harvester/harvester_api.py
@@ -3,7 +3,7 @@ import time
 from pathlib import Path
 from typing import Callable, List, Tuple
 
-from blspy import AugSchemeMPL, G2Element, G1Element
+from blspy import AugSchemeMPL, G1Element, G2Element
 
 from chia.consensus.pot_iterations import calculate_iterations_quality, calculate_sp_interval_iters
 from chia.harvester.harvester import Harvester
diff --git a/chia/protocols/harvester_protocol.py b/chia/protocols/harvester_protocol.py
index d3323a48a..bc4f5da8a 100644
--- a/chia/protocols/harvester_protocol.py
+++ b/chia/protocols/harvester_protocol.py
@@ -1,5 +1,5 @@
 from dataclasses import dataclass
-from typing import List, Tuple, Optional
+from typing import List, Optional, Tuple
 
 from blspy import G1Element, G2Element
 
-- 
2.34.1


From ee3bf4f866949060757ba055528cf0c8a827b938 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:37:46 +0200
Subject: [PATCH 23/77] farmer: Enable `isort` (#11128)

---
 .isort.cfg                    |  3 ---
 chia/farmer/farmer.py         | 16 ++++++++--------
 chia/farmer/farmer_api.py     | 14 +++++++-------
 chia/rpc/farmer_rpc_client.py |  2 +-
 4 files changed, 16 insertions(+), 19 deletions(-)

diff --git a/.isort.cfg b/.isort.cfg
index f63029db4..011e9d61b 100644
--- a/.isort.cfg
+++ b/.isort.cfg
@@ -31,8 +31,6 @@ extend_skip=
     chia/daemon/keychain_proxy.py
     chia/daemon/keychain_server.py
     chia/daemon/server.py
-    chia/farmer/farmer_api.py
-    chia/farmer/farmer.py
     chia/full_node/block_height_map.py
     chia/full_node/block_store.py
     chia/full_node/bundle_tools.py
@@ -60,7 +58,6 @@ extend_skip=
     chia/pools/pool_wallet.py
     chia/protocols/pool_protocol.py
     chia/protocols/protocol_state_machine.py
-    chia/rpc/farmer_rpc_client.py
     chia/rpc/full_node_rpc_client.py
     chia/rpc/rpc_client.py
     chia/rpc/wallet_rpc_api.py
diff --git a/chia/farmer/farmer.py b/chia/farmer/farmer.py
index ab3a24f46..b2d2436b4 100644
--- a/chia/farmer/farmer.py
+++ b/chia/farmer/farmer.py
@@ -2,9 +2,9 @@ import asyncio
 import json
 import logging
 import time
+import traceback
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Tuple
-import traceback
 
 import aiohttp
 from blspy import AugSchemeMPL, G1Element, G2Element, PrivateKey
@@ -18,20 +18,20 @@ from chia.daemon.keychain_proxy import (
     connect_to_keychain_and_validate,
     wrap_local_keychain,
 )
-from chia.plot_sync.receiver import Receiver
 from chia.plot_sync.delta import Delta
-from chia.pools.pool_config import PoolWalletConfig, load_pool_config, add_auth_key
+from chia.plot_sync.receiver import Receiver
+from chia.pools.pool_config import PoolWalletConfig, add_auth_key, load_pool_config
 from chia.protocols import farmer_protocol, harvester_protocol
 from chia.protocols.pool_protocol import (
+    AuthenticationPayload,
     ErrorResponse,
-    get_current_authentication_token,
     GetFarmerResponse,
     PoolErrorCode,
     PostFarmerPayload,
     PostFarmerRequest,
     PutFarmerPayload,
     PutFarmerRequest,
-    AuthenticationPayload,
+    get_current_authentication_token,
 )
 from chia.protocols.protocol_message_types import ProtocolMessageTypes
 from chia.server.outbound_message import NodeType, make_msg
@@ -42,16 +42,16 @@ from chia.types.blockchain_format.proof_of_space import ProofOfSpace
 from chia.types.blockchain_format.sized_bytes import bytes32
 from chia.util.bech32m import decode_puzzle_hash
 from chia.util.byte_types import hexstr_to_bytes
-from chia.util.config import load_config, lock_and_load_config, save_config, config_path_for_filename
+from chia.util.config import config_path_for_filename, load_config, lock_and_load_config, save_config
 from chia.util.hash import std_hash
 from chia.util.ints import uint8, uint16, uint32, uint64
 from chia.util.keychain import Keychain
 from chia.wallet.derive_keys import (
+    find_authentication_sk,
+    find_owner_sk,
     master_sk_to_farmer_sk,
     master_sk_to_pool_sk,
     master_sk_to_wallet_sk,
-    find_authentication_sk,
-    find_owner_sk,
 )
 from chia.wallet.puzzles.singleton_top_layer import SINGLETON_MOD
 
diff --git a/chia/farmer/farmer_api.py b/chia/farmer/farmer_api.py
index 9e94a5052..87ce5525f 100644
--- a/chia/farmer/farmer_api.py
+++ b/chia/farmer/farmer_api.py
@@ -1,6 +1,6 @@
 import json
 import time
-from typing import Callable, Optional, List, Any, Dict, Tuple
+from typing import Any, Callable, Dict, List, Optional, Tuple
 
 import aiohttp
 from blspy import AugSchemeMPL, G2Element, PrivateKey
@@ -12,17 +12,17 @@ from chia.consensus.pot_iterations import calculate_iterations_quality, calculat
 from chia.farmer.farmer import Farmer
 from chia.protocols import farmer_protocol, harvester_protocol
 from chia.protocols.harvester_protocol import (
-    PoolDifficulty,
-    PlotSyncStart,
-    PlotSyncPlotList,
-    PlotSyncPathList,
     PlotSyncDone,
+    PlotSyncPathList,
+    PlotSyncPlotList,
+    PlotSyncStart,
+    PoolDifficulty,
 )
 from chia.protocols.pool_protocol import (
-    get_current_authentication_token,
     PoolErrorCode,
-    PostPartialRequest,
     PostPartialPayload,
+    PostPartialRequest,
+    get_current_authentication_token,
 )
 from chia.protocols.protocol_message_types import ProtocolMessageTypes
 from chia.server.outbound_message import NodeType, make_msg
diff --git a/chia/rpc/farmer_rpc_client.py b/chia/rpc/farmer_rpc_client.py
index 612f42e9d..545b052f9 100644
--- a/chia/rpc/farmer_rpc_client.py
+++ b/chia/rpc/farmer_rpc_client.py
@@ -1,4 +1,4 @@
-from typing import Dict, List, Optional, Any
+from typing import Any, Dict, List, Optional
 
 from chia.rpc.rpc_client import RpcClient
 from chia.types.blockchain_format.sized_bytes import bytes32
-- 
2.34.1


From d1f68daa0f85cd79e73c656dd02200e77befaec1 Mon Sep 17 00:00:00 2001
From: Adam Kelly <338792+aqk@users.noreply.github.com>
Date: Wed, 20 Apr 2022 11:38:29 -0700
Subject: [PATCH 24/77] Correct "Older block not found" error message (#11130)

---
 chia/rpc/full_node_rpc_api.py | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/chia/rpc/full_node_rpc_api.py b/chia/rpc/full_node_rpc_api.py
index 04e84a9bf..807bba187 100644
--- a/chia/rpc/full_node_rpc_api.py
+++ b/chia/rpc/full_node_rpc_api.py
@@ -470,10 +470,10 @@ class FullNodeRpcApi:
 
         newer_block = await self.service.block_store.get_block_record(newer_block_bytes)
         if newer_block is None:
-            raise ValueError("Newer block not found")
+            raise ValueError(f"Newer block {newer_block_hex} not found")
         older_block = await self.service.block_store.get_block_record(older_block_bytes)
         if older_block is None:
-            raise ValueError("Newer block not found")
+            raise ValueError(f"Older block {older_block_hex} not found")
         delta_weight = newer_block.weight - older_block.weight
 
         delta_iters = newer_block.total_iters - older_block.total_iters
-- 
2.34.1


From b224e1dda60dfc50d2b396e00e01721effd6131d Mon Sep 17 00:00:00 2001
From: Adam Kelly <338792+aqk@users.noreply.github.com>
Date: Wed, 20 Apr 2022 11:39:38 -0700
Subject: [PATCH 25/77] Print MempoolInclusionStatus as string when reporting
 mempool inclusion status (#11133)

---
 chia/cmds/cmds_util.py                  | 12 +++++++++++
 chia/cmds/plotnft_funcs.py              |  9 ++++----
 chia/cmds/wallet_funcs.py               |  5 +++--
 chia/types/mempool_submission_status.py | 28 +++++++++++++++++++++++++
 chia/wallet/trade_record.py             |  2 +-
 5 files changed, 49 insertions(+), 7 deletions(-)
 create mode 100644 chia/cmds/cmds_util.py
 create mode 100644 chia/types/mempool_submission_status.py

diff --git a/chia/cmds/cmds_util.py b/chia/cmds/cmds_util.py
new file mode 100644
index 000000000..f2c764bfc
--- /dev/null
+++ b/chia/cmds/cmds_util.py
@@ -0,0 +1,12 @@
+from chia.types.blockchain_format.sized_bytes import bytes32
+from chia.types.mempool_submission_status import MempoolSubmissionStatus
+from chia.wallet.transaction_record import TransactionRecord
+
+
+def transaction_submitted_msg(tx: TransactionRecord) -> str:
+    sent_to = [MempoolSubmissionStatus(s[0], s[1], s[2]).to_json_dict_convenience() for s in tx.sent_to]
+    return f"Transaction submitted to nodes: {sent_to}"
+
+
+def transaction_status_msg(fingerprint: int, tx_id: bytes32) -> str:
+    return f"Run 'chia wallet get_transaction -f {fingerprint} -tx 0x{tx_id}' to get status"
diff --git a/chia/cmds/plotnft_funcs.py b/chia/cmds/plotnft_funcs.py
index b70f202a5..e739c49f6 100644
--- a/chia/cmds/plotnft_funcs.py
+++ b/chia/cmds/plotnft_funcs.py
@@ -26,6 +26,7 @@ from chia.util.byte_types import hexstr_to_bytes
 from chia.util.config import load_config
 from chia.util.default_root import DEFAULT_ROOT_PATH
 from chia.util.ints import uint16, uint32, uint64
+from chia.cmds.cmds_util import transaction_submitted_msg, transaction_status_msg
 from chia.wallet.transaction_record import TransactionRecord
 from chia.wallet.util.wallet_types import WalletType
 
@@ -100,8 +101,8 @@ async def create(args: dict, wallet_client: WalletRpcClient, fingerprint: int) -
                 await asyncio.sleep(0.1)
                 tx = await wallet_client.get_transaction(str(1), tx_record.name)
                 if len(tx.sent_to) > 0:
-                    print(f"Transaction submitted to nodes: {tx.sent_to}")
-                    print(f"Do chia wallet get_transaction -f {fingerprint} -tx 0x{tx_record.name} to get status")
+                    print(transaction_submitted_msg(tx))
+                    print(transaction_status_msg(fingerprint, tx_record.name))
                     return None
         except Exception as e:
             print(f"Error creating plot NFT: {e}\n    Please start both farmer and wallet with:  chia start -r farmer")
@@ -286,8 +287,8 @@ async def submit_tx_with_confirmation(
                 await asyncio.sleep(0.1)
                 tx = await wallet_client.get_transaction(str(1), tx_record.name)
                 if len(tx.sent_to) > 0:
-                    print(f"Transaction submitted to nodes: {tx.sent_to}")
-                    print(f"Do chia wallet get_transaction -f {fingerprint} -tx 0x{tx_record.name} to get status")
+                    print(transaction_submitted_msg(tx))
+                    print(transaction_status_msg(fingerprint, tx_record.name))
                     return None
         except Exception as e:
             print(f"Error performing operation on Plot NFT -f {fingerprint} wallet id: {wallet_id}: {e}")
diff --git a/chia/cmds/wallet_funcs.py b/chia/cmds/wallet_funcs.py
index c6b074e48..1522d21c8 100644
--- a/chia/cmds/wallet_funcs.py
+++ b/chia/cmds/wallet_funcs.py
@@ -18,6 +18,7 @@ from chia.util.bech32m import encode_puzzle_hash
 from chia.util.config import load_config
 from chia.util.default_root import DEFAULT_ROOT_PATH
 from chia.util.ints import uint16, uint32, uint64
+from chia.cmds.cmds_util import transaction_submitted_msg, transaction_status_msg
 from chia.wallet.trade_record import TradeRecord
 from chia.wallet.trading.offer import Offer
 from chia.wallet.trading.trade_status import TradeStatus
@@ -228,8 +229,8 @@ async def send(args: dict, wallet_client: WalletRpcClient, fingerprint: int) ->
         await asyncio.sleep(0.1)
         tx = await wallet_client.get_transaction(str(wallet_id), tx_id)
         if len(tx.sent_to) > 0:
-            print(f"Transaction submitted to nodes: {tx.sent_to}")
-            print(f"Do chia wallet get_transaction -f {fingerprint} -tx 0x{tx_id} to get status")
+            print(transaction_submitted_msg(tx))
+            print(transaction_status_msg(fingerprint, tx_id))
             return None
 
     print("Transaction not yet submitted to nodes")
diff --git a/chia/types/mempool_submission_status.py b/chia/types/mempool_submission_status.py
new file mode 100644
index 000000000..9ba1d5c70
--- /dev/null
+++ b/chia/types/mempool_submission_status.py
@@ -0,0 +1,28 @@
+from dataclasses import dataclass
+from typing import Dict, Optional, Union
+
+from chia.types.mempool_inclusion_status import MempoolInclusionStatus
+from chia.util.ints import uint8
+from chia.util.streamable import Streamable, streamable
+
+
+@streamable
+@dataclass(frozen=True)
+class MempoolSubmissionStatus(Streamable):
+    """
+    :sent_to: in `TradeRecord` and `TransactionRecord` are a
+    Tuple of (peer_id: str, status: MempoolInclusionStatus, error: Optional[str])
+    MempoolInclusionStatus is represented as a uint8 in those structs so they can be `Streamable`
+    """
+
+    peer_id: str
+    inclusion_status: uint8  # MempoolInclusionStatus
+    error_msg: Optional[str]
+
+    def to_json_dict_convenience(self) -> Dict[str, Union[str, MempoolInclusionStatus, Optional[str]]]:
+        formatted = self.to_json_dict()
+        formatted["inclusion_status"] = MempoolInclusionStatus(self.inclusion_status).name
+        return formatted
+
+    def __str__(self) -> str:
+        return f"{self.to_json_dict_convenience()}"
diff --git a/chia/wallet/trade_record.py b/chia/wallet/trade_record.py
index 08c56bb4b..1cf9a452d 100644
--- a/chia/wallet/trade_record.py
+++ b/chia/wallet/trade_record.py
@@ -26,7 +26,7 @@ class TradeRecord(Streamable):
     coins_of_interest: List[Coin]
     trade_id: bytes32
     status: uint32  # TradeStatus, enum not streamable
-    sent_to: List[Tuple[str, uint8, Optional[str]]]
+    sent_to: List[Tuple[str, uint8, Optional[str]]]  # MempoolSubmissionStatus.status enum not streamable
 
     def to_json_dict_convenience(self) -> Dict[str, Any]:
         formatted = self.to_json_dict()
-- 
2.34.1


From efbac6a05f869d80606f595414f240951e500dc5 Mon Sep 17 00:00:00 2001
From: "dependabot[bot]" <49699333+dependabot[bot]@users.noreply.github.com>
Date: Wed, 20 Apr 2022 11:40:51 -0700
Subject: [PATCH 26/77] Bump actions/upload-artifact from 2 to 3 (#11144)

* Bump actions/upload-artifact from 2 to 3

Bumps [actions/upload-artifact](https://github.com/actions/upload-artifact) from 2 to 3.
- [Release notes](https://github.com/actions/upload-artifact/releases)
- [Commits](https://github.com/actions/upload-artifact/compare/v2...v3)

---
updated-dependencies:
- dependency-name: actions/upload-artifact
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>

* Also update runner_templates

* Mark the github workspace as safe (#11159)

* Mark the github workspace as safe

* Move the git config step after git is installed in the test containers

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Gene Hoffman <hoffmang@hoffmang.com>
Co-authored-by: Chris Marslender <chrismarslender@gmail.com>
---
 .github/workflows/build-linux-arm64-installer.yml             | 2 +-
 .github/workflows/build-linux-installer-deb.yml               | 2 +-
 .github/workflows/build-linux-installer-rpm.yml               | 2 +-
 .github/workflows/build-macos-installer.yml                   | 2 +-
 .github/workflows/build-macos-m1-installer.yml                | 2 +-
 .github/workflows/build-test-macos-blockchain.yml             | 2 +-
 .github/workflows/build-test-macos-clvm.yml                   | 2 +-
 .github/workflows/build-test-macos-core-cmds.yml              | 2 +-
 .github/workflows/build-test-macos-core-consensus.yml         | 2 +-
 .github/workflows/build-test-macos-core-custom_types.yml      | 2 +-
 .github/workflows/build-test-macos-core-daemon.yml            | 2 +-
 .../workflows/build-test-macos-core-full_node-full_sync.yml   | 2 +-
 .github/workflows/build-test-macos-core-full_node-stores.yml  | 2 +-
 .github/workflows/build-test-macos-core-full_node.yml         | 2 +-
 .github/workflows/build-test-macos-core-server.yml            | 2 +-
 .github/workflows/build-test-macos-core-ssl.yml               | 2 +-
 .github/workflows/build-test-macos-core-util.yml              | 2 +-
 .github/workflows/build-test-macos-core.yml                   | 2 +-
 .github/workflows/build-test-macos-farmer_harvester.yml       | 2 +-
 .github/workflows/build-test-macos-generator.yml              | 2 +-
 .github/workflows/build-test-macos-plot_sync.yml              | 2 +-
 .github/workflows/build-test-macos-plotting.yml               | 2 +-
 .github/workflows/build-test-macos-pools.yml                  | 2 +-
 .github/workflows/build-test-macos-simulation.yml             | 2 +-
 .github/workflows/build-test-macos-tools.yml                  | 2 +-
 .github/workflows/build-test-macos-util.yml                   | 2 +-
 .github/workflows/build-test-macos-wallet-cat_wallet.yml      | 2 +-
 .github/workflows/build-test-macos-wallet-did_wallet.yml      | 2 +-
 .github/workflows/build-test-macos-wallet-rl_wallet.yml       | 2 +-
 .github/workflows/build-test-macos-wallet-rpc.yml             | 2 +-
 .github/workflows/build-test-macos-wallet-simple_sync.yml     | 2 +-
 .github/workflows/build-test-macos-wallet-sync.yml            | 2 +-
 .github/workflows/build-test-macos-wallet.yml                 | 2 +-
 .github/workflows/build-test-macos-weight_proof.yml           | 2 +-
 .github/workflows/build-test-ubuntu-blockchain.yml            | 2 +-
 .github/workflows/build-test-ubuntu-clvm.yml                  | 2 +-
 .github/workflows/build-test-ubuntu-core-cmds.yml             | 2 +-
 .github/workflows/build-test-ubuntu-core-consensus.yml        | 2 +-
 .github/workflows/build-test-ubuntu-core-custom_types.yml     | 2 +-
 .github/workflows/build-test-ubuntu-core-daemon.yml           | 2 +-
 .../workflows/build-test-ubuntu-core-full_node-full_sync.yml  | 2 +-
 .github/workflows/build-test-ubuntu-core-full_node-stores.yml | 2 +-
 .github/workflows/build-test-ubuntu-core-full_node.yml        | 2 +-
 .github/workflows/build-test-ubuntu-core-server.yml           | 2 +-
 .github/workflows/build-test-ubuntu-core-ssl.yml              | 2 +-
 .github/workflows/build-test-ubuntu-core-util.yml             | 2 +-
 .github/workflows/build-test-ubuntu-core.yml                  | 2 +-
 .github/workflows/build-test-ubuntu-farmer_harvester.yml      | 2 +-
 .github/workflows/build-test-ubuntu-generator.yml             | 2 +-
 .github/workflows/build-test-ubuntu-plot_sync.yml             | 2 +-
 .github/workflows/build-test-ubuntu-plotting.yml              | 2 +-
 .github/workflows/build-test-ubuntu-pools.yml                 | 2 +-
 .github/workflows/build-test-ubuntu-simulation.yml            | 2 +-
 .github/workflows/build-test-ubuntu-tools.yml                 | 2 +-
 .github/workflows/build-test-ubuntu-util.yml                  | 2 +-
 .github/workflows/build-test-ubuntu-wallet-cat_wallet.yml     | 2 +-
 .github/workflows/build-test-ubuntu-wallet-did_wallet.yml     | 2 +-
 .github/workflows/build-test-ubuntu-wallet-rl_wallet.yml      | 2 +-
 .github/workflows/build-test-ubuntu-wallet-rpc.yml            | 2 +-
 .github/workflows/build-test-ubuntu-wallet-simple_sync.yml    | 2 +-
 .github/workflows/build-test-ubuntu-wallet-sync.yml           | 2 +-
 .github/workflows/build-test-ubuntu-wallet.yml                | 2 +-
 .github/workflows/build-test-ubuntu-weight_proof.yml          | 2 +-
 .github/workflows/build-windows-installer.yml                 | 4 ++--
 .github/workflows/upload-pypi-source.yml                      | 2 +-
 tests/runner_templates/build-test-macos                       | 2 +-
 tests/runner_templates/build-test-ubuntu                      | 2 +-
 67 files changed, 68 insertions(+), 68 deletions(-)

diff --git a/.github/workflows/build-linux-arm64-installer.yml b/.github/workflows/build-linux-arm64-installer.yml
index 5cb8cf4ca..56a3b5e7f 100644
--- a/.github/workflows/build-linux-arm64-installer.yml
+++ b/.github/workflows/build-linux-arm64-installer.yml
@@ -119,7 +119,7 @@ jobs:
         sh build_linux_deb.sh arm64
 
     - name: Upload Linux artifacts
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: chia-installers-linux-deb-arm64
         path: ${{ github.workspace }}/build_scripts/final_installer/
diff --git a/.github/workflows/build-linux-installer-deb.yml b/.github/workflows/build-linux-installer-deb.yml
index 43d5fe7e5..e1ff9de56 100644
--- a/.github/workflows/build-linux-installer-deb.yml
+++ b/.github/workflows/build-linux-installer-deb.yml
@@ -162,7 +162,7 @@ jobs:
         sh build_linux_deb.sh amd64
 
     - name: Upload Linux artifacts
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: chia-installers-linux-deb-intel
         path: ${{ github.workspace }}/build_scripts/final_installer/
diff --git a/.github/workflows/build-linux-installer-rpm.yml b/.github/workflows/build-linux-installer-rpm.yml
index 64309818e..b12a702ee 100644
--- a/.github/workflows/build-linux-installer-rpm.yml
+++ b/.github/workflows/build-linux-installer-rpm.yml
@@ -122,7 +122,7 @@ jobs:
         sh build_linux_rpm.sh amd64
 
     - name: Upload Linux artifacts
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: chia-installers-linux-rpm-intel
         path: ${{ github.workspace }}/build_scripts/final_installer/
diff --git a/.github/workflows/build-macos-installer.yml b/.github/workflows/build-macos-installer.yml
index a2b590b9c..ef3b41c58 100644
--- a/.github/workflows/build-macos-installer.yml
+++ b/.github/workflows/build-macos-installer.yml
@@ -148,7 +148,7 @@ jobs:
         sh build_macos.sh
 
     - name: Upload MacOS artifacts
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: chia-installers-macos-dmg-intel
         path: ${{ github.workspace }}/build_scripts/final_installer/
diff --git a/.github/workflows/build-macos-m1-installer.yml b/.github/workflows/build-macos-m1-installer.yml
index 0f5870ff1..17cc3b70c 100644
--- a/.github/workflows/build-macos-m1-installer.yml
+++ b/.github/workflows/build-macos-m1-installer.yml
@@ -122,7 +122,7 @@ jobs:
           arch -arm64 sh build_macos_m1.sh
 
       - name: Upload MacOS artifacts
-        uses: actions/upload-artifact@v2
+        uses: actions/upload-artifact@v3
         with:
           name: chia-installers-macos-dmg-arm64
           path: ${{ github.workspace }}/build_scripts/final_installer/
diff --git a/.github/workflows/build-test-macos-blockchain.yml b/.github/workflows/build-test-macos-blockchain.yml
index 818e10a1a..01dd68588 100644
--- a/.github/workflows/build-test-macos-blockchain.yml
+++ b/.github/workflows/build-test-macos-blockchain.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-clvm.yml b/.github/workflows/build-test-macos-clvm.yml
index 6e945fee8..f27f9e651 100644
--- a/.github/workflows/build-test-macos-clvm.yml
+++ b/.github/workflows/build-test-macos-clvm.yml
@@ -91,7 +91,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-cmds.yml b/.github/workflows/build-test-macos-core-cmds.yml
index b59975bb6..f67ad25e3 100644
--- a/.github/workflows/build-test-macos-core-cmds.yml
+++ b/.github/workflows/build-test-macos-core-cmds.yml
@@ -91,7 +91,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-consensus.yml b/.github/workflows/build-test-macos-core-consensus.yml
index 70f080739..a5aad6169 100644
--- a/.github/workflows/build-test-macos-core-consensus.yml
+++ b/.github/workflows/build-test-macos-core-consensus.yml
@@ -91,7 +91,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-custom_types.yml b/.github/workflows/build-test-macos-core-custom_types.yml
index 24111f0ea..f2dad4ff3 100644
--- a/.github/workflows/build-test-macos-core-custom_types.yml
+++ b/.github/workflows/build-test-macos-core-custom_types.yml
@@ -91,7 +91,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-daemon.yml b/.github/workflows/build-test-macos-core-daemon.yml
index 521c76932..a679447ef 100644
--- a/.github/workflows/build-test-macos-core-daemon.yml
+++ b/.github/workflows/build-test-macos-core-daemon.yml
@@ -109,7 +109,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-full_node-full_sync.yml b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
index d7ac33bea..c613bcb87 100644
--- a/.github/workflows/build-test-macos-core-full_node-full_sync.yml
+++ b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-full_node-stores.yml b/.github/workflows/build-test-macos-core-full_node-stores.yml
index b9695515b..b6cd2c45d 100644
--- a/.github/workflows/build-test-macos-core-full_node-stores.yml
+++ b/.github/workflows/build-test-macos-core-full_node-stores.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-full_node.yml b/.github/workflows/build-test-macos-core-full_node.yml
index 51fa84a3b..2fa7e3c51 100644
--- a/.github/workflows/build-test-macos-core-full_node.yml
+++ b/.github/workflows/build-test-macos-core-full_node.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-server.yml b/.github/workflows/build-test-macos-core-server.yml
index 95857e0c6..0fa88e48f 100644
--- a/.github/workflows/build-test-macos-core-server.yml
+++ b/.github/workflows/build-test-macos-core-server.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-ssl.yml b/.github/workflows/build-test-macos-core-ssl.yml
index c1b0bf96c..4a11ccd2e 100644
--- a/.github/workflows/build-test-macos-core-ssl.yml
+++ b/.github/workflows/build-test-macos-core-ssl.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core-util.yml b/.github/workflows/build-test-macos-core-util.yml
index 3900c066a..a17bb909b 100644
--- a/.github/workflows/build-test-macos-core-util.yml
+++ b/.github/workflows/build-test-macos-core-util.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-core.yml b/.github/workflows/build-test-macos-core.yml
index 1b84573b8..be7d8fcab 100644
--- a/.github/workflows/build-test-macos-core.yml
+++ b/.github/workflows/build-test-macos-core.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-farmer_harvester.yml b/.github/workflows/build-test-macos-farmer_harvester.yml
index 011b077ba..0286aba80 100644
--- a/.github/workflows/build-test-macos-farmer_harvester.yml
+++ b/.github/workflows/build-test-macos-farmer_harvester.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-generator.yml b/.github/workflows/build-test-macos-generator.yml
index e3aca9c35..ccce30af6 100644
--- a/.github/workflows/build-test-macos-generator.yml
+++ b/.github/workflows/build-test-macos-generator.yml
@@ -91,7 +91,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-plot_sync.yml b/.github/workflows/build-test-macos-plot_sync.yml
index 315c909bb..3b72cfaff 100644
--- a/.github/workflows/build-test-macos-plot_sync.yml
+++ b/.github/workflows/build-test-macos-plot_sync.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-plotting.yml b/.github/workflows/build-test-macos-plotting.yml
index 8468bfd97..561f1fa81 100644
--- a/.github/workflows/build-test-macos-plotting.yml
+++ b/.github/workflows/build-test-macos-plotting.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-pools.yml b/.github/workflows/build-test-macos-pools.yml
index 3b2dd413c..8b36cbc7c 100644
--- a/.github/workflows/build-test-macos-pools.yml
+++ b/.github/workflows/build-test-macos-pools.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-simulation.yml b/.github/workflows/build-test-macos-simulation.yml
index d8f78d913..b1e2e79f6 100644
--- a/.github/workflows/build-test-macos-simulation.yml
+++ b/.github/workflows/build-test-macos-simulation.yml
@@ -109,7 +109,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-tools.yml b/.github/workflows/build-test-macos-tools.yml
index b615d40a0..4be349499 100644
--- a/.github/workflows/build-test-macos-tools.yml
+++ b/.github/workflows/build-test-macos-tools.yml
@@ -91,7 +91,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-util.yml b/.github/workflows/build-test-macos-util.yml
index adda26ace..136cbfe8f 100644
--- a/.github/workflows/build-test-macos-util.yml
+++ b/.github/workflows/build-test-macos-util.yml
@@ -91,7 +91,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-wallet-cat_wallet.yml b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
index 0e9c3e86d..5bceb86a7 100644
--- a/.github/workflows/build-test-macos-wallet-cat_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-wallet-did_wallet.yml b/.github/workflows/build-test-macos-wallet-did_wallet.yml
index 4601927e1..c182bc72c 100644
--- a/.github/workflows/build-test-macos-wallet-did_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-did_wallet.yml
@@ -91,7 +91,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-wallet-rl_wallet.yml b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
index 2c5987b75..3045f4be0 100644
--- a/.github/workflows/build-test-macos-wallet-rl_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
@@ -91,7 +91,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-wallet-rpc.yml b/.github/workflows/build-test-macos-wallet-rpc.yml
index ad54fff9c..12a24bd1f 100644
--- a/.github/workflows/build-test-macos-wallet-rpc.yml
+++ b/.github/workflows/build-test-macos-wallet-rpc.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-wallet-simple_sync.yml b/.github/workflows/build-test-macos-wallet-simple_sync.yml
index 9c2e907ca..d8cf60ed0 100644
--- a/.github/workflows/build-test-macos-wallet-simple_sync.yml
+++ b/.github/workflows/build-test-macos-wallet-simple_sync.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-wallet-sync.yml b/.github/workflows/build-test-macos-wallet-sync.yml
index d0d4b945a..ad4c852c3 100644
--- a/.github/workflows/build-test-macos-wallet-sync.yml
+++ b/.github/workflows/build-test-macos-wallet-sync.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-wallet.yml b/.github/workflows/build-test-macos-wallet.yml
index a02077424..c4be58dd0 100644
--- a/.github/workflows/build-test-macos-wallet.yml
+++ b/.github/workflows/build-test-macos-wallet.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-macos-weight_proof.yml b/.github/workflows/build-test-macos-weight_proof.yml
index 1132955ba..2690434d8 100644
--- a/.github/workflows/build-test-macos-weight_proof.yml
+++ b/.github/workflows/build-test-macos-weight_proof.yml
@@ -105,7 +105,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-blockchain.yml b/.github/workflows/build-test-ubuntu-blockchain.yml
index 110949da8..a670a85e0 100644
--- a/.github/workflows/build-test-ubuntu-blockchain.yml
+++ b/.github/workflows/build-test-ubuntu-blockchain.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-clvm.yml b/.github/workflows/build-test-ubuntu-clvm.yml
index 57d505656..0c8bcd74d 100644
--- a/.github/workflows/build-test-ubuntu-clvm.yml
+++ b/.github/workflows/build-test-ubuntu-clvm.yml
@@ -90,7 +90,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-cmds.yml b/.github/workflows/build-test-ubuntu-core-cmds.yml
index 9305933f7..1e99104ff 100644
--- a/.github/workflows/build-test-ubuntu-core-cmds.yml
+++ b/.github/workflows/build-test-ubuntu-core-cmds.yml
@@ -90,7 +90,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-consensus.yml b/.github/workflows/build-test-ubuntu-core-consensus.yml
index 3f373ff0d..8f589ae91 100644
--- a/.github/workflows/build-test-ubuntu-core-consensus.yml
+++ b/.github/workflows/build-test-ubuntu-core-consensus.yml
@@ -90,7 +90,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-custom_types.yml b/.github/workflows/build-test-ubuntu-core-custom_types.yml
index 5abe34e11..14a7817de 100644
--- a/.github/workflows/build-test-ubuntu-core-custom_types.yml
+++ b/.github/workflows/build-test-ubuntu-core-custom_types.yml
@@ -90,7 +90,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-daemon.yml b/.github/workflows/build-test-ubuntu-core-daemon.yml
index 1141c268d..3f9d4328f 100644
--- a/.github/workflows/build-test-ubuntu-core-daemon.yml
+++ b/.github/workflows/build-test-ubuntu-core-daemon.yml
@@ -108,7 +108,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml b/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
index 2873ca064..9cb55ba9a 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-full_node-stores.yml b/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
index 08d4348bf..03661c5ca 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-full_node.yml b/.github/workflows/build-test-ubuntu-core-full_node.yml
index 5258828a6..cbfbcf5db 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-server.yml b/.github/workflows/build-test-ubuntu-core-server.yml
index a996862f5..2e29e7c5f 100644
--- a/.github/workflows/build-test-ubuntu-core-server.yml
+++ b/.github/workflows/build-test-ubuntu-core-server.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-ssl.yml b/.github/workflows/build-test-ubuntu-core-ssl.yml
index ea6e3f19e..931892d87 100644
--- a/.github/workflows/build-test-ubuntu-core-ssl.yml
+++ b/.github/workflows/build-test-ubuntu-core-ssl.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core-util.yml b/.github/workflows/build-test-ubuntu-core-util.yml
index b2bc91886..6b40c42a7 100644
--- a/.github/workflows/build-test-ubuntu-core-util.yml
+++ b/.github/workflows/build-test-ubuntu-core-util.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-core.yml b/.github/workflows/build-test-ubuntu-core.yml
index e45dcea4c..49c5c21e4 100644
--- a/.github/workflows/build-test-ubuntu-core.yml
+++ b/.github/workflows/build-test-ubuntu-core.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-farmer_harvester.yml b/.github/workflows/build-test-ubuntu-farmer_harvester.yml
index de87b70fb..2304dadab 100644
--- a/.github/workflows/build-test-ubuntu-farmer_harvester.yml
+++ b/.github/workflows/build-test-ubuntu-farmer_harvester.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-generator.yml b/.github/workflows/build-test-ubuntu-generator.yml
index a8ac14944..17f9b1ce5 100644
--- a/.github/workflows/build-test-ubuntu-generator.yml
+++ b/.github/workflows/build-test-ubuntu-generator.yml
@@ -90,7 +90,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-plot_sync.yml b/.github/workflows/build-test-ubuntu-plot_sync.yml
index fddf0cd9c..8be06ca85 100644
--- a/.github/workflows/build-test-ubuntu-plot_sync.yml
+++ b/.github/workflows/build-test-ubuntu-plot_sync.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-plotting.yml b/.github/workflows/build-test-ubuntu-plotting.yml
index 974aff32b..32bf337ea 100644
--- a/.github/workflows/build-test-ubuntu-plotting.yml
+++ b/.github/workflows/build-test-ubuntu-plotting.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-pools.yml b/.github/workflows/build-test-ubuntu-pools.yml
index 7e4a705b5..bfbe02312 100644
--- a/.github/workflows/build-test-ubuntu-pools.yml
+++ b/.github/workflows/build-test-ubuntu-pools.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-simulation.yml b/.github/workflows/build-test-ubuntu-simulation.yml
index 60c7de4b1..b286ebdb2 100644
--- a/.github/workflows/build-test-ubuntu-simulation.yml
+++ b/.github/workflows/build-test-ubuntu-simulation.yml
@@ -108,7 +108,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-tools.yml b/.github/workflows/build-test-ubuntu-tools.yml
index f8b84c1d9..b07714020 100644
--- a/.github/workflows/build-test-ubuntu-tools.yml
+++ b/.github/workflows/build-test-ubuntu-tools.yml
@@ -90,7 +90,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-util.yml b/.github/workflows/build-test-ubuntu-util.yml
index 44fb561fa..ff9f5dbf3 100644
--- a/.github/workflows/build-test-ubuntu-util.yml
+++ b/.github/workflows/build-test-ubuntu-util.yml
@@ -90,7 +90,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
index f17cdd36c..1c04603e0 100644
--- a/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
index 2dbf05eb7..8bf4e33a3 100644
--- a/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
@@ -90,7 +90,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
index c85ddec93..2eefca2d0 100644
--- a/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
@@ -90,7 +90,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-wallet-rpc.yml b/.github/workflows/build-test-ubuntu-wallet-rpc.yml
index f417f1ce9..36a38b740 100644
--- a/.github/workflows/build-test-ubuntu-wallet-rpc.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-rpc.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml b/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
index 785d5fa81..bd6925631 100644
--- a/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-wallet-sync.yml b/.github/workflows/build-test-ubuntu-wallet-sync.yml
index 15eeacf1f..c607a7028 100644
--- a/.github/workflows/build-test-ubuntu-wallet-sync.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-sync.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-wallet.yml b/.github/workflows/build-test-ubuntu-wallet.yml
index dd5a55b60..349879eda 100644
--- a/.github/workflows/build-test-ubuntu-wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-test-ubuntu-weight_proof.yml b/.github/workflows/build-test-ubuntu-weight_proof.yml
index 9a8044617..2616c1d40 100644
--- a/.github/workflows/build-test-ubuntu-weight_proof.yml
+++ b/.github/workflows/build-test-ubuntu-weight_proof.yml
@@ -104,7 +104,7 @@ jobs:
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/.github/workflows/build-windows-installer.yml b/.github/workflows/build-windows-installer.yml
index 5ae996af6..5467d23a4 100644
--- a/.github/workflows/build-windows-installer.yml
+++ b/.github/workflows/build-windows-installer.yml
@@ -155,13 +155,13 @@ jobs:
         .\build_scripts\build_windows.ps1
 
     - name: Upload Windows exe's to artifacts
-      uses: actions/upload-artifact@v2.2.2
+      uses: actions/upload-artifact@v3
       with:
         name: chia-installers-windows-exe-intel
         path: ${{ github.workspace }}\chia-blockchain-gui\Chia-win32-x64\
 
     - name: Upload Installer to artifacts
-      uses: actions/upload-artifact@v2.2.2
+      uses: actions/upload-artifact@v3
       with:
         name: Windows-Installers
         path: ${{ github.workspace }}\chia-blockchain-gui\release-builds\
diff --git a/.github/workflows/upload-pypi-source.yml b/.github/workflows/upload-pypi-source.yml
index 9114d3498..c05919949 100644
--- a/.github/workflows/upload-pypi-source.yml
+++ b/.github/workflows/upload-pypi-source.yml
@@ -65,7 +65,7 @@ jobs:
         python -m build --sdist --outdir dist .
 
     - name: Upload artifacts
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: dist
         path: ./dist
diff --git a/tests/runner_templates/build-test-macos b/tests/runner_templates/build-test-macos
index 255b2b8d8..94ea0d294 100644
--- a/tests/runner_templates/build-test-macos
+++ b/tests/runner_templates/build-test-macos
@@ -91,7 +91,7 @@ INSTALL_TIMELORD
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
diff --git a/tests/runner_templates/build-test-ubuntu b/tests/runner_templates/build-test-ubuntu
index 9a765ac43..1fc0c78a1 100644
--- a/tests/runner_templates/build-test-ubuntu
+++ b/tests/runner_templates/build-test-ubuntu
@@ -90,7 +90,7 @@ INSTALL_TIMELORD
         venv/bin/coverage report --rcfile=.coveragerc --show-missing
 
     - name: Publish coverage
-      uses: actions/upload-artifact@v2
+      uses: actions/upload-artifact@v3
       with:
         name: coverage
         path: coverage_reports/*
-- 
2.34.1


From cd9beaca0bb06d827fb84951dd3dfb2ba5861226 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:42:58 +0200
Subject: [PATCH 27/77] wallet: Some rollback fixes (#11149)

* Set `in_transaction` for `set_finished_sync_up_to`

* Call `clean_block_records` based on `in_transaction`

* Don't pop wallets in `reorg_rollback`, do it after it was commited
---
 chia/wallet/wallet_blockchain.py    |  3 ++-
 chia/wallet/wallet_node.py          | 15 +++++++++++++--
 chia/wallet/wallet_state_manager.py |  5 +++--
 3 files changed, 18 insertions(+), 5 deletions(-)

diff --git a/chia/wallet/wallet_blockchain.py b/chia/wallet/wallet_blockchain.py
index f4ea59d1b..d0ebc650e 100644
--- a/chia/wallet/wallet_blockchain.py
+++ b/chia/wallet/wallet_blockchain.py
@@ -187,7 +187,8 @@ class WalletBlockchain(BlockchainInterface):
     async def set_finished_sync_up_to(self, height: int, in_transaction=False):
         if height > await self.get_finished_sync_up_to():
             await self._basic_store.set_object("FINISHED_SYNC_UP_TO", uint32(height), in_transaction)
-            await self.clean_block_records()
+            if not in_transaction:
+                await self.clean_block_records()
 
     async def get_finished_sync_up_to(self):
         h: Optional[uint32] = await self._basic_store.get_object("FINISHED_SYNC_UP_TO", uint32)
diff --git a/chia/wallet/wallet_node.py b/chia/wallet/wallet_node.py
index b64f38cf1..f59e06754 100644
--- a/chia/wallet/wallet_node.py
+++ b/chia/wallet/wallet_node.py
@@ -478,8 +478,8 @@ class WalletNode:
         async with self.wallet_state_manager.db_wrapper.lock:
             try:
                 await self.wallet_state_manager.db_wrapper.begin_transaction()
-                await self.wallet_state_manager.reorg_rollback(fork_height)
-                await self.wallet_state_manager.blockchain.set_finished_sync_up_to(fork_height)
+                removed_wallet_ids = await self.wallet_state_manager.reorg_rollback(fork_height)
+                await self.wallet_state_manager.blockchain.set_finished_sync_up_to(fork_height, True)
                 if cache is None:
                     self.rollback_request_caches(fork_height)
                 else:
@@ -493,6 +493,11 @@ class WalletNode:
                 await self.wallet_state_manager.tx_store.rebuild_tx_cache()
                 await self.wallet_state_manager.pool_store.rebuild_cache()
                 raise
+            else:
+                await self.wallet_state_manager.blockchain.clean_block_records()
+
+                for wallet_id in removed_wallet_ids:
+                    self.wallet_state_manager.wallets.pop(wallet_id)
 
     async def long_sync(
         self,
@@ -686,6 +691,9 @@ class WalletNode:
                                 await self.wallet_state_manager.coin_store.rebuild_wallet_cache()
                                 await self.wallet_state_manager.tx_store.rebuild_tx_cache()
                                 await self.wallet_state_manager.pool_store.rebuild_cache()
+                            else:
+                                await self.wallet_state_manager.blockchain.clean_block_records()
+
             except Exception as e:
                 tb = traceback.format_exc()
                 self.log.error(f"Exception while adding state: {e} {tb}")
@@ -721,6 +729,9 @@ class WalletNode:
                         tb = traceback.format_exc()
                         self.log.error(f"Error adding states.. {e} {tb}")
                         return False
+                    else:
+                        await self.wallet_state_manager.blockchain.clean_block_records()
+
             else:
                 while len(concurrent_tasks_cs_heights) >= target_concurrent_tasks:
                     await asyncio.sleep(0.1)
diff --git a/chia/wallet/wallet_state_manager.py b/chia/wallet/wallet_state_manager.py
index f6a2a037f..84d31c2af 100644
--- a/chia/wallet/wallet_state_manager.py
+++ b/chia/wallet/wallet_state_manager.py
@@ -1078,7 +1078,7 @@ class WalletStateManager:
         wallet = self.wallets[wallet_id]
         return wallet
 
-    async def reorg_rollback(self, height: int):
+    async def reorg_rollback(self, height: int) -> List[uint32]:
         """
         Rolls back and updates the coin_store and transaction store. It's possible this height
         is the tip, or even beyond the tip.
@@ -1104,7 +1104,8 @@ class WalletStateManager:
                     remove_ids.append(wallet_id)
         for wallet_id in remove_ids:
             await self.user_store.delete_wallet(wallet_id, in_transaction=True)
-            self.wallets.pop(wallet_id)
+
+        return remove_ids
 
     async def _await_closed(self) -> None:
         await self.db_connection.close()
-- 
2.34.1


From 73cd386b8742508dca49fddbba0943bd14cdeb6a Mon Sep 17 00:00:00 2001
From: Arvid Norberg <arvid@libtorrent.org>
Date: Wed, 20 Apr 2022 20:43:15 +0200
Subject: [PATCH 28/77] optimize Program.curry() (#11162)

* optimize Program.curry()

* Add a comment for this curry implementation

* optimize Program.curry()

* Add comment

Co-authored-by: arty <art.yerkes@gmail.com>
---
 chia/types/blockchain_format/program.py | 26 +++++++++++++++++++----
 tests/clvm/test_program.py              | 28 +++++++++++++++++++++++++
 2 files changed, 50 insertions(+), 4 deletions(-)

diff --git a/chia/types/blockchain_format/program.py b/chia/types/blockchain_format/program.py
index 096f72d25..784697a5c 100644
--- a/chia/types/blockchain_format/program.py
+++ b/chia/types/blockchain_format/program.py
@@ -1,12 +1,12 @@
 import io
-from typing import List, Set, Tuple, Optional
+from typing import List, Set, Tuple, Optional, Any
 
 from clvm import SExp
 from clvm.casts import int_from_bytes
 from clvm.EvalError import EvalError
 from clvm.serialize import sexp_from_stream, sexp_to_stream
 from chia_rs import MEMPOOL_MODE, run_chia_program, serialized_length, run_generator
-from clvm_tools.curry import curry, uncurry
+from clvm_tools.curry import uncurry
 
 from chia.types.blockchain_format.sized_bytes import bytes32
 from chia.util.hash import std_hash
@@ -88,9 +88,27 @@ class Program(SExp):
         cost, r = self.run_with_cost(INFINITE_COST, args)
         return r
 
+    # Replicates the curry function from clvm_tools, taking advantage of *args
+    # being a list.  We iterate through args in reverse building the code to
+    # create a clvm list.
+    #
+    # Given arguments to a function addressable by the '1' reference in clvm
+    #
+    # fixed_args = 1
+    #
+    # Each arg is prepended as fixed_args = (c (q . arg) fixed_args)
+    #
+    # The resulting argument list is interpreted with apply (2)
+    #
+    # (2 (1 . self) rest)
+    #
+    # Resulting in a function which places its own arguments after those
+    # curried in in the form of a proper list.
     def curry(self, *args) -> "Program":
-        cost, r = curry(self, list(args))
-        return Program.to(r)
+        fixed_args: Any = 1
+        for arg in reversed(args):
+            fixed_args = [4, (1, arg), fixed_args]
+        return Program.to([2, (1, self), fixed_args])
 
     def uncurry(self) -> Tuple["Program", "Program"]:
         r = uncurry(self)
diff --git a/tests/clvm/test_program.py b/tests/clvm/test_program.py
index 5960e7396..76aa5f639 100644
--- a/tests/clvm/test_program.py
+++ b/tests/clvm/test_program.py
@@ -2,6 +2,9 @@ from unittest import TestCase
 
 from chia.types.blockchain_format.program import Program
 from clvm.EvalError import EvalError
+from clvm_tools.curry import uncurry
+from clvm.operators import KEYWORD_TO_ATOM
+from clvm_tools.binutils import assemble, disassemble
 
 
 class TestProgram(TestCase):
@@ -19,3 +22,28 @@ class TestProgram(TestCase):
 
         self.assertRaises(ValueError, lambda: p.at("q"))
         self.assertRaises(EvalError, lambda: p.at("ff"))
+
+
+def check_idempotency(f, *args):
+    prg = Program.to(f)
+    curried = prg.curry(*args)
+
+    r = disassemble(curried)
+    f_0, args_0 = uncurry(curried)
+
+    assert disassemble(f_0) == disassemble(f)
+    assert disassemble(args_0) == disassemble(Program.to(list(args)))
+    return r
+
+
+def test_curry_uncurry():
+    PLUS = KEYWORD_TO_ATOM["+"][0]
+    f = assemble("(+ 2 5)")
+    actual_disassembly = check_idempotency(f, 200, 30)
+    assert actual_disassembly == f"(a (q {PLUS} 2 5) (c (q . 200) (c (q . 30) 1)))"
+
+    f = assemble("(+ 2 5)")
+    args = assemble("(+ (q . 50) (q . 60))")
+    # passing "args" here wraps the arguments in a list
+    actual_disassembly = check_idempotency(f, args)
+    assert actual_disassembly == f"(a (q {PLUS} 2 5) (c (q {PLUS} (q . 50) (q . 60)) 1))"
-- 
2.34.1


From 553e46ab6dfb31f2f1db36d18c82c3c1f7a0a422 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:43:31 +0200
Subject: [PATCH 29/77] harvester: Use a set instead of a list to speed up
 availability checks (#11204)

---
 chia/plotting/manager.py | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/chia/plotting/manager.py b/chia/plotting/manager.py
index ee158848c..72a66f629 100644
--- a/chia/plotting/manager.py
+++ b/chia/plotting/manager.py
@@ -142,9 +142,9 @@ class PlotManager:
 
                 plot_filenames: Dict[Path, List[Path]] = get_plot_filenames(self.root_path)
                 plot_directories: Set[Path] = set(plot_filenames.keys())
-                plot_paths: List[Path] = []
+                plot_paths: Set[Path] = set()
                 for paths in plot_filenames.values():
-                    plot_paths += paths
+                    plot_paths.update(paths)
 
                 total_result: PlotRefreshResult = PlotRefreshResult()
                 total_size = len(plot_paths)
@@ -184,7 +184,7 @@ class PlotManager:
                 for filename in filenames_to_remove:
                     del self.plot_filename_paths[filename]
 
-                for remaining, batch in list_to_batches(plot_paths, self.refresh_parameter.batch_size):
+                for remaining, batch in list_to_batches(list(plot_paths), self.refresh_parameter.batch_size):
                     batch_result: PlotRefreshResult = self.refresh_batch(batch, plot_directories)
                     if not self._refreshing_enabled:
                         self.log.debug("refresh_plots: Aborted")
-- 
2.34.1


From 21a968bec23dc3c300797b313a2b74f55be53404 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Wed, 20 Apr 2022 20:44:27 +0200
Subject: [PATCH 30/77] cmds: Only call `is_running` endpoint once in
 `async_start` (#11221)

---
 chia/cmds/start_funcs.py | 4 +---
 1 file changed, 1 insertion(+), 3 deletions(-)

diff --git a/chia/cmds/start_funcs.py b/chia/cmds/start_funcs.py
index 82bc4fccc..ed36fec90 100644
--- a/chia/cmds/start_funcs.py
+++ b/chia/cmds/start_funcs.py
@@ -62,9 +62,7 @@ async def async_start(root_path: Path, group: str, restart: bool) -> None:
         if await daemon.is_running(service_name=service):
             print(f"{service}: ", end="", flush=True)
             if restart:
-                if not await daemon.is_running(service_name=service):
-                    print("not running")
-                elif await daemon.stop_service(service_name=service):
+                if await daemon.stop_service(service_name=service):
                     print("stopped")
                 else:
                     print("stop failed")
-- 
2.34.1


From 797a2fb5febd92856da91076b9310a82d0bf6e7c Mon Sep 17 00:00:00 2001
From: Gene Hoffman <30377676+hoffmang9@users.noreply.github.com>
Date: Wed, 20 Apr 2022 11:44:52 -0700
Subject: [PATCH 31/77] Remove 3.9.11 for Windows Installer (#11226)

And replace with just 3.9.x
---
 .github/workflows/build-windows-installer.yml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/.github/workflows/build-windows-installer.yml b/.github/workflows/build-windows-installer.yml
index 5467d23a4..b74fefd1b 100644
--- a/.github/workflows/build-windows-installer.yml
+++ b/.github/workflows/build-windows-installer.yml
@@ -62,7 +62,7 @@ jobs:
     - uses: actions/setup-python@v2
       name: Install Python 3.9
       with:
-        python-version: "3.9.11"
+        python-version: "3.9"
 
     - name: Setup Node 16.x
       uses: actions/setup-node@v3
-- 
2.34.1


From fb6c537cfb943d3cd2268d718bfc5295812cc40b Mon Sep 17 00:00:00 2001
From: Sebastjan Trepca <trepca@gmail.com>
Date: Wed, 20 Apr 2022 20:45:30 +0200
Subject: [PATCH 32/77] Use log formatter to avoid serialisation (#11184)

* avoid serialisation in logging

* avoid serialisation in logging

* Revert "avoid serialisation in logging"

This reverts commit 4a2b4473964ecf0863ae6860e72d54a4f5d8958f.
---
 chia/daemon/server.py          | 2 +-
 chia/full_node/weight_proof.py | 2 +-
 chia/wallet/wallet_node.py     | 2 +-
 3 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/chia/daemon/server.py b/chia/daemon/server.py
index 014bb2a78..3079d8ce8 100644
--- a/chia/daemon/server.py
+++ b/chia/daemon/server.py
@@ -220,7 +220,7 @@ class WebSocketServer:
 
         while True:
             msg = await ws.receive()
-            self.log.debug(f"Received message: {msg}")
+            self.log.debug("Received message: %s", msg)
             if msg.type == WSMsgType.TEXT:
                 try:
                     decoded = json.loads(msg.data)
diff --git a/chia/full_node/weight_proof.py b/chia/full_node/weight_proof.py
index 7756b8e65..451499e96 100644
--- a/chia/full_node/weight_proof.py
+++ b/chia/full_node/weight_proof.py
@@ -99,7 +99,7 @@ class WeightProofHandler:
             if ses_height > tip_height:
                 break
             ses = self.blockchain.get_ses(ses_height)
-            log.debug(f"handle sub epoch summary {sub_epoch_n} at height: {ses_height} ses {ses}")
+            log.debug("handle sub epoch summary %s at height: %s ses %s", sub_epoch_n, ses_height, ses)
             sub_epoch_data.append(_create_sub_epoch_data(ses))
         return sub_epoch_data
 
diff --git a/chia/wallet/wallet_node.py b/chia/wallet/wallet_node.py
index f59e06754..f417e58d7 100644
--- a/chia/wallet/wallet_node.py
+++ b/chia/wallet/wallet_node.py
@@ -358,7 +358,7 @@ class WalletNode:
             try:
                 peer, item = None, None
                 item = await self.new_peak_queue.get()
-                self.log.debug(f"Pulled from queue: {item}")
+                self.log.debug("Pulled from queue: %s", item)
                 assert item is not None
                 if item.item_type == NewPeakQueueTypes.COIN_ID_SUBSCRIPTION:
                     # Subscriptions are the highest priority, because we don't want to process any more peaks or
-- 
2.34.1


From 8d510157d98e4dd094464b911d18155ecb63cc04 Mon Sep 17 00:00:00 2001
From: Adam Kelly <338792+aqk@users.noreply.github.com>
Date: Wed, 20 Apr 2022 11:46:51 -0700
Subject: [PATCH 33/77] Improve detection of disconnected websocket between
 services (#11069)

---
 chia/daemon/client.py  | 2 +-
 chia/rpc/rpc_server.py | 6 +++---
 2 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/chia/daemon/client.py b/chia/daemon/client.py
index 88677d689..b4c83c07f 100644
--- a/chia/daemon/client.py
+++ b/chia/daemon/client.py
@@ -67,7 +67,7 @@ class DaemonProxy:
         request_id = request["request_id"]
         self._request_dict[request_id] = asyncio.Event()
         string = dict_to_json_str(request)
-        if self.websocket is None:
+        if self.websocket is None or self.websocket.closed:
             raise Exception("Websocket is not connected")
         asyncio.create_task(self.websocket.send_str(string))
 
diff --git a/chia/rpc/rpc_server.py b/chia/rpc/rpc_server.py
index aff8aecaf..9fecdf575 100644
--- a/chia/rpc/rpc_server.py
+++ b/chia/rpc/rpc_server.py
@@ -54,7 +54,7 @@ class RpcServer:
             await self.client_session.close()
 
     async def _state_changed(self, *args):
-        if self.websocket is None:
+        if self.websocket is None or self.websocket.closed:
             return None
         payloads: List[Dict] = await self.rpc_api._state_changed(*args)
 
@@ -73,7 +73,7 @@ class RpcServer:
         for payload in payloads:
             if "success" not in payload["data"]:
                 payload["data"]["success"] = True
-            if self.websocket is None:
+            if self.websocket is None or self.websocket.closed:
                 return None
             try:
                 await self.websocket.send_str(dict_to_json_str(payload))
@@ -82,7 +82,7 @@ class RpcServer:
                 self.log.warning(f"Sending data failed. Exception {tb}.")
 
     def state_changed(self, *args):
-        if self.websocket is None:
+        if self.websocket is None or self.websocket.closed:
             return None
         asyncio.create_task(self._state_changed(*args))
 
-- 
2.34.1


From ef3ac41f8be30f13e9c6d98d827741d681effb0f Mon Sep 17 00:00:00 2001
From: William Blanke <wjb98672@gmail.com>
Date: Wed, 20 Apr 2022 11:52:23 -0700
Subject: [PATCH 34/77] updated bls and vdf to new releases

---
 setup.py | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/setup.py b/setup.py
index 2792f953c..55dc64d82 100644
--- a/setup.py
+++ b/setup.py
@@ -3,8 +3,8 @@ from setuptools import setup
 dependencies = [
     "multidict==5.1.0",  # Avoid 5.2.0 due to Avast
     "aiofiles==0.7.0",  # Async IO for files
-    "blspy==1.0.9",  # Signature library
-    "chiavdf==1.0.5",  # timelord and vdf verification
+    "blspy==1.0.10",  # Signature library
+    "chiavdf==1.0.6",  # timelord and vdf verification
     "chiabip158==1.1",  # bip158-style wallet filters
     "chiapos==1.0.10",  # proof of space
     "clvm==0.9.7",
-- 
2.34.1


From 25ab0c90cb34cd048463082801c3cc26bfac389a Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Thu, 21 Apr 2022 00:27:59 +0200
Subject: [PATCH 35/77] github: Fix `plot_sync` workflows after #10940 merge
 (#11241)

---
 .github/workflows/build-test-macos-plot_sync.yml  | 2 +-
 .github/workflows/build-test-ubuntu-plot_sync.yml | 2 +-
 2 files changed, 2 insertions(+), 2 deletions(-)

diff --git a/.github/workflows/build-test-macos-plot_sync.yml b/.github/workflows/build-test-macos-plot_sync.yml
index 3b72cfaff..1acd030f9 100644
--- a/.github/workflows/build-test-macos-plot_sync.yml
+++ b/.github/workflows/build-test-macos-plot_sync.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test plot_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/plot_sync/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/plot_sync/test_*.py --durations=10  -n 4 -m "not benchmark"
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-plot_sync.yml b/.github/workflows/build-test-ubuntu-plot_sync.yml
index 8be06ca85..2877a4c19 100644
--- a/.github/workflows/build-test-ubuntu-plot_sync.yml
+++ b/.github/workflows/build-test-ubuntu-plot_sync.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test plot_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc ./venv/bin/py.test tests/plot_sync/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/plot_sync/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
 
     - name: Process coverage data
       run: |
-- 
2.34.1


From 527b30e917247ab6eb747a8de12a6ced9ec6d621 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Wed, 20 Apr 2022 23:39:51 -0500
Subject: [PATCH 36/77] Add cli only rpm (#11236)

* Add cli only rpm

* Ensure rvm (fpm) is loaded before running fpm

* Use full path to fpm, since GHA seems to mess up the PATH in the container

* Add back source and add use ruby-3

* Call rpm script with bash, to see if the rvm script works

* Add --depends for libcrypt.so.1
---
 .../workflows/build-linux-installer-rpm.yml   |  2 +-
 build_scripts/build_linux_rpm.sh              | 28 +++++++++++++++++++
 2 files changed, 29 insertions(+), 1 deletion(-)

diff --git a/.github/workflows/build-linux-installer-rpm.yml b/.github/workflows/build-linux-installer-rpm.yml
index b12a702ee..36c5795aa 100644
--- a/.github/workflows/build-linux-installer-rpm.yml
+++ b/.github/workflows/build-linux-installer-rpm.yml
@@ -119,7 +119,7 @@ jobs:
         git -C ./chia-blockchain-gui status
         . ./activate
         cd ./build_scripts
-        sh build_linux_rpm.sh amd64
+        bash build_linux_rpm.sh amd64
 
     - name: Upload Linux artifacts
       uses: actions/upload-artifact@v3
diff --git a/build_scripts/build_linux_rpm.sh b/build_scripts/build_linux_rpm.sh
index 21db74f43..60829b193 100644
--- a/build_scripts/build_linux_rpm.sh
+++ b/build_scripts/build_linux_rpm.sh
@@ -43,6 +43,31 @@ if [ "$LAST_EXIT_CODE" -ne 0 ]; then
 	exit $LAST_EXIT_CODE
 fi
 
+# Builds CLI only rpm
+CLI_RPM_BASE="chia-blockchain-cli-$CHIA_INSTALLER_VERSION-1.$REDHAT_PLATFORM"
+mkdir -p "dist/$CLI_RPM_BASE/opt/chia"
+mkdir -p "dist/$CLI_RPM_BASE/usr/bin"
+cp -r dist/daemon/* "dist/$CLI_RPM_BASE/opt/chia/"
+ln -s ../../opt/chia/chia "dist/$CLI_RPM_BASE/usr/bin/chia"
+# This is built into the base build image
+# shellcheck disable=SC1091
+. /etc/profile.d/rvm.sh
+rvm use ruby-3
+# /usr/lib64/libcrypt.so.1 is marked as a dependency specifically because newer versions of fedora bundle
+# libcrypt.so.2 by default, and the libxcrypt-compat package needs to be installed for the other version
+# Marking as a dependency allows yum/dnf to automatically install the libxcrypt-compat package as well
+fpm -s dir -t rpm \
+  -C "dist/$CLI_RPM_BASE" \
+  -p "dist/$CLI_RPM_BASE.rpm" \
+  --name chia-blockchain-cli \
+  --license Apache-2.0 \
+  --version "$CHIA_INSTALLER_VERSION" \
+  --architecture "$REDHAT_PLATFORM" \
+  --description "Chia is a modern cryptocurrency built from scratch, designed to be efficient, decentralized, and secure." \
+  --depends /usr/lib64/libcrypt.so.1 \
+  .
+# CLI only rpm done
+
 cp -r dist/daemon ../chia-blockchain-gui/packages/gui
 cd .. || exit
 cd chia-blockchain-gui || exit
@@ -109,4 +134,7 @@ if [ "$REDHAT_PLATFORM" = "x86_64" ]; then
   fi
 fi
 
+# Move the cli only rpm into final installers as well, so it gets uploaded as an artifact
+mv "dist/$CLI_RPM_BASE.rpm" final_installer/
+
 ls final_installer/
-- 
2.34.1


From aaf3fbc1603d2f0efa672c09062d16d4c385bced Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Thu, 21 Apr 2022 16:58:07 -0700
Subject: [PATCH 37/77] generate file lists for workflows instead of wildcard
 patterns (#11117)

---
 .github/workflows/build-test-macos-blockchain.yml           | 2 +-
 .github/workflows/build-test-macos-clvm.yml                 | 2 +-
 .github/workflows/build-test-macos-core-cmds.yml            | 2 +-
 .github/workflows/build-test-macos-core-consensus.yml       | 2 +-
 .github/workflows/build-test-macos-core-custom_types.yml    | 2 +-
 .github/workflows/build-test-macos-core-daemon.yml          | 2 +-
 .../workflows/build-test-macos-core-full_node-full_sync.yml | 2 +-
 .../workflows/build-test-macos-core-full_node-stores.yml    | 2 +-
 .github/workflows/build-test-macos-core-full_node.yml       | 2 +-
 .github/workflows/build-test-macos-core-server.yml          | 2 +-
 .github/workflows/build-test-macos-core-ssl.yml             | 2 +-
 .github/workflows/build-test-macos-core-util.yml            | 2 +-
 .github/workflows/build-test-macos-core.yml                 | 2 +-
 .github/workflows/build-test-macos-farmer_harvester.yml     | 2 +-
 .github/workflows/build-test-macos-generator.yml            | 2 +-
 .github/workflows/build-test-macos-plot_sync.yml            | 2 +-
 .github/workflows/build-test-macos-plotting.yml             | 2 +-
 .github/workflows/build-test-macos-pools.yml                | 2 +-
 .github/workflows/build-test-macos-simulation.yml           | 2 +-
 .github/workflows/build-test-macos-tools.yml                | 2 +-
 .github/workflows/build-test-macos-util.yml                 | 2 +-
 .github/workflows/build-test-macos-wallet-cat_wallet.yml    | 2 +-
 .github/workflows/build-test-macos-wallet-did_wallet.yml    | 2 +-
 .github/workflows/build-test-macos-wallet-rl_wallet.yml     | 2 +-
 .github/workflows/build-test-macos-wallet-rpc.yml           | 2 +-
 .github/workflows/build-test-macos-wallet-simple_sync.yml   | 2 +-
 .github/workflows/build-test-macos-wallet-sync.yml          | 2 +-
 .github/workflows/build-test-macos-wallet.yml               | 2 +-
 .github/workflows/build-test-macos-weight_proof.yml         | 2 +-
 .github/workflows/build-test-ubuntu-blockchain.yml          | 2 +-
 .github/workflows/build-test-ubuntu-clvm.yml                | 2 +-
 .github/workflows/build-test-ubuntu-core-cmds.yml           | 2 +-
 .github/workflows/build-test-ubuntu-core-consensus.yml      | 2 +-
 .github/workflows/build-test-ubuntu-core-custom_types.yml   | 2 +-
 .github/workflows/build-test-ubuntu-core-daemon.yml         | 2 +-
 .../build-test-ubuntu-core-full_node-full_sync.yml          | 2 +-
 .../workflows/build-test-ubuntu-core-full_node-stores.yml   | 2 +-
 .github/workflows/build-test-ubuntu-core-full_node.yml      | 2 +-
 .github/workflows/build-test-ubuntu-core-server.yml         | 2 +-
 .github/workflows/build-test-ubuntu-core-ssl.yml            | 2 +-
 .github/workflows/build-test-ubuntu-core-util.yml           | 2 +-
 .github/workflows/build-test-ubuntu-core.yml                | 2 +-
 .github/workflows/build-test-ubuntu-farmer_harvester.yml    | 2 +-
 .github/workflows/build-test-ubuntu-generator.yml           | 2 +-
 .github/workflows/build-test-ubuntu-plot_sync.yml           | 2 +-
 .github/workflows/build-test-ubuntu-plotting.yml            | 2 +-
 .github/workflows/build-test-ubuntu-pools.yml               | 2 +-
 .github/workflows/build-test-ubuntu-simulation.yml          | 2 +-
 .github/workflows/build-test-ubuntu-tools.yml               | 2 +-
 .github/workflows/build-test-ubuntu-util.yml                | 2 +-
 .github/workflows/build-test-ubuntu-wallet-cat_wallet.yml   | 2 +-
 .github/workflows/build-test-ubuntu-wallet-did_wallet.yml   | 2 +-
 .github/workflows/build-test-ubuntu-wallet-rl_wallet.yml    | 2 +-
 .github/workflows/build-test-ubuntu-wallet-rpc.yml          | 2 +-
 .github/workflows/build-test-ubuntu-wallet-simple_sync.yml  | 2 +-
 .github/workflows/build-test-ubuntu-wallet-sync.yml         | 2 +-
 .github/workflows/build-test-ubuntu-wallet.yml              | 2 +-
 .github/workflows/build-test-ubuntu-weight_proof.yml        | 2 +-
 tests/build-workflows.py                                    | 6 ++++--
 tests/runner_templates/build-test-macos                     | 2 +-
 tests/runner_templates/build-test-ubuntu                    | 2 +-
 61 files changed, 64 insertions(+), 62 deletions(-)

diff --git a/.github/workflows/build-test-macos-blockchain.yml b/.github/workflows/build-test-macos-blockchain.yml
index 01dd68588..cd92c3e12 100644
--- a/.github/workflows/build-test-macos-blockchain.yml
+++ b/.github/workflows/build-test-macos-blockchain.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test blockchain code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/blockchain/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/blockchain/test_blockchain.py tests/blockchain/test_blockchain_transactions.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-clvm.yml b/.github/workflows/build-test-macos-clvm.yml
index f27f9e651..213aeaee5 100644
--- a/.github/workflows/build-test-macos-clvm.yml
+++ b/.github/workflows/build-test-macos-clvm.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test clvm code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/clvm/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/clvm/test_chialisp_deserialization.py tests/clvm/test_clvm_compilation.py tests/clvm/test_program.py tests/clvm/test_puzzle_compression.py tests/clvm/test_puzzles.py tests/clvm/test_serialized_program.py tests/clvm/test_singletons.py tests/clvm/test_spend_sim.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-cmds.yml b/.github/workflows/build-test-macos-core-cmds.yml
index f67ad25e3..ad056811e 100644
--- a/.github/workflows/build-test-macos-core-cmds.yml
+++ b/.github/workflows/build-test-macos-core-cmds.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test core-cmds code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/cmds/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/core/cmds/test_keys.py tests/core/cmds/test_wallet.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-consensus.yml b/.github/workflows/build-test-macos-core-consensus.yml
index a5aad6169..8cded054e 100644
--- a/.github/workflows/build-test-macos-core-consensus.yml
+++ b/.github/workflows/build-test-macos-core-consensus.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test core-consensus code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/consensus/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/core/consensus/test_pot_iterations.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-custom_types.yml b/.github/workflows/build-test-macos-core-custom_types.yml
index f2dad4ff3..f8d950e36 100644
--- a/.github/workflows/build-test-macos-core-custom_types.yml
+++ b/.github/workflows/build-test-macos-core-custom_types.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test core-custom_types code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/custom_types/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/core/custom_types/test_coin.py tests/core/custom_types/test_proof_of_space.py tests/core/custom_types/test_spend_bundle.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-daemon.yml b/.github/workflows/build-test-macos-core-daemon.yml
index a679447ef..7be54a932 100644
--- a/.github/workflows/build-test-macos-core-daemon.yml
+++ b/.github/workflows/build-test-macos-core-daemon.yml
@@ -97,7 +97,7 @@ jobs:
     - name: Test core-daemon code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/daemon/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/core/daemon/test_daemon.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-full_node-full_sync.yml b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
index c613bcb87..552b0a4a8 100644
--- a/.github/workflows/build-test-macos-core-full_node-full_sync.yml
+++ b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-full_node-full_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/full_sync/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/core/full_node/full_sync/test_full_sync.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-full_node-stores.yml b/.github/workflows/build-test-macos-core-full_node-stores.yml
index b6cd2c45d..06f362dcb 100644
--- a/.github/workflows/build-test-macos-core-full_node-stores.yml
+++ b/.github/workflows/build-test-macos-core-full_node-stores.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-full_node-stores code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/stores/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/core/full_node/stores/test_block_store.py tests/core/full_node/stores/test_coin_store.py tests/core/full_node/stores/test_full_node_store.py tests/core/full_node/stores/test_hint_store.py tests/core/full_node/stores/test_sync_store.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-full_node.yml b/.github/workflows/build-test-macos-core-full_node.yml
index 2fa7e3c51..9db1b8b8d 100644
--- a/.github/workflows/build-test-macos-core-full_node.yml
+++ b/.github/workflows/build-test-macos-core-full_node.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-full_node code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/core/full_node/test_address_manager.py tests/core/full_node/test_block_height_map.py tests/core/full_node/test_conditions.py tests/core/full_node/test_full_node.py tests/core/full_node/test_mempool.py tests/core/full_node/test_mempool_performance.py tests/core/full_node/test_node_load.py tests/core/full_node/test_peer_store_resolver.py tests/core/full_node/test_performance.py tests/core/full_node/test_transactions.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-server.yml b/.github/workflows/build-test-macos-core-server.yml
index 0fa88e48f..f80358b7d 100644
--- a/.github/workflows/build-test-macos-core-server.yml
+++ b/.github/workflows/build-test-macos-core-server.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-server code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/server/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/core/server/test_dos.py tests/core/server/test_rate_limits.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-ssl.yml b/.github/workflows/build-test-macos-core-ssl.yml
index 4a11ccd2e..1711e2d80 100644
--- a/.github/workflows/build-test-macos-core-ssl.yml
+++ b/.github/workflows/build-test-macos-core-ssl.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-ssl code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/ssl/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/core/ssl/test_ssl.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core-util.yml b/.github/workflows/build-test-macos-core-util.yml
index a17bb909b..a062fdd09 100644
--- a/.github/workflows/build-test-macos-core-util.yml
+++ b/.github/workflows/build-test-macos-core-util.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core-util code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/util/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/core/util/test_cached_bls.py tests/core/util/test_config.py tests/core/util/test_db_wrapper.py tests/core/util/test_file_keyring_synchronization.py tests/core/util/test_files.py tests/core/util/test_keychain.py tests/core/util/test_keyring_wrapper.py tests/core/util/test_lru_cache.py tests/core/util/test_significant_bits.py tests/core/util/test_streamable.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-core.yml b/.github/workflows/build-test-macos-core.yml
index be7d8fcab..5734712dd 100644
--- a/.github/workflows/build-test-macos-core.yml
+++ b/.github/workflows/build-test-macos-core.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test core code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/core/test_cost_calculation.py tests/core/test_crawler_rpc.py tests/core/test_daemon_rpc.py tests/core/test_db_conversion.py tests/core/test_db_validation.py tests/core/test_farmer_harvester_rpc.py tests/core/test_filter.py tests/core/test_full_node_rpc.py tests/core/test_merkle_set.py tests/core/test_setproctitle.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-farmer_harvester.yml b/.github/workflows/build-test-macos-farmer_harvester.yml
index 0286aba80..9ebfb33cf 100644
--- a/.github/workflows/build-test-macos-farmer_harvester.yml
+++ b/.github/workflows/build-test-macos-farmer_harvester.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test farmer_harvester code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/farmer_harvester/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/farmer_harvester/test_farmer_harvester.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-generator.yml b/.github/workflows/build-test-macos-generator.yml
index ccce30af6..3579b3423 100644
--- a/.github/workflows/build-test-macos-generator.yml
+++ b/.github/workflows/build-test-macos-generator.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test generator code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/generator/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/generator/test_compression.py tests/generator/test_generator_types.py tests/generator/test_list_to_batches.py tests/generator/test_rom.py tests/generator/test_scan.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-plot_sync.yml b/.github/workflows/build-test-macos-plot_sync.yml
index 1acd030f9..9933ce387 100644
--- a/.github/workflows/build-test-macos-plot_sync.yml
+++ b/.github/workflows/build-test-macos-plot_sync.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test plot_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/plot_sync/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/plot_sync/test_delta.py tests/plot_sync/test_plot_sync.py tests/plot_sync/test_receiver.py tests/plot_sync/test_sender.py tests/plot_sync/test_sync_simulated.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-plotting.yml b/.github/workflows/build-test-macos-plotting.yml
index 561f1fa81..c4567aa62 100644
--- a/.github/workflows/build-test-macos-plotting.yml
+++ b/.github/workflows/build-test-macos-plotting.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test plotting code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/plotting/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/plotting/test_plot_manager.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-pools.yml b/.github/workflows/build-test-macos-pools.yml
index 8b36cbc7c..f2bad167a 100644
--- a/.github/workflows/build-test-macos-pools.yml
+++ b/.github/workflows/build-test-macos-pools.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test pools code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/pools/test_*.py --durations=10  -n 2 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 2 -m "not benchmark" tests/pools/test_pool_cmdline.py tests/pools/test_pool_config.py tests/pools/test_pool_puzzles_lifecycle.py tests/pools/test_pool_rpc.py tests/pools/test_pool_wallet.py tests/pools/test_wallet_pool_store.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-simulation.yml b/.github/workflows/build-test-macos-simulation.yml
index b1e2e79f6..aee486d14 100644
--- a/.github/workflows/build-test-macos-simulation.yml
+++ b/.github/workflows/build-test-macos-simulation.yml
@@ -97,7 +97,7 @@ jobs:
     - name: Test simulation code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/simulation/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/simulation/test_simulation.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-tools.yml b/.github/workflows/build-test-macos-tools.yml
index 4be349499..dbded6899 100644
--- a/.github/workflows/build-test-macos-tools.yml
+++ b/.github/workflows/build-test-macos-tools.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test tools code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/tools/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/tools/test_full_sync.py tests/tools/test_run_block.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-util.yml b/.github/workflows/build-test-macos-util.yml
index 136cbfe8f..74ecf863b 100644
--- a/.github/workflows/build-test-macos-util.yml
+++ b/.github/workflows/build-test-macos-util.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test util code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/util/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/util/test_chunks.py tests/util/test_full_block_utils.py tests/util/test_lock_queue.py tests/util/test_network_protocol_files.py tests/util/test_struct_stream.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-cat_wallet.yml b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
index 5bceb86a7..59c3a94a4 100644
--- a/.github/workflows/build-test-macos-wallet-cat_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet-cat_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/cat_wallet/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/wallet/cat_wallet/test_cat_lifecycle.py tests/wallet/cat_wallet/test_cat_wallet.py tests/wallet/cat_wallet/test_offer_lifecycle.py tests/wallet/cat_wallet/test_trades.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-did_wallet.yml b/.github/workflows/build-test-macos-wallet-did_wallet.yml
index c182bc72c..115a025e4 100644
--- a/.github/workflows/build-test-macos-wallet-did_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-did_wallet.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test wallet-did_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/did_wallet/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/wallet/did_wallet/test_did.py tests/wallet/did_wallet/test_did_rpc.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-rl_wallet.yml b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
index 3045f4be0..6a1fec488 100644
--- a/.github/workflows/build-test-macos-wallet-rl_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
@@ -79,7 +79,7 @@ jobs:
     - name: Test wallet-rl_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/rl_wallet/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/wallet/rl_wallet/test_rl_rpc.py tests/wallet/rl_wallet/test_rl_wallet.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-rpc.yml b/.github/workflows/build-test-macos-wallet-rpc.yml
index 12a24bd1f..6a3acae8b 100644
--- a/.github/workflows/build-test-macos-wallet-rpc.yml
+++ b/.github/workflows/build-test-macos-wallet-rpc.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet-rpc code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/rpc/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/wallet/rpc/test_wallet_rpc.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-simple_sync.yml b/.github/workflows/build-test-macos-wallet-simple_sync.yml
index d8cf60ed0..0944cc2ea 100644
--- a/.github/workflows/build-test-macos-wallet-simple_sync.yml
+++ b/.github/workflows/build-test-macos-wallet-simple_sync.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet-simple_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/simple_sync/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/wallet/simple_sync/test_simple_sync_protocol.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet-sync.yml b/.github/workflows/build-test-macos-wallet-sync.yml
index ad4c852c3..f828659f0 100644
--- a/.github/workflows/build-test-macos-wallet-sync.yml
+++ b/.github/workflows/build-test-macos-wallet-sync.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet-sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/sync/test_*.py --durations=10  -n 0 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" tests/wallet/sync/test_wallet_sync.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-wallet.yml b/.github/workflows/build-test-macos-wallet.yml
index c4be58dd0..6bc89ae0b 100644
--- a/.github/workflows/build-test-macos-wallet.yml
+++ b/.github/workflows/build-test-macos-wallet.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/wallet/test_bech32m.py tests/wallet/test_chialisp.py tests/wallet/test_puzzle_store.py tests/wallet/test_singleton.py tests/wallet/test_singleton_lifecycle.py tests/wallet/test_singleton_lifecycle_fast.py tests/wallet/test_taproot.py tests/wallet/test_wallet.py tests/wallet/test_wallet_blockchain.py tests/wallet/test_wallet_interested_store.py tests/wallet/test_wallet_key_val_store.py tests/wallet/test_wallet_store.py tests/wallet/test_wallet_user_store.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-macos-weight_proof.yml b/.github/workflows/build-test-macos-weight_proof.yml
index 2690434d8..cec62d95f 100644
--- a/.github/workflows/build-test-macos-weight_proof.yml
+++ b/.github/workflows/build-test-macos-weight_proof.yml
@@ -93,7 +93,7 @@ jobs:
     - name: Test weight_proof code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/weight_proof/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" tests/weight_proof/test_weight_proof.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-blockchain.yml b/.github/workflows/build-test-ubuntu-blockchain.yml
index a670a85e0..c19918886 100644
--- a/.github/workflows/build-test-ubuntu-blockchain.yml
+++ b/.github/workflows/build-test-ubuntu-blockchain.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test blockchain code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/blockchain/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/blockchain/test_blockchain.py tests/blockchain/test_blockchain_transactions.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-clvm.yml b/.github/workflows/build-test-ubuntu-clvm.yml
index 0c8bcd74d..8b8d97e0d 100644
--- a/.github/workflows/build-test-ubuntu-clvm.yml
+++ b/.github/workflows/build-test-ubuntu-clvm.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test clvm code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/clvm/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/clvm/test_chialisp_deserialization.py tests/clvm/test_clvm_compilation.py tests/clvm/test_program.py tests/clvm/test_puzzle_compression.py tests/clvm/test_puzzles.py tests/clvm/test_serialized_program.py tests/clvm/test_singletons.py tests/clvm/test_spend_sim.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-cmds.yml b/.github/workflows/build-test-ubuntu-core-cmds.yml
index 1e99104ff..7edd499d9 100644
--- a/.github/workflows/build-test-ubuntu-core-cmds.yml
+++ b/.github/workflows/build-test-ubuntu-core-cmds.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test core-cmds code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/cmds/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/core/cmds/test_keys.py tests/core/cmds/test_wallet.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-consensus.yml b/.github/workflows/build-test-ubuntu-core-consensus.yml
index 8f589ae91..2f7fc109b 100644
--- a/.github/workflows/build-test-ubuntu-core-consensus.yml
+++ b/.github/workflows/build-test-ubuntu-core-consensus.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test core-consensus code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/consensus/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/core/consensus/test_pot_iterations.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-custom_types.yml b/.github/workflows/build-test-ubuntu-core-custom_types.yml
index 14a7817de..559f5b982 100644
--- a/.github/workflows/build-test-ubuntu-core-custom_types.yml
+++ b/.github/workflows/build-test-ubuntu-core-custom_types.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test core-custom_types code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/custom_types/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/core/custom_types/test_coin.py tests/core/custom_types/test_proof_of_space.py tests/core/custom_types/test_spend_bundle.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-daemon.yml b/.github/workflows/build-test-ubuntu-core-daemon.yml
index 3f9d4328f..eb0cf56ff 100644
--- a/.github/workflows/build-test-ubuntu-core-daemon.yml
+++ b/.github/workflows/build-test-ubuntu-core-daemon.yml
@@ -96,7 +96,7 @@ jobs:
     - name: Test core-daemon code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/daemon/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/core/daemon/test_daemon.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml b/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
index 9cb55ba9a..24cdeb5c3 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-full_node-full_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/full_sync/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/core/full_node/full_sync/test_full_sync.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-full_node-stores.yml b/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
index 03661c5ca..468870192 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-full_node-stores code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/stores/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark"  tests/core/full_node/stores/test_block_store.py tests/core/full_node/stores/test_coin_store.py tests/core/full_node/stores/test_full_node_store.py tests/core/full_node/stores/test_hint_store.py tests/core/full_node/stores/test_sync_store.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-full_node.yml b/.github/workflows/build-test-ubuntu-core-full_node.yml
index cbfbcf5db..34f8f746e 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-full_node code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/full_node/test_*.py --durations=10  -n 4 -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark"  tests/core/full_node/test_address_manager.py tests/core/full_node/test_block_height_map.py tests/core/full_node/test_conditions.py tests/core/full_node/test_full_node.py tests/core/full_node/test_mempool.py tests/core/full_node/test_mempool_performance.py tests/core/full_node/test_node_load.py tests/core/full_node/test_peer_store_resolver.py tests/core/full_node/test_performance.py tests/core/full_node/test_transactions.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-server.yml b/.github/workflows/build-test-ubuntu-core-server.yml
index 2e29e7c5f..adef8eb31 100644
--- a/.github/workflows/build-test-ubuntu-core-server.yml
+++ b/.github/workflows/build-test-ubuntu-core-server.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-server code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/server/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/core/server/test_dos.py tests/core/server/test_rate_limits.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-ssl.yml b/.github/workflows/build-test-ubuntu-core-ssl.yml
index 931892d87..031b4d71e 100644
--- a/.github/workflows/build-test-ubuntu-core-ssl.yml
+++ b/.github/workflows/build-test-ubuntu-core-ssl.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-ssl code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/ssl/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/core/ssl/test_ssl.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core-util.yml b/.github/workflows/build-test-ubuntu-core-util.yml
index 6b40c42a7..41ae35a25 100644
--- a/.github/workflows/build-test-ubuntu-core-util.yml
+++ b/.github/workflows/build-test-ubuntu-core-util.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core-util code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/util/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/core/util/test_cached_bls.py tests/core/util/test_config.py tests/core/util/test_db_wrapper.py tests/core/util/test_file_keyring_synchronization.py tests/core/util/test_files.py tests/core/util/test_keychain.py tests/core/util/test_keyring_wrapper.py tests/core/util/test_lru_cache.py tests/core/util/test_significant_bits.py tests/core/util/test_streamable.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-core.yml b/.github/workflows/build-test-ubuntu-core.yml
index 49c5c21e4..216984f64 100644
--- a/.github/workflows/build-test-ubuntu-core.yml
+++ b/.github/workflows/build-test-ubuntu-core.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test core code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/core/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/core/test_cost_calculation.py tests/core/test_crawler_rpc.py tests/core/test_daemon_rpc.py tests/core/test_db_conversion.py tests/core/test_db_validation.py tests/core/test_farmer_harvester_rpc.py tests/core/test_filter.py tests/core/test_full_node_rpc.py tests/core/test_merkle_set.py tests/core/test_setproctitle.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-farmer_harvester.yml b/.github/workflows/build-test-ubuntu-farmer_harvester.yml
index 2304dadab..0e4cdbc82 100644
--- a/.github/workflows/build-test-ubuntu-farmer_harvester.yml
+++ b/.github/workflows/build-test-ubuntu-farmer_harvester.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test farmer_harvester code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/farmer_harvester/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/farmer_harvester/test_farmer_harvester.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-generator.yml b/.github/workflows/build-test-ubuntu-generator.yml
index 17f9b1ce5..e3dc6aaa9 100644
--- a/.github/workflows/build-test-ubuntu-generator.yml
+++ b/.github/workflows/build-test-ubuntu-generator.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test generator code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/generator/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/generator/test_compression.py tests/generator/test_generator_types.py tests/generator/test_list_to_batches.py tests/generator/test_rom.py tests/generator/test_scan.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-plot_sync.yml b/.github/workflows/build-test-ubuntu-plot_sync.yml
index 2877a4c19..26f8be548 100644
--- a/.github/workflows/build-test-ubuntu-plot_sync.yml
+++ b/.github/workflows/build-test-ubuntu-plot_sync.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test plot_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/plot_sync/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/plot_sync/test_delta.py tests/plot_sync/test_plot_sync.py tests/plot_sync/test_receiver.py tests/plot_sync/test_sender.py tests/plot_sync/test_sync_simulated.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-plotting.yml b/.github/workflows/build-test-ubuntu-plotting.yml
index 32bf337ea..4d4d4ef4f 100644
--- a/.github/workflows/build-test-ubuntu-plotting.yml
+++ b/.github/workflows/build-test-ubuntu-plotting.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test plotting code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/plotting/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/plotting/test_plot_manager.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-pools.yml b/.github/workflows/build-test-ubuntu-pools.yml
index bfbe02312..69b8d42fb 100644
--- a/.github/workflows/build-test-ubuntu-pools.yml
+++ b/.github/workflows/build-test-ubuntu-pools.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test pools code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/pools/test_*.py --durations=10  -n 2 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 2 -m "not benchmark" -p no:monitor tests/pools/test_pool_cmdline.py tests/pools/test_pool_config.py tests/pools/test_pool_puzzles_lifecycle.py tests/pools/test_pool_rpc.py tests/pools/test_pool_wallet.py tests/pools/test_wallet_pool_store.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-simulation.yml b/.github/workflows/build-test-ubuntu-simulation.yml
index b286ebdb2..be3dfca01 100644
--- a/.github/workflows/build-test-ubuntu-simulation.yml
+++ b/.github/workflows/build-test-ubuntu-simulation.yml
@@ -96,7 +96,7 @@ jobs:
     - name: Test simulation code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/simulation/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/simulation/test_simulation.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-tools.yml b/.github/workflows/build-test-ubuntu-tools.yml
index b07714020..4ed939841 100644
--- a/.github/workflows/build-test-ubuntu-tools.yml
+++ b/.github/workflows/build-test-ubuntu-tools.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test tools code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/tools/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/tools/test_full_sync.py tests/tools/test_run_block.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-util.yml b/.github/workflows/build-test-ubuntu-util.yml
index ff9f5dbf3..b973a8f52 100644
--- a/.github/workflows/build-test-ubuntu-util.yml
+++ b/.github/workflows/build-test-ubuntu-util.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test util code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/util/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/util/test_chunks.py tests/util/test_full_block_utils.py tests/util/test_lock_queue.py tests/util/test_network_protocol_files.py tests/util/test_struct_stream.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
index 1c04603e0..d7bfb2dc8 100644
--- a/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet-cat_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/cat_wallet/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/wallet/cat_wallet/test_cat_lifecycle.py tests/wallet/cat_wallet/test_cat_wallet.py tests/wallet/cat_wallet/test_offer_lifecycle.py tests/wallet/cat_wallet/test_trades.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
index 8bf4e33a3..bd47b8609 100644
--- a/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test wallet-did_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/did_wallet/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/wallet/did_wallet/test_did.py tests/wallet/did_wallet/test_did_rpc.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
index 2eefca2d0..5444f3bda 100644
--- a/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
@@ -78,7 +78,7 @@ jobs:
     - name: Test wallet-rl_wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/rl_wallet/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/wallet/rl_wallet/test_rl_rpc.py tests/wallet/rl_wallet/test_rl_wallet.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-rpc.yml b/.github/workflows/build-test-ubuntu-wallet-rpc.yml
index 36a38b740..ee196ca3f 100644
--- a/.github/workflows/build-test-ubuntu-wallet-rpc.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-rpc.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet-rpc code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/rpc/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/wallet/rpc/test_wallet_rpc.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml b/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
index bd6925631..0ec30ae4a 100644
--- a/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet-simple_sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/simple_sync/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/wallet/simple_sync/test_simple_sync_protocol.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet-sync.yml b/.github/workflows/build-test-ubuntu-wallet-sync.yml
index c607a7028..eeecfe12a 100644
--- a/.github/workflows/build-test-ubuntu-wallet-sync.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-sync.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet-sync code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/sync/test_*.py --durations=10  -n 0 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 0 -m "not benchmark" -p no:monitor tests/wallet/sync/test_wallet_sync.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-wallet.yml b/.github/workflows/build-test-ubuntu-wallet.yml
index 349879eda..35fe07923 100644
--- a/.github/workflows/build-test-ubuntu-wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test wallet code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/wallet/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/wallet/test_bech32m.py tests/wallet/test_chialisp.py tests/wallet/test_puzzle_store.py tests/wallet/test_singleton.py tests/wallet/test_singleton_lifecycle.py tests/wallet/test_singleton_lifecycle_fast.py tests/wallet/test_taproot.py tests/wallet/test_wallet.py tests/wallet/test_wallet_blockchain.py tests/wallet/test_wallet_interested_store.py tests/wallet/test_wallet_key_val_store.py tests/wallet/test_wallet_store.py tests/wallet/test_wallet_user_store.py
 
     - name: Process coverage data
       run: |
diff --git a/.github/workflows/build-test-ubuntu-weight_proof.yml b/.github/workflows/build-test-ubuntu-weight_proof.yml
index 2616c1d40..4e52234bd 100644
--- a/.github/workflows/build-test-ubuntu-weight_proof.yml
+++ b/.github/workflows/build-test-ubuntu-weight_proof.yml
@@ -92,7 +92,7 @@ jobs:
     - name: Test weight_proof code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest tests/weight_proof/test_*.py --durations=10  -n 4 -m "not benchmark" -p no:monitor
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10  -n 4 -m "not benchmark" -p no:monitor tests/weight_proof/test_weight_proof.py
 
     - name: Process coverage data
       run: |
diff --git a/tests/build-workflows.py b/tests/build-workflows.py
index 9be0e7933..06593900d 100755
--- a/tests/build-workflows.py
+++ b/tests/build-workflows.py
@@ -72,7 +72,7 @@ def generate_replacements(conf, dir):
             Path(root_path / "runner_templates/check-resource-usage.include.yml")
         ).rstrip(),
         "DISABLE_PYTEST_MONITOR": "",
-        "TEST_DIR": "",
+        "TEST_FILES": "",
         "TEST_NAME": "",
         "PYTEST_PARALLEL_ARGS": "",
     }
@@ -88,7 +88,9 @@ def generate_replacements(conf, dir):
         replacements["INSTALL_TIMELORD"] = "# Omitted installing Timelord"
     if conf["job_timeout"]:
         replacements["JOB_TIMEOUT"] = str(conf["job_timeout"])
-    replacements["TEST_DIR"] = "/".join([*dir.relative_to(root_path.parent).parts, "test_*.py"])
+    test_files = sorted(dir.glob("test_*.py"))
+    test_file_paths = [file.relative_to(root_path.parent).as_posix() for file in test_files]
+    replacements["TEST_FILES"] = " ".join(test_file_paths)
     replacements["TEST_NAME"] = test_name(dir)
     if "test_name" in conf:
         replacements["TEST_NAME"] = conf["test_name"]
diff --git a/tests/runner_templates/build-test-macos b/tests/runner_templates/build-test-macos
index 94ea0d294..25417a8d9 100644
--- a/tests/runner_templates/build-test-macos
+++ b/tests/runner_templates/build-test-macos
@@ -79,7 +79,7 @@ INSTALL_TIMELORD
     - name: Test TEST_NAME code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest TEST_DIR --durations=10 PYTEST_PARALLEL_ARGS -m "not benchmark"
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10 PYTEST_PARALLEL_ARGS -m "not benchmark" TEST_FILES
 
     - name: Process coverage data
       run: |
diff --git a/tests/runner_templates/build-test-ubuntu b/tests/runner_templates/build-test-ubuntu
index 1fc0c78a1..dae0a828a 100644
--- a/tests/runner_templates/build-test-ubuntu
+++ b/tests/runner_templates/build-test-ubuntu
@@ -78,7 +78,7 @@ INSTALL_TIMELORD
     - name: Test TEST_NAME code with pytest
       run: |
         . ./activate
-        venv/bin/coverage run --rcfile=.coveragerc --module pytest TEST_DIR --durations=10 PYTEST_PARALLEL_ARGS -m "not benchmark" DISABLE_PYTEST_MONITOR
+        venv/bin/coverage run --rcfile=.coveragerc --module pytest --durations=10 PYTEST_PARALLEL_ARGS -m "not benchmark" DISABLE_PYTEST_MONITOR TEST_FILES
 
     - name: Process coverage data
       run: |
-- 
2.34.1


From 2f477bb93783fe9e577519029fe30d69e6e8e10f Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Fri, 22 Apr 2022 01:58:35 +0200
Subject: [PATCH 38/77] harvester: Tweak `get_plots` RPC (#11246)

---
 chia/harvester/harvester.py | 3 +--
 1 file changed, 1 insertion(+), 2 deletions(-)

diff --git a/chia/harvester/harvester.py b/chia/harvester/harvester.py
index ff5ba444f..0b615a5bb 100644
--- a/chia/harvester/harvester.py
+++ b/chia/harvester/harvester.py
@@ -118,13 +118,12 @@ class Harvester:
                     {
                         "filename": str(path),
                         "size": prover.get_size(),
-                        "plot-seed": prover.get_id(),  # Deprecated
                         "plot_id": prover.get_id(),
                         "pool_public_key": plot_info.pool_public_key,
                         "pool_contract_puzzle_hash": plot_info.pool_contract_puzzle_hash,
                         "plot_public_key": plot_info.plot_public_key,
                         "file_size": plot_info.file_size,
-                        "time_modified": plot_info.time_modified,
+                        "time_modified": int(plot_info.time_modified),
                     }
                 )
             self.log.debug(
-- 
2.34.1


From cb98258a8ef1117f3c26d0b7caa3d5a28d49e0b3 Mon Sep 17 00:00:00 2001
From: Earle Lowe <30607889+emlowe@users.noreply.github.com>
Date: Thu, 21 Apr 2022 16:59:11 -0700
Subject: [PATCH 39/77] Check observer addresses (#11259)

---
 chia/farmer/farmer.py                   | 38 +++++++++++----------
 chia/rpc/farmer_rpc_api.py              |  3 +-
 chia/rpc/farmer_rpc_client.py           |  7 ++--
 chia/rpc/wallet_rpc_api.py              | 42 ++++++++++-------------
 chia/rpc/wallet_rpc_client.py           |  4 +--
 chia/wallet/derive_keys.py              | 37 +++++++++++++++++++--
 tests/core/test_farmer_harvester_rpc.py | 44 ++++++++++++++++---------
 tests/wallet/rpc/test_wallet_rpc.py     | 34 +++++++++++++++++--
 8 files changed, 143 insertions(+), 66 deletions(-)

diff --git a/chia/farmer/farmer.py b/chia/farmer/farmer.py
index b2d2436b4..3e79ed2da 100644
--- a/chia/farmer/farmer.py
+++ b/chia/farmer/farmer.py
@@ -4,13 +4,12 @@ import logging
 import time
 import traceback
 from pathlib import Path
-from typing import Any, Callable, Dict, List, Optional, Tuple
+from typing import Any, Callable, Dict, List, Optional, Set, Tuple
 
 import aiohttp
 from blspy import AugSchemeMPL, G1Element, G2Element, PrivateKey
 
 import chia.server.ws_connection as ws  # lgtm [py/import-and-import-from]
-from chia.consensus.coinbase import create_puzzlehash_for_pk
 from chia.consensus.constants import ConsensusConstants
 from chia.daemon.keychain_proxy import (
     KeychainProxy,
@@ -51,7 +50,7 @@ from chia.wallet.derive_keys import (
     find_owner_sk,
     master_sk_to_farmer_sk,
     master_sk_to_pool_sk,
-    master_sk_to_wallet_sk,
+    match_address_to_sk,
 )
 from chia.wallet.puzzles.singleton_top_layer import SINGLETON_MOD
 
@@ -503,7 +502,7 @@ class Farmer:
                         farmer_info, error_code = await update_pool_farmer_info()
                         if error_code == PoolErrorCode.FARMER_NOT_KNOWN:
                             # Make the farmer known on the pool with a POST /farmer
-                            owner_sk_and_index: Optional[PrivateKey, uint32] = find_owner_sk(
+                            owner_sk_and_index: Optional[Tuple[PrivateKey, uint32]] = find_owner_sk(
                                 self.all_root_sks, pool_config.owner_public_key
                             )
                             assert owner_sk_and_index is not None
@@ -527,7 +526,7 @@ class Farmer:
                             and pool_config.payout_instructions.lower() != farmer_info.payout_instructions.lower()
                         )
                         if payout_instructions_update_required or error_code == PoolErrorCode.INVALID_SIGNATURE:
-                            owner_sk_and_index: Optional[PrivateKey, uint32] = find_owner_sk(
+                            owner_sk_and_index: Optional[Tuple[PrivateKey, uint32]] = find_owner_sk(
                                 self.all_root_sks, pool_config.owner_public_key
                             )
                             assert owner_sk_and_index is not None
@@ -550,25 +549,30 @@ class Farmer:
     def get_private_keys(self):
         return self._private_keys
 
-    async def get_reward_targets(self, search_for_private_key: bool) -> Dict:
+    async def get_reward_targets(self, search_for_private_key: bool, max_ph_to_search: int = 500) -> Dict:
         if search_for_private_key:
             all_sks = await self.get_all_private_keys()
-            stop_searching_for_farmer, stop_searching_for_pool = False, False
-            for i in range(500):
-                if stop_searching_for_farmer and stop_searching_for_pool and i > 0:
+            have_farmer_sk, have_pool_sk = False, False
+            search_addresses: List[bytes32] = [self.farmer_target, self.pool_target]
+            for sk, _ in all_sks:
+                found_addresses: Set[bytes32] = match_address_to_sk(sk, search_addresses, max_ph_to_search)
+
+                if not have_farmer_sk and self.farmer_target in found_addresses:
+                    search_addresses.remove(self.farmer_target)
+                    have_farmer_sk = True
+
+                if not have_pool_sk and self.pool_target in found_addresses:
+                    search_addresses.remove(self.pool_target)
+                    have_pool_sk = True
+
+                if have_farmer_sk and have_pool_sk:
                     break
-                for sk, _ in all_sks:
-                    ph = create_puzzlehash_for_pk(master_sk_to_wallet_sk(sk, uint32(i)).get_g1())
 
-                    if ph == self.farmer_target:
-                        stop_searching_for_farmer = True
-                    if ph == self.pool_target:
-                        stop_searching_for_pool = True
             return {
                 "farmer_target": self.farmer_target_encoded,
                 "pool_target": self.pool_target_encoded,
-                "have_farmer_sk": stop_searching_for_farmer,
-                "have_pool_sk": stop_searching_for_pool,
+                "have_farmer_sk": have_farmer_sk,
+                "have_pool_sk": have_pool_sk,
             }
         return {
             "farmer_target": self.farmer_target_encoded,
diff --git a/chia/rpc/farmer_rpc_api.py b/chia/rpc/farmer_rpc_api.py
index 396a3c476..0c0a7b6e1 100644
--- a/chia/rpc/farmer_rpc_api.py
+++ b/chia/rpc/farmer_rpc_api.py
@@ -97,7 +97,8 @@ class FarmerRpcApi:
 
     async def get_reward_targets(self, request: Dict) -> Dict:
         search_for_private_key = request["search_for_private_key"]
-        return await self.service.get_reward_targets(search_for_private_key)
+        max_ph_to_search = request.get("max_ph_to_search", 500)
+        return await self.service.get_reward_targets(search_for_private_key, max_ph_to_search)
 
     async def set_reward_targets(self, request: Dict) -> Dict:
         farmer_target, pool_target = None, None
diff --git a/chia/rpc/farmer_rpc_client.py b/chia/rpc/farmer_rpc_client.py
index 545b052f9..e746614ee 100644
--- a/chia/rpc/farmer_rpc_client.py
+++ b/chia/rpc/farmer_rpc_client.py
@@ -22,8 +22,11 @@ class FarmerRpcClient(RpcClient):
     async def get_signage_points(self) -> List[Dict]:
         return (await self.fetch("get_signage_points", {}))["signage_points"]
 
-    async def get_reward_targets(self, search_for_private_key: bool) -> Dict:
-        response = await self.fetch("get_reward_targets", {"search_for_private_key": search_for_private_key})
+    async def get_reward_targets(self, search_for_private_key: bool, max_ph_to_search: int = 500) -> Dict:
+        response = await self.fetch(
+            "get_reward_targets",
+            {"search_for_private_key": search_for_private_key, "max_ph_to_search": max_ph_to_search},
+        )
         return_dict = {
             "farmer_target": response["farmer_target"],
             "pool_target": response["pool_target"],
diff --git a/chia/rpc/wallet_rpc_api.py b/chia/rpc/wallet_rpc_api.py
index d4e782041..ef31c275f 100644
--- a/chia/rpc/wallet_rpc_api.py
+++ b/chia/rpc/wallet_rpc_api.py
@@ -24,10 +24,15 @@ from chia.util.path import path_from_root
 from chia.util.ws_message import WsRpcMessage, create_payload_dict
 from chia.wallet.cat_wallet.cat_constants import DEFAULT_CATS
 from chia.wallet.cat_wallet.cat_wallet import CATWallet
-from chia.wallet.derive_keys import master_sk_to_singleton_owner_sk, master_sk_to_wallet_sk_unhardened, MAX_POOL_WALLETS
-from chia.wallet.rl_wallet.rl_wallet import RLWallet
-from chia.wallet.derive_keys import master_sk_to_farmer_sk, master_sk_to_pool_sk, master_sk_to_wallet_sk
+from chia.wallet.derive_keys import (
+    MAX_POOL_WALLETS,
+    master_sk_to_farmer_sk,
+    master_sk_to_pool_sk,
+    master_sk_to_singleton_owner_sk,
+    match_address_to_sk,
+)
 from chia.wallet.did_wallet.did_wallet import DIDWallet
+from chia.wallet.rl_wallet.rl_wallet import RLWallet
 from chia.wallet.trade_record import TradeRecord
 from chia.wallet.trading.offer import Offer
 from chia.wallet.transaction_record import TransactionRecord
@@ -36,7 +41,6 @@ from chia.wallet.util.wallet_types import AmountWithPuzzlehash, WalletType
 from chia.wallet.wallet_info import WalletInfo
 from chia.wallet.wallet_node import WalletNode
 from chia.util.config import load_config
-from chia.consensus.coinbase import create_puzzlehash_for_pk
 
 # Timeout for response from wallet/full node for sending a transaction
 TIMEOUT = 30
@@ -302,25 +306,12 @@ class WalletRpcApi:
         config: Dict = load_config(new_root, "config.yaml")
         farmer_target = config["farmer"].get("xch_target_address")
         pool_target = config["pool"].get("xch_target_address")
-        found_farmer = False
-        found_pool = False
-        selected = config["selected_network"]
-        prefix = config["network_overrides"]["config"][selected]["address_prefix"]
-        for i in range(max_ph_to_search):
-            if found_farmer and found_pool:
-                break
-
-            phs = [
-                encode_puzzle_hash(create_puzzlehash_for_pk(master_sk_to_wallet_sk(sk, uint32(i)).get_g1()), prefix),
-                encode_puzzle_hash(
-                    create_puzzlehash_for_pk(master_sk_to_wallet_sk_unhardened(sk, uint32(i)).get_g1()), prefix
-                ),
-            ]
-            for ph in phs:
-                if ph == farmer_target:
-                    found_farmer = True
-                if ph == pool_target:
-                    found_pool = True
+        address_to_check: List[bytes32] = [decode_puzzle_hash(farmer_target), decode_puzzle_hash(pool_target)]
+
+        found_addresses: Set[bytes32] = match_address_to_sk(sk, address_to_check, max_ph_to_search)
+
+        found_farmer = address_to_check[0] in found_addresses
+        found_pool = address_to_check[1] in found_addresses
 
         return found_farmer, found_pool
 
@@ -334,9 +325,12 @@ class WalletRpcApi:
         walletBalance: bool = False
 
         fingerprint = request["fingerprint"]
+        max_ph_to_search = request.get("max_ph_to_search", 100)
         sk, _ = await self._get_private_key(fingerprint)
         if sk is not None:
-            used_for_farmer, used_for_pool = await self._check_key_used_for_rewards(self.service.root_path, sk, 100)
+            used_for_farmer, used_for_pool = await self._check_key_used_for_rewards(
+                self.service.root_path, sk, max_ph_to_search
+            )
 
             if self.service.logged_in_fingerprint != fingerprint:
                 await self._stop_wallet()
diff --git a/chia/rpc/wallet_rpc_client.py b/chia/rpc/wallet_rpc_client.py
index 135fb9f37..8ece41978 100644
--- a/chia/rpc/wallet_rpc_client.py
+++ b/chia/rpc/wallet_rpc_client.py
@@ -58,8 +58,8 @@ class WalletRpcClient(RpcClient):
     async def delete_key(self, fingerprint: int) -> None:
         return await self.fetch("delete_key", {"fingerprint": fingerprint})
 
-    async def check_delete_key(self, fingerprint: int) -> None:
-        return await self.fetch("check_delete_key", {"fingerprint": fingerprint})
+    async def check_delete_key(self, fingerprint: int, max_ph_to_search: int = 100) -> None:
+        return await self.fetch("check_delete_key", {"fingerprint": fingerprint, "max_ph_to_search": max_ph_to_search})
 
     async def delete_all_keys(self) -> None:
         return await self.fetch("delete_all_keys", {})
diff --git a/chia/wallet/derive_keys.py b/chia/wallet/derive_keys.py
index 9f3443dca..5900c1c36 100644
--- a/chia/wallet/derive_keys.py
+++ b/chia/wallet/derive_keys.py
@@ -1,7 +1,9 @@
-from typing import List, Optional, Tuple
+from typing import List, Optional, Tuple, Set
 
 from blspy import AugSchemeMPL, PrivateKey, G1Element
 
+from chia.consensus.coinbase import create_puzzlehash_for_pk
+from chia.types.blockchain_format.sized_bytes import bytes32
 from chia.util.ints import uint32
 
 # EIP 2334 bls key derivation
@@ -76,7 +78,7 @@ def master_sk_to_pooling_authentication_sk(master: PrivateKey, pool_wallet_index
     return _derive_path(master, [12381, 8444, 6, pool_wallet_index * 10000 + index])
 
 
-def find_owner_sk(all_sks: List[PrivateKey], owner_pk: G1Element) -> Optional[Tuple[G1Element, uint32]]:
+def find_owner_sk(all_sks: List[PrivateKey], owner_pk: G1Element) -> Optional[Tuple[PrivateKey, uint32]]:
     for pool_wallet_index in range(MAX_POOL_WALLETS):
         for sk in all_sks:
             try_owner_sk = master_sk_to_singleton_owner_sk(sk, uint32(pool_wallet_index))
@@ -95,3 +97,34 @@ def find_authentication_sk(all_sks: List[PrivateKey], owner_pk: G1Element) -> Op
                 # NOTE: ONLY use 0 for authentication key index to ensure compatibility
                 return master_sk_to_pooling_authentication_sk(sk, uint32(pool_wallet_index), uint32(0))
     return None
+
+
+def match_address_to_sk(
+    sk: PrivateKey, addresses_to_search: List[bytes32], max_ph_to_search: int = 500
+) -> Set[bytes32]:
+    """
+    Checks the list of given address is a derivation of the given sk within the given number of derivations
+    Returns a Set of the addresses that are derivations of the given sk
+    """
+    if sk is None or not addresses_to_search:
+        return set()
+
+    found_addresses: Set[bytes32] = set()
+    search_list: Set[bytes32] = set(addresses_to_search)
+
+    for i in range(max_ph_to_search):
+
+        phs = [
+            create_puzzlehash_for_pk(master_sk_to_wallet_sk(sk, uint32(i)).get_g1()),
+            create_puzzlehash_for_pk(master_sk_to_wallet_sk_unhardened(sk, uint32(i)).get_g1()),
+        ]
+
+        for address in search_list:
+            if address in phs:
+                found_addresses.add(address)
+
+        search_list = search_list - found_addresses
+        if not len(search_list):
+            return found_addresses
+
+    return found_addresses
diff --git a/tests/core/test_farmer_harvester_rpc.py b/tests/core/test_farmer_harvester_rpc.py
index e312698fe..df22f0237 100644
--- a/tests/core/test_farmer_harvester_rpc.py
+++ b/tests/core/test_farmer_harvester_rpc.py
@@ -17,7 +17,7 @@ from chia.util.byte_types import hexstr_to_bytes
 from chia.util.config import load_config, lock_and_load_config, save_config
 from chia.util.hash import std_hash
 from chia.util.ints import uint8, uint16, uint32, uint64
-from chia.wallet.derive_keys import master_sk_to_wallet_sk
+from chia.wallet.derive_keys import master_sk_to_wallet_sk, master_sk_to_wallet_sk_unhardened
 from tests.setup_nodes import setup_harvester_farmer, test_constants
 from tests.time_out_assert import time_out_assert, time_out_assert_custom_interval
 from tests.util.rpc import validate_get_routes
@@ -181,36 +181,48 @@ async def test_farmer_reward_target_endpoints(bt, harvester_farmer_environment):
     targets_1 = await farmer_rpc_client.get_reward_targets(False)
     assert "have_pool_sk" not in targets_1
     assert "have_farmer_sk" not in targets_1
-    targets_2 = await farmer_rpc_client.get_reward_targets(True)
+    targets_2 = await farmer_rpc_client.get_reward_targets(True, 2)
     assert targets_2["have_pool_sk"] and targets_2["have_farmer_sk"]
 
-    new_ph: bytes32 = create_puzzlehash_for_pk(master_sk_to_wallet_sk(bt.farmer_master_sk, uint32(10)).get_g1())
-    new_ph_2: bytes32 = create_puzzlehash_for_pk(master_sk_to_wallet_sk(bt.pool_master_sk, uint32(472)).get_g1())
+    new_ph: bytes32 = create_puzzlehash_for_pk(master_sk_to_wallet_sk(bt.farmer_master_sk, uint32(2)).get_g1())
+    new_ph_2: bytes32 = create_puzzlehash_for_pk(master_sk_to_wallet_sk(bt.pool_master_sk, uint32(7)).get_g1())
 
     await farmer_rpc_client.set_reward_targets(encode_puzzle_hash(new_ph, "xch"), encode_puzzle_hash(new_ph_2, "xch"))
-    targets_3 = await farmer_rpc_client.get_reward_targets(True)
+    targets_3 = await farmer_rpc_client.get_reward_targets(True, 10)
     assert decode_puzzle_hash(targets_3["farmer_target"]) == new_ph
     assert decode_puzzle_hash(targets_3["pool_target"]) == new_ph_2
     assert targets_3["have_pool_sk"] and targets_3["have_farmer_sk"]
 
-    new_ph_3: bytes32 = create_puzzlehash_for_pk(master_sk_to_wallet_sk(bt.pool_master_sk, uint32(1888)).get_g1())
-    await farmer_rpc_client.set_reward_targets(None, encode_puzzle_hash(new_ph_3, "xch"))
-    targets_4 = await farmer_rpc_client.get_reward_targets(True)
-    assert decode_puzzle_hash(targets_4["farmer_target"]) == new_ph
-    assert decode_puzzle_hash(targets_4["pool_target"]) == new_ph_3
-    assert not targets_4["have_pool_sk"] and targets_3["have_farmer_sk"]
+    # limit the derivation search to 3 should fail to find the pool sk
+    targets_4 = await farmer_rpc_client.get_reward_targets(True, 3)
+    assert not targets_4["have_pool_sk"] and targets_4["have_farmer_sk"]
+
+    # check observer addresses
+    observer_farmer: bytes32 = create_puzzlehash_for_pk(
+        master_sk_to_wallet_sk_unhardened(bt.farmer_master_sk, uint32(2)).get_g1()
+    )
+    observer_pool: bytes32 = create_puzzlehash_for_pk(
+        master_sk_to_wallet_sk_unhardened(bt.pool_master_sk, uint32(7)).get_g1()
+    )
+    await farmer_rpc_client.set_reward_targets(
+        encode_puzzle_hash(observer_farmer, "xch"), encode_puzzle_hash(observer_pool, "xch")
+    )
+    targets = await farmer_rpc_client.get_reward_targets(True, 10)
+    assert decode_puzzle_hash(targets["farmer_target"]) == observer_farmer
+    assert decode_puzzle_hash(targets["pool_target"]) == observer_pool
+    assert targets["have_pool_sk"] and targets["have_farmer_sk"]
 
     root_path = farmer_api.farmer._root_path
     config = load_config(root_path, "config.yaml")
-    assert config["farmer"]["xch_target_address"] == encode_puzzle_hash(new_ph, "xch")
-    assert config["pool"]["xch_target_address"] == encode_puzzle_hash(new_ph_3, "xch")
+    assert config["farmer"]["xch_target_address"] == encode_puzzle_hash(observer_farmer, "xch")
+    assert config["pool"]["xch_target_address"] == encode_puzzle_hash(observer_pool, "xch")
 
-    new_ph_3_encoded = encode_puzzle_hash(new_ph_3, "xch")
-    added_char = new_ph_3_encoded + "a"
+    new_ph_2_encoded = encode_puzzle_hash(new_ph_2, "xch")
+    added_char = new_ph_2_encoded + "a"
     with pytest.raises(ValueError):
         await farmer_rpc_client.set_reward_targets(None, added_char)
 
-    replaced_char = new_ph_3_encoded[0:-1] + "a"
+    replaced_char = new_ph_2_encoded[0:-1] + "a"
     with pytest.raises(ValueError):
         await farmer_rpc_client.set_reward_targets(None, replaced_char)
 
diff --git a/tests/wallet/rpc/test_wallet_rpc.py b/tests/wallet/rpc/test_wallet_rpc.py
index 87eb78283..ac631d6c4 100644
--- a/tests/wallet/rpc/test_wallet_rpc.py
+++ b/tests/wallet/rpc/test_wallet_rpc.py
@@ -26,7 +26,7 @@ from chia.util.hash import std_hash
 from chia.util.ints import uint16, uint32, uint64
 from chia.wallet.cat_wallet.cat_constants import DEFAULT_CATS
 from chia.wallet.cat_wallet.cat_wallet import CATWallet
-from chia.wallet.derive_keys import master_sk_to_wallet_sk
+from chia.wallet.derive_keys import master_sk_to_wallet_sk, master_sk_to_wallet_sk_unhardened
 from chia.wallet.trading.trade_status import TradeStatus
 from chia.wallet.transaction_record import TransactionRecord
 from chia.wallet.transaction_sorting import SortKey
@@ -643,7 +643,37 @@ class TestWalletRpc:
             assert sk_dict["used_for_pool_rewards"] is True
 
             # Check unknown key
-            sk_dict = await client.check_delete_key(123456)
+            sk_dict = await client.check_delete_key(123456, 10)
+            assert sk_dict["fingerprint"] == 123456
+            assert sk_dict["used_for_farmer_rewards"] is False
+            assert sk_dict["used_for_pool_rewards"] is False
+
+            # Add in observer reward addresses into farmer and pool for testing delete key checks
+            # set farmer to first private key
+            sk = await wallet_node.get_key_for_fingerprint(pks[0])
+            test_ph = create_puzzlehash_for_pk(master_sk_to_wallet_sk_unhardened(sk, uint32(0)).get_g1())
+            with lock_and_load_config(wallet_node.root_path, "config.yaml") as test_config:
+                test_config["farmer"]["xch_target_address"] = encode_puzzle_hash(test_ph, "txch")
+                # set pool to second private key
+                sk = await wallet_node.get_key_for_fingerprint(pks[1])
+                test_ph = create_puzzlehash_for_pk(master_sk_to_wallet_sk_unhardened(sk, uint32(0)).get_g1())
+                test_config["pool"]["xch_target_address"] = encode_puzzle_hash(test_ph, "txch")
+                save_config(wallet_node.root_path, "config.yaml", test_config)
+
+            # Check first key
+            sk_dict = await client.check_delete_key(pks[0])
+            assert sk_dict["fingerprint"] == pks[0]
+            assert sk_dict["used_for_farmer_rewards"] is True
+            assert sk_dict["used_for_pool_rewards"] is False
+
+            # Check second key
+            sk_dict = await client.check_delete_key(pks[1])
+            assert sk_dict["fingerprint"] == pks[1]
+            assert sk_dict["used_for_farmer_rewards"] is False
+            assert sk_dict["used_for_pool_rewards"] is True
+
+            # Check unknown key
+            sk_dict = await client.check_delete_key(123456, 10)
             assert sk_dict["fingerprint"] == 123456
             assert sk_dict["used_for_farmer_rewards"] is False
             assert sk_dict["used_for_pool_rewards"] is False
-- 
2.34.1


From 077c8db1ff33e46f73468581a6a54ac0b8a2c82c Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Thu, 21 Apr 2022 18:59:27 -0500
Subject: [PATCH 40/77] Testing postinst/prerm scripts with the UI .deb
 (#11258)

---
 build_scripts/assets/deb/postinst.sh | 7 +++++++
 build_scripts/assets/deb/prerm.sh    | 7 +++++++
 build_scripts/build_linux_deb.sh     | 6 ++++--
 build_scripts/deb-options.json       | 9 +++++++++
 4 files changed, 27 insertions(+), 2 deletions(-)
 create mode 100644 build_scripts/assets/deb/postinst.sh
 create mode 100644 build_scripts/assets/deb/prerm.sh
 create mode 100644 build_scripts/deb-options.json

diff --git a/build_scripts/assets/deb/postinst.sh b/build_scripts/assets/deb/postinst.sh
new file mode 100644
index 000000000..01be34115
--- /dev/null
+++ b/build_scripts/assets/deb/postinst.sh
@@ -0,0 +1,7 @@
+#!/usr/bin/env bash
+# Post install script for the UI .deb to place symlinks in places to allow the CLI to work similarly in both versions
+
+set -e
+
+ln -s /usr/lib/chia-blockchain/resources/app.asar.unpacked/daemon/chia /usr/bin/chia || true
+ln -s /usr/lib/chia-blockchain/resources/app.asar.unpacked/daemon /opt/chia || true
diff --git a/build_scripts/assets/deb/prerm.sh b/build_scripts/assets/deb/prerm.sh
new file mode 100644
index 000000000..9e34e2602
--- /dev/null
+++ b/build_scripts/assets/deb/prerm.sh
@@ -0,0 +1,7 @@
+#!/usr/bin/env bash
+# Pre remove script for the UI .deb to clean up the symlinks from the installer
+
+set -e
+
+unlink /usr/bin/chia || true
+unlink /opt/chia || true
diff --git a/build_scripts/build_linux_deb.sh b/build_scripts/build_linux_deb.sh
index ba74d7b46..27e24ba38 100644
--- a/build_scripts/build_linux_deb.sh
+++ b/build_scripts/build_linux_deb.sh
@@ -98,8 +98,10 @@ cd ../../../build_scripts || exit
 echo "Create chia-$CHIA_INSTALLER_VERSION.deb"
 rm -rf final_installer
 mkdir final_installer
-electron-installer-debian --src dist/$DIR_NAME/ --dest final_installer/ \
---arch "$PLATFORM" --options.version $CHIA_INSTALLER_VERSION --options.bin chia-blockchain --options.name chia-blockchain
+electron-installer-debian --src "dist/$DIR_NAME/" \
+  --arch "$PLATFORM" \
+  --options.version "$CHIA_INSTALLER_VERSION" \
+  --config deb-options.json
 LAST_EXIT_CODE=$?
 if [ "$LAST_EXIT_CODE" -ne 0 ]; then
 	echo >&2 "electron-installer-debian failed!"
diff --git a/build_scripts/deb-options.json b/build_scripts/deb-options.json
new file mode 100644
index 000000000..da5ef86f0
--- /dev/null
+++ b/build_scripts/deb-options.json
@@ -0,0 +1,9 @@
+{
+  "dest": "final_installer/",
+  "bin": "chia-blockchain",
+  "name": "chia-blockchain",
+  "scripts": {
+    "postinst": "assets/deb/postinst.sh",
+    "prerm": "assets/deb/prerm.sh"
+  }
+}
-- 
2.34.1


From 7d11d54f898d51ad68040297263514fe41d7dbc0 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Fri, 22 Apr 2022 02:00:00 +0200
Subject: [PATCH 41/77] plotting: Enable `isort` (#11135)

---
 .isort.cfg                          |  6 ------
 chia/plotting/check_plots.py        |  6 +++---
 chia/plotting/manager.py            | 10 ++--------
 chia/plotting/util.py               |  1 -
 tests/plotting/test_plot_manager.py | 11 ++++++-----
 tests/plotting/util.py              |  3 ++-
 6 files changed, 13 insertions(+), 24 deletions(-)

diff --git a/.isort.cfg b/.isort.cfg
index 011e9d61b..217c7f235 100644
--- a/.isort.cfg
+++ b/.isort.cfg
@@ -49,10 +49,6 @@ extend_skip=
     chia/plotters/install_plotter.py
     chia/plotters/madmax.py
     chia/plotters/plotters.py
-    chia/plotting/check_plots.py
-    chia/plotting/create_plots.py
-    chia/plotting/manager.py
-    chia/plotting/util.py
     chia/pools/pool_puzzles.py
     chia/pools/pool_wallet_info.py
     chia/pools/pool_wallet.py
@@ -189,8 +185,6 @@ extend_skip=
     tests/generator/test_list_to_batches.py
     tests/generator/test_rom.py
     tests/generator/test_scan.py
-    tests/plotting/test_plot_manager.py
-    tests/plotting/util.py
     tests/pools/test_pool_cmdline.py
     tests/pools/test_pool_config.py
     tests/pools/test_pool_puzzles_lifecycle.py
diff --git a/chia/plotting/check_plots.py b/chia/plotting/check_plots.py
index b6169fb5c..fd503a6e3 100644
--- a/chia/plotting/check_plots.py
+++ b/chia/plotting/check_plots.py
@@ -1,7 +1,7 @@
 import logging
 from collections import Counter
 from pathlib import Path
-from time import time, sleep
+from time import sleep, time
 from typing import List
 
 from blspy import G1Element
@@ -9,11 +9,11 @@ from chiapos import Verifier
 
 from chia.plotting.manager import PlotManager
 from chia.plotting.util import (
+    PlotRefreshEvents,
     PlotRefreshResult,
     PlotsRefreshParameter,
-    PlotRefreshEvents,
-    get_plot_filenames,
     find_duplicate_plot_IDs,
+    get_plot_filenames,
     parse_plot_info,
 )
 from chia.util.bech32m import encode_puzzle_hash
diff --git a/chia/plotting/manager.py b/chia/plotting/manager.py
index 72a66f629..6539634de 100644
--- a/chia/plotting/manager.py
+++ b/chia/plotting/manager.py
@@ -2,22 +2,16 @@ import logging
 import threading
 import time
 import traceback
+from concurrent.futures.thread import ThreadPoolExecutor
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Set, Tuple
-from concurrent.futures.thread import ThreadPoolExecutor
 
 from blspy import G1Element
 from chiapos import DiskProver
 
 from chia.consensus.pos_quality import UI_ACTUAL_SPACE_CONSTANT_FACTOR, _expected_plot_size
 from chia.plotting.cache import Cache, CacheEntry
-from chia.plotting.util import (
-    PlotInfo,
-    PlotRefreshResult,
-    PlotsRefreshParameter,
-    PlotRefreshEvents,
-    get_plot_filenames,
-)
+from chia.plotting.util import PlotInfo, PlotRefreshEvents, PlotRefreshResult, PlotsRefreshParameter, get_plot_filenames
 from chia.util.generator_tools import list_to_batches
 
 log = logging.getLogger(__name__)
diff --git a/chia/plotting/util.py b/chia/plotting/util.py
index ae542437c..a25591338 100644
--- a/chia/plotting/util.py
+++ b/chia/plotting/util.py
@@ -1,5 +1,4 @@
 import logging
-
 from dataclasses import dataclass, field
 from enum import Enum
 from pathlib import Path
diff --git a/tests/plotting/test_plot_manager.py b/tests/plotting/test_plot_manager.py
index 41a9a363c..743dc6ff2 100644
--- a/tests/plotting/test_plot_manager.py
+++ b/tests/plotting/test_plot_manager.py
@@ -1,25 +1,26 @@
 import logging
 import time
+from dataclasses import dataclass
 from os import unlink
 from pathlib import Path
 from shutil import copy, move
 from typing import Callable, Iterator, List, Optional
+
 import pytest
 from blspy import G1Element
 
-from dataclasses import dataclass
+from chia.plotting.manager import Cache, PlotManager
 from chia.plotting.util import (
     PlotInfo,
-    PlotRefreshResult,
     PlotRefreshEvents,
-    remove_plot,
-    get_plot_directories,
+    PlotRefreshResult,
     add_plot_directory,
+    get_plot_directories,
+    remove_plot,
     remove_plot_directory,
 )
 from chia.util.config import create_default_chia_config
 from chia.util.path import mkdir
-from chia.plotting.manager import Cache, PlotManager
 from tests.block_tools import get_plot_dir
 from tests.plotting.util import get_test_plots
 from tests.time_out_assert import time_out_assert
diff --git a/tests/plotting/util.py b/tests/plotting/util.py
index 570caa55f..9422611b0 100644
--- a/tests/plotting/util.py
+++ b/tests/plotting/util.py
@@ -1,5 +1,6 @@
-from typing import List
 from pathlib import Path
+from typing import List
+
 from tests.block_tools import get_plot_dir
 
 
-- 
2.34.1


From 3c482245513576e8dbc1dcbf026bef4c622c8108 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Thu, 21 Apr 2022 17:00:28 -0700
Subject: [PATCH 42/77] check dependency artifacts (#11243)

* check dependency artifacts

* remove commented out code

* find root path relative to script

* fixup stringy pathy mixup

* Update check_dependency_artifacts.py
---
 .../workflows/check_wheel_availability.yaml   | 38 ++++++++++
 build_scripts/check_dependency_artifacts.py   | 70 +++++++++++++++++++
 2 files changed, 108 insertions(+)
 create mode 100644 .github/workflows/check_wheel_availability.yaml
 create mode 100644 build_scripts/check_dependency_artifacts.py

diff --git a/.github/workflows/check_wheel_availability.yaml b/.github/workflows/check_wheel_availability.yaml
new file mode 100644
index 000000000..c051bd485
--- /dev/null
+++ b/.github/workflows/check_wheel_availability.yaml
@@ -0,0 +1,38 @@
+name: Check Dependency Artifacts
+
+on:
+  push:
+    branches:
+      - main
+    tags:
+        - '**'
+  pull_request:
+    branches:
+      - '**'
+
+concurrency:
+  # SHA is added to the end if on `main` to let all main workflows run
+  group: ${{ github.ref }}-${{ github.workflow }}-${{ github.event_name }}-${{ github.ref == 'refs/heads/main' && github.sha || '' }}
+  cancel-in-progress: true
+
+jobs:
+  check_dependency_artifacts:
+    name: Check Dependency Artifacts
+    runs-on: ${{ matrix.os }}
+    strategy:
+      fail-fast: false
+      matrix:
+        python-version: ['3.7', '3.8', '3.9']
+        os: [macOS-latest, ubuntu-latest]
+
+    steps:
+    - name: Checkout Code
+      uses: actions/checkout@v3
+
+    - name: Setup Python environment
+      uses: actions/setup-python@v2
+      with:
+        python-version: ${{ matrix.python-version }}
+
+    - name: Check Wheel Availability
+      run: python build_scripts/check_dependency_artifacts.py
diff --git a/build_scripts/check_dependency_artifacts.py b/build_scripts/check_dependency_artifacts.py
new file mode 100644
index 000000000..2c34a4c54
--- /dev/null
+++ b/build_scripts/check_dependency_artifacts.py
@@ -0,0 +1,70 @@
+import os
+import pathlib
+import subprocess
+import sys
+import tempfile
+
+excepted_packages = {
+    "keyrings.cryptfile",  # pure python
+    "dnslib",  # pure python
+}
+
+
+def excepted(path: pathlib.Path) -> bool:
+    # TODO: This should be implemented with a real file name parser though i'm
+    #       uncertain at the moment what package that would be.
+
+    name, dash, rest = path.name.partition("-")
+    return name in excepted_packages
+
+
+def main() -> int:
+    with tempfile.TemporaryDirectory() as directory_string:
+        directory_path = pathlib.Path(directory_string)
+
+        extras = ["upnp"]
+        package_path_string = os.fspath(pathlib.Path(__file__).parent.parent)
+
+        if len(extras) > 0:
+            package_and_extras = f"{package_path_string}[{','.join(extras)}]"
+        else:
+            package_and_extras = package_path_string
+
+        subprocess.run(
+            [
+                sys.executable,
+                "-m",
+                "pip",
+                "download",
+                "--dest",
+                os.fspath(directory_path),
+                "--extra-index",
+                "https://pypi.chia.net/simple/",
+                package_and_extras,
+            ],
+            check=True,
+        )
+
+        failed_artifacts = []
+
+        for artifact in directory_path.iterdir():
+            if artifact.suffix == ".whl":
+                # everything being a wheel is the target
+                continue
+
+            if excepted(artifact):
+                continue
+
+            failed_artifacts.append(artifact)
+
+        if len(failed_artifacts) > 0:
+            print("The following unacceptable artifacts were downloaded by pip:")
+            for artifact in failed_artifacts:
+                print(f"    {artifact.name}")
+
+            return 1
+
+        return 0
+
+
+sys.exit(main())
-- 
2.34.1


From 48bb002d951d240b0aa1704980076369cc59c0b1 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Thu, 21 Apr 2022 17:01:17 -0700
Subject: [PATCH 43/77] have pyinstaller check platlib for dll's, not ROOT
 (#11120)

---
 chia/pyinstaller.spec | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/chia/pyinstaller.spec b/chia/pyinstaller.spec
index 6d81c943a..2e4bc0be2 100644
--- a/chia/pyinstaller.spec
+++ b/chia/pyinstaller.spec
@@ -2,6 +2,7 @@
 import importlib
 import pathlib
 import platform
+import sysconfig
 
 from pkg_resources import get_distribution
 
@@ -98,7 +99,7 @@ if THIS_IS_WINDOWS:
 
 if THIS_IS_WINDOWS:
     chia_mod = importlib.import_module("chia")
-    dll_paths = ROOT / "*.dll"
+    dll_paths = pathlib.Path(sysconfig.get_path("platlib")) / "*.dll"
 
     binaries = [
         (
-- 
2.34.1


From 7b838239a9fb0eba9ce3b73e9c021154594b0318 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Fri, 22 Apr 2022 12:53:03 -0500
Subject: [PATCH 44/77] Additional metrics (#11271)

* Remove _set_state_changed_callback from harvester_api.py as its never actually called

In rpc/rpc_server.py:318, what is actually called is rpc_server.rpc_api.service._set_state_changed_callback, so the version of this in harvester.py is what is actually used

* Remove duplicate initial value for state_changed_callback in init

* _state_changed -> state_changed so it can be called from harvester_api as well

* Add farming info state_changed event from harvester

* Add time to farming_info event

* Add [pre_]validation_time to block event

* Remove unused set_state_changed_callback on full_node_api. This is actually called on full_node_rpc_api.service

* Remove unused set_state_changed_callback on crawler_api. This is actually called on crawler_rpc_api.service (crawler)

* Remove unused set_state_changed_callback on farmer_api. This is actually called on farmer_rpc_api.service (farmer), not the api itself

* Add state changed event for submitting a partial

* Lint fixes
---
 chia/farmer/farmer_api.py       | 16 ++++++++++++----
 chia/full_node/full_node.py     |  2 ++
 chia/full_node/full_node_api.py |  5 +----
 chia/harvester/harvester.py     | 11 +++++------
 chia/harvester/harvester_api.py | 18 +++++++++++++-----
 chia/rpc/farmer_rpc_api.py      | 25 ++++++++++++++++++-------
 chia/rpc/harvester_rpc_api.py   | 17 +++++++++++++----
 chia/seeder/crawler_api.py      |  5 +----
 8 files changed, 65 insertions(+), 34 deletions(-)

diff --git a/chia/farmer/farmer_api.py b/chia/farmer/farmer_api.py
index 87ce5525f..6982d6305 100644
--- a/chia/farmer/farmer_api.py
+++ b/chia/farmer/farmer_api.py
@@ -1,6 +1,6 @@
 import json
 import time
-from typing import Any, Callable, Dict, List, Optional, Tuple
+from typing import Any, Dict, List, Optional, Tuple
 
 import aiohttp
 from blspy import AugSchemeMPL, G2Element, PrivateKey
@@ -50,9 +50,6 @@ class FarmerAPI:
     def __init__(self, farmer) -> None:
         self.farmer = farmer
 
-    def _set_state_changed_callback(self, callback: Callable):
-        self.farmer.state_changed_callback = callback
-
     @api_request
     @peer_required
     async def new_proof_of_space(
@@ -272,6 +269,17 @@ class FarmerAPI:
                     self.farmer.log.error(f"Error connecting to pool: {e}")
                     return
 
+                self.farmer.state_changed(
+                    "submitted_partial",
+                    {
+                        "launcher_id": post_partial_request.payload.launcher_id.hex(),
+                        "pool_url": pool_url,
+                        "current_difficulty": pool_state_dict["current_difficulty"],
+                        "points_acknowledged_since_start": pool_state_dict["points_acknowledged_since_start"],
+                        "points_acknowledged_24h": pool_state_dict["points_acknowledged_24h"],
+                    },
+                )
+
                 return
 
     @api_request
diff --git a/chia/full_node/full_node.py b/chia/full_node/full_node.py
index 4c5ebbe54..a77bf3c2c 100644
--- a/chia/full_node/full_node.py
+++ b/chia/full_node/full_node.py
@@ -1629,6 +1629,8 @@ class FullNode:
             "k_size": block.reward_chain_block.proof_of_space.size,
             "header_hash": block.header_hash,
             "height": block.height,
+            "validation_time": validation_time,
+            "pre_validation_time": pre_validation_time,
         }
 
         if block.transactions_info is not None:
diff --git a/chia/full_node/full_node_api.py b/chia/full_node/full_node_api.py
index ff91b1185..790da6315 100644
--- a/chia/full_node/full_node_api.py
+++ b/chia/full_node/full_node_api.py
@@ -3,7 +3,7 @@ import dataclasses
 import time
 import traceback
 from secrets import token_bytes
-from typing import Callable, Dict, List, Optional, Tuple, Set
+from typing import Dict, List, Optional, Tuple, Set
 
 from blspy import AugSchemeMPL, G2Element
 from chiabip158 import PyBIP158
@@ -54,9 +54,6 @@ class FullNodeAPI:
     def __init__(self, full_node) -> None:
         self.full_node = full_node
 
-    def _set_state_changed_callback(self, callback: Callable):
-        self.full_node.state_changed_callback = callback
-
     @property
     def server(self):
         return self.full_node.server
diff --git a/chia/harvester/harvester.py b/chia/harvester/harvester.py
index 0b615a5bb..9dc2b8855 100644
--- a/chia/harvester/harvester.py
+++ b/chia/harvester/harvester.py
@@ -4,7 +4,7 @@ import dataclasses
 import logging
 from concurrent.futures.thread import ThreadPoolExecutor
 from pathlib import Path
-from typing import Callable, Dict, List, Optional, Tuple
+from typing import Any, Callable, Dict, List, Optional, Tuple
 
 import chia.server.ws_connection as ws  # lgtm [py/import-and-import-from]
 from chia.consensus.constants import ConsensusConstants
@@ -58,7 +58,6 @@ class Harvester:
         self.plot_sync_sender = Sender(self.plot_manager)
         self._is_shutdown = False
         self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=config["num_threads"])
-        self.state_changed_callback = None
         self.server = None
         self.constants = constants
         self.cached_challenges = []
@@ -82,9 +81,9 @@ class Harvester:
     def _set_state_changed_callback(self, callback: Callable):
         self.state_changed_callback = callback
 
-    def _state_changed(self, change: str):
+    def state_changed(self, change: str, change_data: Dict[str, Any] = None):
         if self.state_changed_callback is not None:
-            self.state_changed_callback(change)
+            self.state_changed_callback(change, change_data)
 
     def _plot_refresh_callback(self, event: PlotRefreshEvents, update_result: PlotRefreshResult):
         log_function = self.log.debug if event != PlotRefreshEvents.done else self.log.info
@@ -104,7 +103,7 @@ class Harvester:
 
     def on_disconnect(self, connection: ws.WSChiaConnection):
         self.log.info(f"peer disconnected {connection.get_peer_logging()}")
-        self._state_changed("close_connection")
+        self.state_changed("close_connection")
         self.plot_manager.stop_refreshing()
         self.plot_sync_sender.stop()
 
@@ -140,7 +139,7 @@ class Harvester:
     def delete_plot(self, str_path: str):
         remove_plot(Path(str_path))
         self.plot_manager.trigger_refresh()
-        self._state_changed("plots")
+        self.state_changed("plots")
         return True
 
     async def add_plot_directory(self, str_path: str) -> bool:
diff --git a/chia/harvester/harvester_api.py b/chia/harvester/harvester_api.py
index 26197d7d5..54fe3f0e3 100644
--- a/chia/harvester/harvester_api.py
+++ b/chia/harvester/harvester_api.py
@@ -1,7 +1,7 @@
 import asyncio
 import time
 from pathlib import Path
-from typing import Callable, List, Tuple
+from typing import List, Tuple
 
 from blspy import AugSchemeMPL, G1Element, G2Element
 
@@ -27,9 +27,6 @@ class HarvesterAPI:
     def __init__(self, harvester: Harvester):
         self.harvester = harvester
 
-    def _set_state_changed_callback(self, callback: Callable):
-        self.harvester.state_changed_callback = callback
-
     @peer_required
     @api_request
     async def harvester_handshake(
@@ -218,11 +215,22 @@ class HarvesterAPI:
         )
         pass_msg = make_msg(ProtocolMessageTypes.farming_info, farming_info)
         await peer.send_message(pass_msg)
+        found_time = time.time() - start
         self.harvester.log.info(
             f"{len(awaitables)} plots were eligible for farming {new_challenge.challenge_hash.hex()[:10]}..."
-            f" Found {total_proofs_found} proofs. Time: {time.time() - start:.5f} s. "
+            f" Found {total_proofs_found} proofs. Time: {found_time:.5f} s. "
             f"Total {self.harvester.plot_manager.plot_count()} plots"
         )
+        self.harvester.state_changed(
+            "farming_info",
+            {
+                "challenge_hash": new_challenge.challenge_hash.hex(),
+                "total_plots": self.harvester.plot_manager.plot_count(),
+                "found_proofs": total_proofs_found,
+                "eligible_plots": len(awaitables),
+                "time": found_time,
+            },
+        )
 
     @api_request
     async def request_signatures(self, request: harvester_protocol.RequestSignatures):
diff --git a/chia/rpc/farmer_rpc_api.py b/chia/rpc/farmer_rpc_api.py
index 0c0a7b6e1..fb22062ad 100644
--- a/chia/rpc/farmer_rpc_api.py
+++ b/chia/rpc/farmer_rpc_api.py
@@ -24,37 +24,48 @@ class FarmerRpcApi:
         }
 
     async def _state_changed(self, change: str, change_data: Dict) -> List[WsRpcMessage]:
+        payloads = []
+
         if change == "new_signage_point":
             sp_hash = change_data["sp_hash"]
             data = await self.get_signage_point({"sp_hash": sp_hash.hex()})
-            return [
+            payloads.append(
                 create_payload_dict(
                     "new_signage_point",
                     data,
                     self.service_name,
                     "wallet_ui",
                 )
-            ]
+            )
         elif change == "new_farming_info":
-            return [
+            payloads.append(
                 create_payload_dict(
                     "new_farming_info",
                     change_data,
                     self.service_name,
                     "wallet_ui",
                 )
-            ]
+            )
         elif change == "new_plots":
-            return [
+            payloads.append(
                 create_payload_dict(
                     "get_harvesters",
                     change_data,
                     self.service_name,
                     "wallet_ui",
                 )
-            ]
+            )
+        elif change == "submitted_partial":
+            payloads.append(
+                create_payload_dict(
+                    "submitted_partial",
+                    change_data,
+                    self.service_name,
+                    "metrics",
+                )
+            )
 
-        return []
+        return payloads
 
     async def get_signage_point(self, request: Dict) -> Dict:
         sp_hash = hexstr_to_bytes(request["sp_hash"])
diff --git a/chia/rpc/harvester_rpc_api.py b/chia/rpc/harvester_rpc_api.py
index ecb8acbe8..0a368c7c1 100644
--- a/chia/rpc/harvester_rpc_api.py
+++ b/chia/rpc/harvester_rpc_api.py
@@ -1,4 +1,4 @@
-from typing import Callable, Dict, List
+from typing import Any, Callable, Dict, List
 
 from chia.harvester.harvester import Harvester
 from chia.util.ws_message import WsRpcMessage, create_payload_dict
@@ -19,12 +19,21 @@ class HarvesterRpcApi:
             "/remove_plot_directory": self.remove_plot_directory,
         }
 
-    async def _state_changed(self, change: str) -> List[WsRpcMessage]:
+    async def _state_changed(self, change: str, change_data: Dict[str, Any] = None) -> List[WsRpcMessage]:
+        if change_data is None:
+            change_data = {}
+
+        payloads = []
+
         if change == "plots":
             data = await self.get_plots({})
             payload = create_payload_dict("get_plots", data, self.service_name, "wallet_ui")
-            return [payload]
-        return []
+            payloads.append(payload)
+
+        if change == "farming_info":
+            payloads.append(create_payload_dict("farming_info", change_data, self.service_name, "metrics"))
+
+        return payloads
 
     async def get_plots(self, request: Dict) -> Dict:
         plots, failed_to_open, not_found = self.service.get_plots()
diff --git a/chia/seeder/crawler_api.py b/chia/seeder/crawler_api.py
index 304be592d..8efe415d2 100644
--- a/chia/seeder/crawler_api.py
+++ b/chia/seeder/crawler_api.py
@@ -1,4 +1,4 @@
-from typing import Callable, Optional
+from typing import Optional
 
 import chia.server.ws_connection as ws
 from chia.full_node.full_node import full_node_protocol, wallet_protocol
@@ -13,9 +13,6 @@ class CrawlerAPI:
     def __init__(self, crawler):
         self.crawler = crawler
 
-    def _set_state_changed_callback(self, callback: Callable):
-        self.crawler.state_changed_callback = callback
-
     def __getattr__(self, attr_name: str):
         async def invoke(*args, **kwargs):
             pass
-- 
2.34.1


From f9c4f1f96d9d5b82dbf323b7d0e1375ae3734943 Mon Sep 17 00:00:00 2001
From: Arvid Norberg <arvid@libtorrent.org>
Date: Fri, 22 Apr 2022 19:53:53 +0200
Subject: [PATCH 45/77] add tool to measure CPU utilization of a process tree
 (#11264)

* add tool to measure CPU utilization of a process tree and plot it over time

* make collecing thread counters optional
---
 tools/cpu_utilization.py | 117 +++++++++++++++++++++++++++++++++++++++
 1 file changed, 117 insertions(+)
 create mode 100644 tools/cpu_utilization.py

diff --git a/tools/cpu_utilization.py b/tools/cpu_utilization.py
new file mode 100644
index 000000000..9f9f9019a
--- /dev/null
+++ b/tools/cpu_utilization.py
@@ -0,0 +1,117 @@
+import time
+from dataclasses import dataclass
+from subprocess import check_call
+from typing import Dict, List
+
+import click
+import psutil
+
+
+@dataclass(frozen=True)
+class Counters:
+    user_time: int
+    system_time: int
+
+
+@click.command()
+@click.argument("pid", type=int, required=True)
+@click.option(
+    "--output",
+    type=str,
+    default="cpu-usage.log",
+    help="the file to print CPU usage stats to",
+)
+@click.option(
+    "--threads",
+    is_flag=True,
+    default=False,
+    help="Also capture threads counters",
+)
+def main(pid: int, output: str, threads: bool) -> None:
+    process = psutil.Process(pid)
+
+    stats: Dict[int, Dict[int, Counters]] = {pid: {}}
+    timestamps: List[float] = []
+
+    try:
+        step = 0
+        while process.is_running():
+
+            timestamps.append(time.perf_counter())
+            ps = process.cpu_times()
+            stats[pid][step] = Counters(ps.user, ps.system)
+
+            for p in process.children(recursive=True):
+                try:
+                    ps = p.cpu_times()
+                    if p.pid not in stats:
+                        stats[p.pid] = {}
+                    stats[p.pid][step] = Counters(ps.user, ps.system)
+                except Exception:
+                    pass
+            if threads:
+                for t in process.threads():
+                    try:
+                        if t.id not in stats:
+                            stats[t.id] = {}
+                        stats[t.id][step] = Counters(t.user_time, t.system_time)
+                    except Exception:
+                        pass
+
+            time.sleep(0.05)
+            step += 1
+    except KeyboardInterrupt:
+        pass
+
+    cols = sorted(stats.items())
+    start_time = timestamps[0]
+    with open(output, "w+") as out:
+        out.write("timestamp ")
+        for col_id, _ in cols:
+            out.write(f"{col_id:5d}-user {col_id:6d}-sys ")
+        out.write("\n")
+        for row, ts in enumerate(timestamps):
+            if row == 0:
+                continue
+            time_delta = ts - timestamps[row - 1]
+            out.write(f"{ts-start_time:10f} ")
+            for _, c in cols:
+                if row in c and (row - 1) in c:
+                    out.write(f"   {(c[row].user_time - c[row - 1].user_time)*100/time_delta:6.2f}% ")
+                    out.write(f"   {(c[row].system_time - c[row - 1].system_time)*100/time_delta:6.2f}% ")
+                else:
+                    out.write("     0.00%      0.00% ")
+            row += 1
+            out.write("\n")
+
+    with open("plot-cpu.gnuplot", "w+") as out:
+        out.write(
+            f"""
+set term png small size 1500, {120*len(cols)}
+set output "cpu.png"
+set yrange [0:100]
+unset xtics
+set multiplot layout {len(cols)},1
+"""
+        )
+        for idx, c2 in enumerate(cols):
+            if c2[0] == pid:
+                title = f"pid {c2[0]} (main)"
+            else:
+                title = f"pid {c2[0]}"
+
+            out.write(f'set ylabel "CPU (%)\\n{title}"\n')
+            if idx == len(cols) - 1:
+                out.write('set xlabel "time (s)"\n')
+            out.write(
+                f'plot "{output}" using 1:(${idx*2+2}+${idx*2+3}) title "User" with filledcurves y=0, '
+                f'"{output}" using 1:{idx*2+3} title "System" with filledcurves y=0\n'
+            )
+
+    print('running "gnuplot plot-cpu.gnuplot"')
+    check_call(["gnuplot", "plot-cpu.gnuplot"])
+
+
+if __name__ == "__main__":
+    # pylint: disable = no-value-for-parameter
+    main()
-- 
2.34.1


From c0f3d4d23108920370e0d9e12289df67f1e71881 Mon Sep 17 00:00:00 2001
From: dustinface <35775977+xdustinface@users.noreply.github.com>
Date: Fri, 22 Apr 2022 19:55:57 +0200
Subject: [PATCH 46/77] daemon|util: Don't remove from list while iterating
 (#11208)

* daemon: Iterate over a copy of `websockets`

Currently when it fails to send the response to one websocket it skips
the next websocket in list becaue we remove from the list while
iterating.

* util: Iterate over a copy of `peers_with_peak`

Currently when a peer is closed it skips the check for the next peer in
the list becaue we remove from the list while iterating.
---
 chia/daemon/server.py              | 4 ++--
 chia/util/check_fork_next_block.py | 2 +-
 2 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/chia/daemon/server.py b/chia/daemon/server.py
index 3079d8ce8..db3618bdd 100644
--- a/chia/daemon/server.py
+++ b/chia/daemon/server.py
@@ -613,7 +613,7 @@ class WebSocketServer:
 
         response = create_payload("keyring_status_changed", keyring_status, "daemon", destination)
 
-        for websocket in websockets:
+        for websocket in websockets.copy():
             try:
                 await websocket.send_str(response)
             except Exception as e:
@@ -672,7 +672,7 @@ class WebSocketServer:
 
         response = create_payload("state_changed", message, service, "wallet_ui")
 
-        for websocket in websockets:
+        for websocket in websockets.copy():
             try:
                 await websocket.send_str(response)
             except Exception as e:
diff --git a/chia/util/check_fork_next_block.py b/chia/util/check_fork_next_block.py
index ce291fcc6..0a6945fcc 100644
--- a/chia/util/check_fork_next_block.py
+++ b/chia/util/check_fork_next_block.py
@@ -15,7 +15,7 @@ async def check_fork_next_block(
         potential_peek = uint32(our_peak_height + 1)
         # This is the fork point in SES in the case where no fork was detected
         if blockchain.get_peak_height() is not None and fork_point_height == max_fork_ses_height:
-            for peer in peers_with_peak:
+            for peer in peers_with_peak.copy():
                 if peer.closed:
                     peers_with_peak.remove(peer)
                     continue
-- 
2.34.1


From d473911454b56285545bcfe1b21d54cd34207893 Mon Sep 17 00:00:00 2001
From: wjblanke <wjb98672@gmail.com>
Date: Fri, 22 Apr 2022 11:37:17 -0700
Subject: [PATCH 47/77] revert to old bls no gil release until windows is
 sorted (#11275)

---
 setup.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/setup.py b/setup.py
index 55dc64d82..1618daec6 100644
--- a/setup.py
+++ b/setup.py
@@ -3,7 +3,7 @@ from setuptools import setup
 dependencies = [
     "multidict==5.1.0",  # Avoid 5.2.0 due to Avast
     "aiofiles==0.7.0",  # Async IO for files
-    "blspy==1.0.10",  # Signature library
+    "blspy==1.0.9",  # Signature library
     "chiavdf==1.0.6",  # timelord and vdf verification
     "chiabip158==1.1",  # bip158-style wallet filters
     "chiapos==1.0.10",  # proof of space
-- 
2.34.1


From 8460a35466e890d69afb091971afa86a6749590a Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Sat, 23 Apr 2022 20:11:09 -0700
Subject: [PATCH 48/77] Debian bookworm now uses 3.10, update the comment
 (#11278)

---
 .github/workflows/test-install-scripts.yml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/.github/workflows/test-install-scripts.yml b/.github/workflows/test-install-scripts.yml
index 7d27cec94..05e1d419e 100644
--- a/.github/workflows/test-install-scripts.yml
+++ b/.github/workflows/test-install-scripts.yml
@@ -80,7 +80,7 @@ jobs:
           url: "docker://debian:bullseye"
         - name: debian:bookworm
           type: debian
-          # https://packages.debian.org/bookworm/python/python3 (3.9)
+          # https://packages.debian.org/bookworm/python/python3 (3.10)
           url: "docker://debian:bookworm"
         - name: fedora:33
           type: fedora
-- 
2.34.1


From b1c7f70c9fd091fd4aefad86bb22a170f6d81651 Mon Sep 17 00:00:00 2001
From: Earle Lowe <30607889+emlowe@users.noreply.github.com>
Date: Sat, 23 Apr 2022 20:11:31 -0700
Subject: [PATCH 49/77] Update setproctitle to 1.2.3 for python 3.10 (#11274)

---
 setup.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/setup.py b/setup.py
index 1618daec6..5d479f3fb 100644
--- a/setup.py
+++ b/setup.py
@@ -25,7 +25,7 @@ dependencies = [
     #  "keyrings.cryptfile==1.3.8",  # Secure storage for keys on Linux (Will be replaced)
     #  See https://github.com/frispete/keyrings.cryptfile/issues/15
     "PyYAML==5.4.1",  # Used for config file format
-    "setproctitle==1.2.2",  # Gives the chia processes readable names
+    "setproctitle==1.2.3",  # Gives the chia processes readable names
     "sortedcontainers==2.4.0",  # For maintaining sorted mempools
     # TODO: when moving to click 8 remove the pinning of black noted below
     "click==7.1.2",  # For the CLI
-- 
2.34.1


From 7cd2a6f0c8a5450fed6cfb3146dd027db3b8f831 Mon Sep 17 00:00:00 2001
From: Earle Lowe <30607889+emlowe@users.noreply.github.com>
Date: Sat, 23 Apr 2022 20:11:56 -0700
Subject: [PATCH 50/77] Remove multidict from setup.py for python 3.10 (#11272)

* Testing multidict 6.0.2

* Stop specifying multidict directly
---
 setup.py | 1 -
 1 file changed, 1 deletion(-)

diff --git a/setup.py b/setup.py
index 5d479f3fb..a24d31dee 100644
--- a/setup.py
+++ b/setup.py
@@ -1,7 +1,6 @@
 from setuptools import setup
 
 dependencies = [
-    "multidict==5.1.0",  # Avoid 5.2.0 due to Avast
     "aiofiles==0.7.0",  # Async IO for files
     "blspy==1.0.9",  # Signature library
     "chiavdf==1.0.6",  # timelord and vdf verification
-- 
2.34.1


From ee893348096b0aaca23ec11c3be999fe76bc0efb Mon Sep 17 00:00:00 2001
From: Earle Lowe <30607889+emlowe@users.noreply.github.com>
Date: Sat, 23 Apr 2022 20:13:06 -0700
Subject: [PATCH 51/77] Update PyYAML to 6.0 for python 3.10 (#11273)

---
 setup.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/setup.py b/setup.py
index a24d31dee..ea54221b9 100644
--- a/setup.py
+++ b/setup.py
@@ -23,7 +23,7 @@ dependencies = [
     "keyrings.cryptfile==1.3.4",  # Secure storage for keys on Linux (Will be replaced)
     #  "keyrings.cryptfile==1.3.8",  # Secure storage for keys on Linux (Will be replaced)
     #  See https://github.com/frispete/keyrings.cryptfile/issues/15
-    "PyYAML==5.4.1",  # Used for config file format
+    "PyYAML==6.0",  # Used for config file format
     "setproctitle==1.2.3",  # Gives the chia processes readable names
     "sortedcontainers==2.4.0",  # For maintaining sorted mempools
     # TODO: when moving to click 8 remove the pinning of black noted below
-- 
2.34.1


From dae4f55aa5beb0c5d75ae5ad230b4c4f084e28f4 Mon Sep 17 00:00:00 2001
From: William Blanke <wjb98672@gmail.com>
Date: Sun, 24 Apr 2022 10:24:15 -0700
Subject: [PATCH 52/77] updated gui to 042e2af1a4f0333939286328d0b59d592e605daf

---
 chia-blockchain-gui | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/chia-blockchain-gui b/chia-blockchain-gui
index 81303fb96..042e2af1a 160000
--- a/chia-blockchain-gui
+++ b/chia-blockchain-gui
@@ -1 +1 @@
-Subproject commit 81303fb962f4a627a2e1c55098e187a9057745da
+Subproject commit 042e2af1a4f0333939286328d0b59d592e605daf
-- 
2.34.1


From bb556dffbd455d77b7a9b43f69fa3060f4db2860 Mon Sep 17 00:00:00 2001
From: William Blanke <wjb98672@gmail.com>
Date: Sun, 24 Apr 2022 10:25:05 -0700
Subject: [PATCH 53/77] updated gui to
 042e2af1a4f0333939286328d0b59d592e605daf. bls to 1.0.11 for windows multi

---
 setup.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/setup.py b/setup.py
index ea54221b9..4c969130a 100644
--- a/setup.py
+++ b/setup.py
@@ -2,7 +2,7 @@ from setuptools import setup
 
 dependencies = [
     "aiofiles==0.7.0",  # Async IO for files
-    "blspy==1.0.9",  # Signature library
+    "blspy==1.0.11",  # Signature library
     "chiavdf==1.0.6",  # timelord and vdf verification
     "chiabip158==1.1",  # bip158-style wallet filters
     "chiapos==1.0.10",  # proof of space
-- 
2.34.1


From e584513c7013e2520c43ac7746c3e22ee557ab50 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Mon, 25 Apr 2022 09:20:08 -0700
Subject: [PATCH 54/77] Add Linux Mint to test matrix (#11295)

* add Linux Mint to test matrix

* : -> / for linux mint dockers

* Prepare Linux Mint

* stop testing linux mint 21 since it reports 20.3

* names, comment, and add 19.2

* mint

* manually install requests

* trailing whitespace
---
 .github/workflows/test-install-scripts.yml | 54 ++++++++++++++++++++++
 1 file changed, 54 insertions(+)

diff --git a/.github/workflows/test-install-scripts.yml b/.github/workflows/test-install-scripts.yml
index 05e1d419e..6ad2cfc38 100644
--- a/.github/workflows/test-install-scripts.yml
+++ b/.github/workflows/test-install-scripts.yml
@@ -113,6 +113,41 @@ jobs:
           type: ubuntu
           # https://packages.ubuntu.com/impish/python3 (21.10, 3.9)
           url: "docker://ubuntu:impish"
+        - name: linuxmintd/mint19.1-amd64 (Tessa)
+          type: mint
+          # 3.6 default with an option for 3.7
+          url: "docker://linuxmintd/mint19.1-amd64"
+        - name: linuxmintd/mint19.2-amd64 (Tina)
+          type: mint
+          # 3.6 default with an option for 3.7
+          url: "docker://linuxmintd/mint19.2-amd64"
+        - name: linuxmintd/mint19.3-amd64 (Tricia)
+          type: mint
+          # 3.6 default with an option for 3.7
+          url: "docker://linuxmintd/mint19.3-amd64"
+        - name: linuxmintd/mint20-amd64 (Ulyana)
+          type: mint
+          # 3.8
+          url: "docker://linuxmintd/mint20-amd64"
+        - name: linuxmintd/mint20.1-amd64 (Ulyssa)
+          type: mint
+          # 3.8
+          url: "docker://linuxmintd/mint20.1-amd64"
+        - name: linuxmintd/mint20.2-amd64 (Uma)
+          type: mint
+          # 3.8
+          url: "docker://linuxmintd/mint20.2-amd64"
+        - name: linuxmintd/mint20.3-amd64 (Una)
+          type: mint
+          # 3.8
+          url: "docker://linuxmintd/mint20.3-amd64"
+#        The Linux Mint 21 docker image reports as 20.3 but has different Python.
+#        Uncomment after adapting to handle this or upstream fixing it.
+#        Also, Linux Mint 21 is not released as of this change.
+#        - name: linuxmintd/mint21-amd64
+#          type: linuxmint
+#          # 3.10 default with an option for 3.9
+#          url: "docker://linuxmintd/mint21-amd64"
 
     steps:
     - name: Prepare Amazon Linux
@@ -188,6 +223,25 @@ jobs:
         apt-get --yes update
         apt-get install --yes git lsb-release sudo
 
+    - name: Prepare Linux Mint
+      if: ${{ matrix.distribution.type == 'mint' }}
+      env:
+        DEBIAN_FRONTEND: noninteractive
+      run: |
+        # for 19.*
+        apt-get --yes update
+        # for 19.3 to avoid
+        # Setting up software-properties-common (2.0.0.2) ...
+        # Traceback (most recent call last):
+        #   File "/usr/lib/linuxmint/mintSources/mintSources.py", line 11, in <module>
+        #     import requests
+        # ModuleNotFoundError: No module named 'requests'
+        apt-get install --yes python3-requests
+        apt-get install --yes software-properties-common
+        add-apt-repository --yes ppa:git-core/ppa
+        apt-get --yes update
+        apt-get install --yes git lsb-release sudo
+
     - name: Add safe git directory
       run: git config --global --add safe.directory $GITHUB_WORKSPACE
 
-- 
2.34.1


From 3f0dd497a7b2262b287781b624da291ced725a5f Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Mon, 25 Apr 2022 11:20:39 -0500
Subject: [PATCH 55/77] Update to pyinstaller 5.0 (#11289)

---
 build_scripts/build_windows.ps1 | 2 +-
 setup.py                        | 2 +-
 2 files changed, 2 insertions(+), 2 deletions(-)

diff --git a/build_scripts/build_windows.ps1 b/build_scripts/build_windows.ps1
index 38498d42b..e0e7e8fcc 100644
--- a/build_scripts/build_windows.ps1
+++ b/build_scripts/build_windows.ps1
@@ -31,7 +31,7 @@ python -m venv venv
 python -m pip install --upgrade pip
 pip install wheel pep517
 pip install pywin32
-pip install pyinstaller==4.9
+pip install pyinstaller==5.0
 
 Write-Output "   ---"
 # The environment variable CHIA_INSTALLER_VERSION needs to be defined
diff --git a/setup.py b/setup.py
index 4c969130a..6fcb759a4 100644
--- a/setup.py
+++ b/setup.py
@@ -56,7 +56,7 @@ dev_dependencies = [
     "black==21.12b0",
     "aiohttp_cors",  # For blackd
     "ipython",  # For asyncio debugging
-    "pyinstaller==4.9",
+    "pyinstaller==5.0",
     "types-aiofiles",
     "types-click",
     "types-cryptography",
-- 
2.34.1


From bcaa5e6088671ad68bb21d98d750934410216869 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Mon, 25 Apr 2022 11:08:26 -0700
Subject: [PATCH 56/77] simplify install.sh ubuntu version tracking (#11288)

* simplify install.sh ubuntu version tracking

* quotes for bash

* undo some unintended changes
---
 install.sh | 20 ++++++++++++++------
 1 file changed, 14 insertions(+), 6 deletions(-)

diff --git a/install.sh b/install.sh
index 5ce4095fe..8e2b97131 100755
--- a/install.sh
+++ b/install.sh
@@ -56,7 +56,10 @@ fi
 # Get submodules
 git submodule update --init mozilla-ca
 
-UBUNTU_PRE_2004=false
+UBUNTU_PRE_2004=0
+UBUNTU_2000=0
+UBUNTU_2100=0
+
 if $UBUNTU; then
   LSB_RELEASE=$(lsb_release -rs)
   # In case Ubuntu minimal does not come with bc
@@ -64,8 +67,13 @@ if $UBUNTU; then
     sudo apt install bc -y
   fi
   # Mint 20.04 responds with 20 here so 20 instead of 20.04
-  UBUNTU_PRE_2004=$(echo "$LSB_RELEASE<20" | bc)
-  UBUNTU_2100=$(echo "$LSB_RELEASE>=21" | bc)
+  if [ "$(echo "$LSB_RELEASE<20" | bc)" = "1" ]; then
+    UBUNTU_PRE_2004=1
+  elif [ "$(echo "$LSB_RELEASE<21" | bc)" = "1" ]; then
+    UBUNTU_2000=1
+  else
+    UBUNTU_2100=1
+  fi
 fi
 
 install_python3_and_sqlite3_from_source_with_yum() {
@@ -114,16 +122,16 @@ install_python3_and_sqlite3_from_source_with_yum() {
 # Manage npm and other install requirements on an OS specific basis
 if [ "$(uname)" = "Linux" ]; then
   #LINUX=1
-  if [ "$UBUNTU" = "true" ] && [ "$UBUNTU_PRE_2004" = "1" ]; then
+  if [ "$UBUNTU_PRE_2004" = "1" ]; then
     # Ubuntu
     echo "Installing on Ubuntu pre 20.04 LTS."
     sudo apt-get update
     sudo apt-get install -y python3.7-venv python3.7-distutils openssl
-  elif [ "$UBUNTU" = "true" ] && [ "$UBUNTU_PRE_2004" = "0" ] && [ "$UBUNTU_2100" = "0" ]; then
+  elif [ "$UBUNTU_2000" = "1" ]; then
     echo "Installing on Ubuntu 20.04 LTS."
     sudo apt-get update
     sudo apt-get install -y python3.8-venv python3-distutils openssl
-  elif [ "$UBUNTU" = "true" ] && [ "$UBUNTU_2100" = "1" ]; then
+  elif [ "$UBUNTU_2100" = "1" ]; then
     echo "Installing on Ubuntu 21.04 or newer."
     sudo apt-get update
     sudo apt-get install -y python3.9-venv python3-distutils openssl
-- 
2.34.1


From d750c901b96e650ce039285e01ff0ffc589e5d1e Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Mon, 25 Apr 2022 16:50:38 -0500
Subject: [PATCH 57/77] Fix targeting for arm64 to not land on native arm64 mac
 runners (#11309)

---
 .github/workflows/build-linux-arm64-installer.yml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/.github/workflows/build-linux-arm64-installer.yml b/.github/workflows/build-linux-arm64-installer.yml
index 56a3b5e7f..5e17da8df 100644
--- a/.github/workflows/build-linux-arm64-installer.yml
+++ b/.github/workflows/build-linux-arm64-installer.yml
@@ -18,7 +18,7 @@ concurrency:
 jobs:
   build:
     name: Linux ARM64 installer on Python 3.8
-    runs-on: [ARM64]
+    runs-on: [Linux, ARM64]
     container: chianetwork/ubuntu-18.04-builder:latest
     timeout-minutes: 120
     strategy:
-- 
2.34.1


From bfb488b1b9cfb88364171205de981e1cab01ba15 Mon Sep 17 00:00:00 2001
From: Jack Nelson <jack@jacknelson.xyz>
Date: Mon, 25 Apr 2022 19:05:35 -0400
Subject: [PATCH 58/77] undo 9130 (#10278)

---
 chia/consensus/default_constants.py | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/chia/consensus/default_constants.py b/chia/consensus/default_constants.py
index a6066fe4c..a4eed66e0 100644
--- a/chia/consensus/default_constants.py
+++ b/chia/consensus/default_constants.py
@@ -38,8 +38,8 @@ testnet_kwargs = {
         "3d8765d3a597ec1d99663f6c9816d915b9f68613ac94009884c4addaefcce6af"
     ),
     "MAX_VDF_WITNESS_SIZE": 64,
-    # Size of mempool = 50x the size of block # temporary change until #9125 gets in
-    "MEMPOOL_BLOCK_BUFFER": 10,
+    # Size of mempool = 50x the size of block
+    "MEMPOOL_BLOCK_BUFFER": 50,
     # Max coin amount, fits into 64 bits
     "MAX_COIN_AMOUNT": uint64((1 << 64) - 1),
     # Max block cost in clvm cost units
-- 
2.34.1


From 83337750407a2223bfde26a9fb4d3cd346e41105 Mon Sep 17 00:00:00 2001
From: Arvid Norberg <arvid@libtorrent.org>
Date: Tue, 26 Apr 2022 01:06:18 +0200
Subject: [PATCH 59/77] make BlockTools generate more accurate block timestamps
 (#11261)

* when generating blocks, we truncate the time-per-block to whole seconds before assigning the timestamp to the next block. When the time-per-block has a fractional part (say, 18.75) the blocks will consistently come 0.75 seconds early. This patch rounds up or down with a probability proportional to the size of the fractional part. This means blocks will come at the right time on average

* make block timestamp rounding deterministic, depending on residual from last rounding

* disable block timestamp residual by default, to not disturb existing tests
---
 tests/block_tools.py | 47 +++++++++++++++++++++++++++++++++-----------
 1 file changed, 36 insertions(+), 11 deletions(-)

diff --git a/tests/block_tools.py b/tests/block_tools.py
index 6c573dffe..da42e7eb7 100644
--- a/tests/block_tools.py
+++ b/tests/block_tools.py
@@ -1,4 +1,5 @@
 import asyncio
+import math
 import copy
 import logging
 import os
@@ -144,6 +145,7 @@ class BlockTools:
 
         self.root_path = root_path
         self.local_keychain = keychain
+        self._block_time_residual = 0.0
 
         create_default_chia_config(root_path)
         create_all_ssl(
@@ -437,12 +439,14 @@ class BlockTools:
         previous_generator: Optional[Union[CompressorArg, List[uint32]]] = None,
         genesis_timestamp: Optional[uint64] = None,
         force_plot_id: Optional[bytes32] = None,
+        use_timestamp_residual: bool = False,
     ) -> List[FullBlock]:
         assert num_blocks > 0
         if block_list_input is not None:
             block_list = block_list_input.copy()
         else:
             block_list = []
+
         constants = self.constants
         transaction_data_included = False
         if time_per_block is None:
@@ -601,7 +605,10 @@ class BlockTools:
                             block_generator = None
                             aggregate_signature = G2Element()
 
-                        full_block, block_record = get_full_block_and_block_record(
+                        if not use_timestamp_residual:
+                            self._block_time_residual = 0.0
+
+                        full_block, block_record, self._block_time_residual = get_full_block_and_block_record(
                             constants,
                             blocks,
                             sub_slot_start_total_iters,
@@ -630,6 +637,7 @@ class BlockTools:
                             seed,
                             normalized_to_identity_cc_ip=normalized_to_identity_cc_ip,
                             current_time=current_time,
+                            block_time_residual=self._block_time_residual,
                         )
                         if block_record.is_transaction_block:
                             transaction_data_included = True
@@ -868,7 +876,11 @@ class BlockTools:
                         else:
                             block_generator = None
                             aggregate_signature = G2Element()
-                        full_block, block_record = get_full_block_and_block_record(
+
+                        if not use_timestamp_residual:
+                            self._block_time_residual = 0.0
+
+                        full_block, block_record, self._block_time_residual = get_full_block_and_block_record(
                             constants,
                             blocks,
                             sub_slot_start_total_iters,
@@ -899,6 +911,7 @@ class BlockTools:
                             overflow_rc_challenge=overflow_rc_challenge,
                             normalized_to_identity_cc_ip=normalized_to_identity_cc_ip,
                             current_time=current_time,
+                            block_time_residual=self._block_time_residual,
                         )
 
                         if block_record.is_transaction_block:
@@ -1132,7 +1145,8 @@ class BlockTools:
         force_plot_id: Optional[bytes32] = None,
     ) -> List[Tuple[uint64, ProofOfSpace]]:
         found_proofs: List[Tuple[uint64, ProofOfSpace]] = []
-        random.seed(seed)
+        rng = random.Random()
+        rng.seed(seed)
         for plot_info in self.plot_manager.plots.values():
             plot_id: bytes32 = plot_info.prover.get_id()
             if force_plot_id is not None and plot_id != force_plot_id:
@@ -1180,9 +1194,9 @@ class BlockTools:
                         found_proofs.append((required_iters, proof_of_space))
         random_sample = found_proofs
         if len(found_proofs) >= 1:
-            if random.random() < 0.1:
+            if rng.random() < 0.1:
                 # Removes some proofs of space to create "random" chains, based on the seed
-                random_sample = random.sample(found_proofs, len(found_proofs) - 1)
+                random_sample = rng.sample(found_proofs, len(found_proofs) - 1)
         return random_sample
 
 
@@ -1469,6 +1483,11 @@ def get_icc(
     )
 
 
+def round_timestamp(timestamp: float, residual: float) -> Tuple[int, float]:
+    mod = math.modf(timestamp + residual)
+    return (int(mod[1]), mod[0])
+
+
 def get_full_block_and_block_record(
     constants: ConsensusConstants,
     blocks: Dict[bytes32, BlockRecord],
@@ -1501,14 +1520,19 @@ def get_full_block_and_block_record(
     overflow_rc_challenge: bytes32 = None,
     normalized_to_identity_cc_ip: bool = False,
     current_time: bool = False,
-) -> Tuple[FullBlock, BlockRecord]:
+    block_time_residual: float = 0.0,
+) -> Tuple[FullBlock, BlockRecord, float]:
     if current_time is True:
         if prev_block.timestamp is not None:
-            timestamp = uint64(max(int(time.time()), prev_block.timestamp + int(time_per_block)))
+            time_delta, block_time_residual = round_timestamp(time_per_block, block_time_residual)
+            timestamp = uint64(max(int(time.time()), prev_block.timestamp + time_delta))
         else:
             timestamp = uint64(int(time.time()))
     else:
-        timestamp = uint64(start_timestamp + int((prev_block.height + 1 - start_height) * time_per_block))
+        time_delta, block_time_residual = round_timestamp(
+            (prev_block.height + 1 - start_height) * time_per_block, block_time_residual
+        )
+        timestamp = uint64(start_timestamp + time_delta)
     sp_iters = calculate_sp_iters(constants, sub_slot_iters, signage_point_index)
     ip_iters = calculate_ip_iters(constants, sub_slot_iters, signage_point_index, required_iters)
 
@@ -1559,7 +1583,7 @@ def get_full_block_and_block_record(
         normalized_to_identity_cc_ip,
     )
 
-    return full_block, block_record
+    return full_block, block_record, block_time_residual
 
 
 def compute_cost_test(generator: BlockGenerator, cost_per_byte: int) -> Tuple[Optional[uint16], uint64]:
@@ -1632,9 +1656,10 @@ def create_test_foliage(
         prev_transaction_block = None
         is_transaction_block = True
 
-    random.seed(seed)
+    rng = random.Random()
+    rng.seed(seed)
     # Use the extension data to create different blocks based on header hash
-    extension_data: bytes32 = bytes32(random.randint(0, 100000000).to_bytes(32, "big"))
+    extension_data: bytes32 = bytes32(rng.randint(0, 100000000).to_bytes(32, "big"))
     if prev_block is None:
         height: uint32 = uint32(0)
     else:
-- 
2.34.1


From 73e1fabb5dca522c27c16592bdc07c327c99abf6 Mon Sep 17 00:00:00 2001
From: Arvid Norberg <arvid@libtorrent.org>
Date: Tue, 26 Apr 2022 01:06:35 +0200
Subject: [PATCH 60/77] significantly speed up get_consecutive_blocks() in
 BlockTools, but caching the block-map, height-to-hash and difficulty from the
 last invocation (#11263)

---
 tests/block_tools.py | 28 +++++++++++++++++++++++++---
 1 file changed, 25 insertions(+), 3 deletions(-)

diff --git a/tests/block_tools.py b/tests/block_tools.py
index da42e7eb7..0cb9e541a 100644
--- a/tests/block_tools.py
+++ b/tests/block_tools.py
@@ -131,6 +131,11 @@ class BlockTools:
     Tools to generate blocks for testing.
     """
 
+    _block_cache_header: bytes32
+    _block_cache_height_to_hash: Dict[uint32, bytes32]
+    _block_cache_difficulty: uint64
+    _block_cache: Dict[bytes32, BlockRecord]
+
     def __init__(
         self,
         constants: ConsensusConstants = test_constants,
@@ -138,6 +143,9 @@ class BlockTools:
         const_dict=None,
         keychain: Optional[Keychain] = None,
     ):
+
+        self._block_cache_header = bytes32([0] * 32)
+
         self._tempdir = None
         if root_path is None:
             self._tempdir = tempfile.TemporaryDirectory()
@@ -478,7 +486,12 @@ class BlockTools:
             return block_list
 
         blocks: Dict[bytes32, BlockRecord]
-        height_to_hash, difficulty, blocks = load_block_list(block_list, constants)
+        if block_list[-1].header_hash == self._block_cache_header:
+            height_to_hash = self._block_cache_height_to_hash
+            difficulty = self._block_cache_difficulty
+            blocks = self._block_cache
+        else:
+            height_to_hash, difficulty, blocks = load_block_list(block_list, constants)
 
         latest_block: BlockRecord = blocks[block_list[-1].header_hash]
         curr = latest_block
@@ -665,6 +678,10 @@ class BlockTools:
                         finished_sub_slots_at_ip = []
                         num_blocks -= 1
                         if num_blocks <= 0 and not keep_going_until_tx_block:
+                            self._block_cache_header = block_list[-1].header_hash
+                            self._block_cache_height_to_hash = height_to_hash
+                            self._block_cache_difficulty = difficulty
+                            self._block_cache = blocks
                             return block_list
 
             # Finish the end of sub-slot and try again next sub-slot
@@ -934,14 +951,19 @@ class BlockTools:
                         blocks_added_this_sub_slot += 1
                         log.info(f"Created block {block_record.height } ov=True, iters " f"{block_record.total_iters}")
                         num_blocks -= 1
-                        if num_blocks <= 0 and not keep_going_until_tx_block:
-                            return block_list
 
                         blocks[full_block.header_hash] = block_record
                         height_to_hash[uint32(full_block.height)] = full_block.header_hash
                         latest_block = blocks[full_block.header_hash]
                         finished_sub_slots_at_ip = []
 
+                        if num_blocks <= 0 and not keep_going_until_tx_block:
+                            self._block_cache_header = block_list[-1].header_hash
+                            self._block_cache_height_to_hash = height_to_hash
+                            self._block_cache_difficulty = difficulty
+                            self._block_cache = blocks
+                            return block_list
+
             finished_sub_slots_at_sp = finished_sub_slots_eos.copy()
             same_slot_as_last = False
             sub_slot_start_total_iters = uint128(sub_slot_start_total_iters + sub_slot_iters)
-- 
2.34.1


From fd7c3c6363ad016af2723a7d117f4d75da70f269 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Tue, 26 Apr 2022 10:01:21 -0500
Subject: [PATCH 61/77] Update names of installer workflows so they get grouped
 together in the workflow listing (#11310)

---
 .github/workflows/build-linux-arm64-installer.yml | 4 ++--
 .github/workflows/build-linux-installer-deb.yml   | 4 ++--
 .github/workflows/build-linux-installer-rpm.yml   | 4 ++--
 .github/workflows/build-macos-installer.yml       | 4 ++--
 .github/workflows/build-macos-m1-installer.yml    | 4 ++--
 .github/workflows/build-windows-installer.yml     | 4 ++--
 6 files changed, 12 insertions(+), 12 deletions(-)

diff --git a/.github/workflows/build-linux-arm64-installer.yml b/.github/workflows/build-linux-arm64-installer.yml
index 5e17da8df..418cebd28 100644
--- a/.github/workflows/build-linux-arm64-installer.yml
+++ b/.github/workflows/build-linux-arm64-installer.yml
@@ -1,4 +1,4 @@
-name: Linux ARM64 installer on Python 3.8
+name: Build Installer - Linux DEB ARM64
 
 on:
   push:
@@ -17,7 +17,7 @@ concurrency:
 
 jobs:
   build:
-    name: Linux ARM64 installer on Python 3.8
+    name: Linux arm64 DEB Installer
     runs-on: [Linux, ARM64]
     container: chianetwork/ubuntu-18.04-builder:latest
     timeout-minutes: 120
diff --git a/.github/workflows/build-linux-installer-deb.yml b/.github/workflows/build-linux-installer-deb.yml
index e1ff9de56..3147ffc05 100644
--- a/.github/workflows/build-linux-installer-deb.yml
+++ b/.github/workflows/build-linux-installer-deb.yml
@@ -1,4 +1,4 @@
-name: Linux .deb installer on Python 3.8
+name: Build Installer - Linux DEB AMD64
 
 on:
   workflow_dispatch:
@@ -18,7 +18,7 @@ concurrency:
 
 jobs:
   build:
-    name: Linux .deb installer on Python 3.8
+    name: Linux amd64 DEB Installer
     runs-on: ${{ matrix.os }}
     timeout-minutes: 40
     strategy:
diff --git a/.github/workflows/build-linux-installer-rpm.yml b/.github/workflows/build-linux-installer-rpm.yml
index 36c5795aa..be74457ca 100644
--- a/.github/workflows/build-linux-installer-rpm.yml
+++ b/.github/workflows/build-linux-installer-rpm.yml
@@ -1,4 +1,4 @@
-name: Linux .rpm installer on Python 3.9
+name: Build Installer - Linux RPM AMD64
 
 on:
   workflow_dispatch:
@@ -18,7 +18,7 @@ concurrency:
 
 jobs:
   build:
-    name: Linux .rpm installer on Python 3.9
+    name: Linux amd64 RPM Installer
     runs-on: ubuntu-latest
     container:
       image: chianetwork/centos7-builder:latest
diff --git a/.github/workflows/build-macos-installer.yml b/.github/workflows/build-macos-installer.yml
index ef3b41c58..6748cc037 100644
--- a/.github/workflows/build-macos-installer.yml
+++ b/.github/workflows/build-macos-installer.yml
@@ -1,4 +1,4 @@
-name: MacOS Intel installer on Python 3.9
+name: Build Installer - MacOS Intel
 
 on:
   push:
@@ -17,7 +17,7 @@ concurrency:
 
 jobs:
   build:
-    name: MacOS Intel Installer on Python 3.9
+    name: MacOS Intel Installer
     runs-on: ${{ matrix.os }}
     timeout-minutes: 40
     strategy:
diff --git a/.github/workflows/build-macos-m1-installer.yml b/.github/workflows/build-macos-m1-installer.yml
index 17cc3b70c..d234c1514 100644
--- a/.github/workflows/build-macos-m1-installer.yml
+++ b/.github/workflows/build-macos-m1-installer.yml
@@ -1,4 +1,4 @@
-name: MacOS M1 installer on Python 3.9
+name: Build Installer - MacOS arm64
 
 on:
   push:
@@ -17,7 +17,7 @@ concurrency:
 
 jobs:
   build:
-    name: MacOS M1 installer on Python 3.9
+    name: MacOS arm64 installer
     runs-on: [m1]
     timeout-minutes: 40
     strategy:
diff --git a/.github/workflows/build-windows-installer.yml b/.github/workflows/build-windows-installer.yml
index b74fefd1b..15fa47090 100644
--- a/.github/workflows/build-windows-installer.yml
+++ b/.github/workflows/build-windows-installer.yml
@@ -1,4 +1,4 @@
-name: Windows Installer on Windows 10 and Python 3.9
+name: Build Installer - Windows 10
 
 on:
   push:
@@ -17,7 +17,7 @@ concurrency:
 
 jobs:
   build:
-    name: Windows Installer on Windows 10 and Python 3.9
+    name: Windows 10 Installer
     runs-on: [windows-2019]
     timeout-minutes: 50
 
-- 
2.34.1


From f976c07c54c15eee8be00bd385b1fadcf9cc79bf Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Tue, 26 Apr 2022 10:48:04 -0700
Subject: [PATCH 62/77] also m1 and arm64 for wheel checks (#11277)

* also m1 and arm64 for wheel checks

* account for self-hosted and pre-setup-python of m1 and arm64 runners

* &&

* python3

* report python version

* use docker on arm64 to get multiple python versions

* flush

* report more system information

* except pycryptodome for now

* more variables, simpler logic

* corrections

* switch to [macos, arm64]

* add python version to job name

* separate os and arch matrix axes

* reorder matrixing

* drop workflow name from job name

* oops

* skip python setup in docker cases

* drop the containers

* Update check_dependency_artifacts.py
---
 .../workflows/check_wheel_availability.yaml   | 35 ++++++++++++++++---
 build_scripts/check_dependency_artifacts.py   | 14 ++++++++
 2 files changed, 44 insertions(+), 5 deletions(-)

diff --git a/.github/workflows/check_wheel_availability.yaml b/.github/workflows/check_wheel_availability.yaml
index c051bd485..4563629cf 100644
--- a/.github/workflows/check_wheel_availability.yaml
+++ b/.github/workflows/check_wheel_availability.yaml
@@ -17,20 +17,45 @@ concurrency:
 
 jobs:
   check_dependency_artifacts:
-    name: Check Dependency Artifacts
-    runs-on: ${{ matrix.os }}
+    name: ${{ matrix.os.name }} ${{ matrix.arch.name }} ${{ matrix.python-version }}
+    runs-on: ${{ matrix.os.runs-on[matrix.arch.matrix] }}
     strategy:
       fail-fast: false
       matrix:
+        os:
+          - name: Linux
+            matrix: linux
+            runs-on:
+              intel: ubuntu-latest
+              arm: [linux, arm64]
+          - name: macOS
+            matrix: macos
+            runs-on:
+              intel: macos-latest
+              arm: [macos, arm64]
+        arch:
+          - name: ARM64
+            matrix: arm
+          - name: Intel
+            matrix: intel
         python-version: ['3.7', '3.8', '3.9']
-        os: [macOS-latest, ubuntu-latest]
+        exclude:
+          - os:
+              matrix: macos
+            python-version: '3.7'
+          - os:
+              matrix: macos
+            arch:
+              matrix: arm
+            python-version: '3.8'
 
     steps:
+    - uses: Chia-Network/actions/clean-workspace@main
+
     - name: Checkout Code
       uses: actions/checkout@v3
 
-    - name: Setup Python environment
-      uses: actions/setup-python@v2
+    - uses: Chia-Network/actions/setup-python@main
       with:
         python-version: ${{ matrix.python-version }}
 
diff --git a/build_scripts/check_dependency_artifacts.py b/build_scripts/check_dependency_artifacts.py
index 2c34a4c54..07fe57b83 100644
--- a/build_scripts/check_dependency_artifacts.py
+++ b/build_scripts/check_dependency_artifacts.py
@@ -1,5 +1,6 @@
 import os
 import pathlib
+import platform
 import subprocess
 import sys
 import tempfile
@@ -20,6 +21,8 @@ def excepted(path: pathlib.Path) -> bool:
 
 def main() -> int:
     with tempfile.TemporaryDirectory() as directory_string:
+        print(f"Working in: {directory_string}")
+        print()
         directory_path = pathlib.Path(directory_string)
 
         extras = ["upnp"]
@@ -30,6 +33,17 @@ def main() -> int:
         else:
             package_and_extras = package_path_string
 
+        print("Downloading packages for Python version:")
+        lines = [
+            *sys.version.splitlines(),
+            "",
+            f"machine: {platform.machine()}",
+            f"platform: {platform.platform()}",
+        ]
+        for line in lines:
+            print(f"    {line}")
+        print(flush=True)
+
         subprocess.run(
             [
                 sys.executable,
-- 
2.34.1


From a983c4a90bb75338fa0b3cbf9f048063582044d7 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Tue, 26 Apr 2022 13:27:14 -0500
Subject: [PATCH 63/77] Upload CLI RPMS to s3, create checksums, etc (#11316)

---
 .../workflows/build-linux-installer-rpm.yml   | 24 ++++++++++++-------
 1 file changed, 16 insertions(+), 8 deletions(-)

diff --git a/.github/workflows/build-linux-installer-rpm.yml b/.github/workflows/build-linux-installer-rpm.yml
index be74457ca..38f6d5486 100644
--- a/.github/workflows/build-linux-installer-rpm.yml
+++ b/.github/workflows/build-linux-installer-rpm.yml
@@ -145,15 +145,17 @@ jobs:
           echo "CHIA_DEV_BUILD=$CHIA_DEV_BUILD" >>$GITHUB_ENV
           ls $GITHUB_WORKSPACE/build_scripts/final_installer/
           aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm s3://download.chia.net/dev/chia-blockchain-${CHIA_DEV_BUILD}-1.x86_64.rpm
+          aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm s3://download.chia.net/dev/chia-blockchain-cli-${CHIA_DEV_BUILD}-1.x86_64.rpm
 
     - name: Create Checksums
       if: startsWith(github.ref, 'refs/tags/') || github.ref == 'refs/heads/main'
       env:
         CHIA_INSTALLER_VERSION: ${{ steps.version_number.outputs.CHIA_INSTALLER_VERSION }}
       run: |
-         ls $GITHUB_WORKSPACE/build_scripts/final_installer/
-         sha256sum $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm > $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.sha256
-         ls $GITHUB_WORKSPACE/build_scripts/final_installer/
+        ls $GITHUB_WORKSPACE/build_scripts/final_installer/
+        sha256sum $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm > $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.sha256
+        sha256sum $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm > $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.sha256
+        ls $GITHUB_WORKSPACE/build_scripts/final_installer/
 
     - name: Install py3createtorrent
       if: startsWith(github.ref, 'refs/tags/') || github.ref == 'refs/heads/main'
@@ -165,8 +167,9 @@ jobs:
       env:
         CHIA_INSTALLER_VERSION: ${{ steps.version_number.outputs.CHIA_INSTALLER_VERSION }}
       run: |
-          py3createtorrent -f -t udp://tracker.opentrackr.org:1337/announce $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm -o $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.torrent --webseed https://download.chia.net/install/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm
-          ls
+        py3createtorrent -f -t udp://tracker.opentrackr.org:1337/announce $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm -o $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.torrent --webseed https://download.chia.net/install/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm
+        py3createtorrent -f -t udp://tracker.opentrackr.org:1337/announce $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm -o $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.torrent --webseed https://download.chia.net/install/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm
+        ls
 
     - name: Upload Beta Installer
       if: steps.check_secrets.outputs.HAS_SECRET && github.ref == 'refs/heads/main'
@@ -175,15 +178,20 @@ jobs:
       run: |
         aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm s3://download.chia.net/beta/chia-blockchain-1.x86_64_latest_beta.rpm
         aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.sha256 s3://download.chia.net/beta/chia-blockchain-1.x86_64_latest_beta.rpm.sha256
+        aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm s3://download.chia.net/beta/chia-blockchain-cli-1.x86_64_latest_beta.rpm
+        aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.sha256 s3://download.chia.net/beta/chia-blockchain-cli-1.x86_64_latest_beta.rpm.sha256
 
     - name: Upload Release Files
       if: steps.check_secrets.outputs.HAS_SECRET && startsWith(github.ref, 'refs/tags/')
       env:
         CHIA_INSTALLER_VERSION: ${{ steps.version_number.outputs.CHIA_INSTALLER_VERSION }}
       run: |
-          aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm s3://download.chia.net/install/
-          aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.sha256 s3://download.chia.net/install/
-          aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.torrent s3://download.chia.net/torrents/
+        aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm s3://download.chia.net/install/
+        aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.sha256 s3://download.chia.net/install/
+        aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.torrent s3://download.chia.net/torrents/
+        aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm s3://download.chia.net/install/
+        aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.sha256 s3://download.chia.net/install/
+        aws s3 cp $GITHUB_WORKSPACE/build_scripts/final_installer/chia-blockchain-cli-${CHIA_INSTALLER_VERSION}-1.x86_64.rpm.torrent s3://download.chia.net/torrents/
 
     - name: Get tag name
       if: startsWith(github.ref, 'refs/tags/')
-- 
2.34.1


From 7892148bdc3ab37720f182db44ac2b768f130d0a Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Tue, 26 Apr 2022 12:37:01 -0700
Subject: [PATCH 64/77] Support for Python 3.10 (#9930)

* Support for Python 3.10

* Update install.sh to block Python 3.11

* websockets to 10.1

* Update workflows for Python 3.10

* single quote 3.10

* Enable fedora:35 (py3.10) installer script testing

* rebuild workflows

* fixup test-install-scripts.yml

* add ignore for distutils deprecation in tests for now

* asyncio.get_event_loop().run_until_complete() -> asyncio.run()

* aiohttp==3.8.1 for python 3.10 support

* use ssl.Purpose.CLIENT_AUTH for ssl_context_for_server()

* rebuild workflows

* use ssl_context_for_client() in BlockTools.get_daemon_ssl_context()

* create a client context for the RpcServer to connect to the daemon

* go back to asyncio.get_event_loop().run_until_complete() for now to recover 3.7

* ignore:There is no current event loop:DeprecationWarning

* Ms.plot load perf2 (#10978)

* 2.7 seconds -> 0.45 seconds

* Merge

* Work on create_plots refactor

* Try to fix tests

* Try to fix tests

* Use new functions

* Fix block_tools by adding dir

* Extra argument

* Try to fix cyclic import

* isort

* Drop warning

* Some cleanups around `exclude_final_dir` and directory adding

* Cleanup `min_mainnet_k_size` checks

* Drop unrelated changes

* Fixes after rebase

* Fix cyclic import

* Update tests/block_tools.py

Co-authored-by: dustinface <35775977+xdustinface@users.noreply.github.com>

* Update tests/block_tools.py

Co-authored-by: dustinface <35775977+xdustinface@users.noreply.github.com>

Co-authored-by: xdustinface <xdustinfacex@gmail.com>
Co-authored-by: dustinface <35775977+xdustinface@users.noreply.github.com>

* remove 3.10 avoidance step from debian:bookworm installer testing

* add 3.10 to wheel availability check workflow

* add 3.10 to Install.ps1 supported Python versions for Windows

* add jammy jellyfish to the install script test matrix

* correct ubuntu:jammy job name

* add 22.04 with Python 3.10 to install.sh

Co-authored-by: Gene Hoffman <hoffmang@hoffmang.com>
Co-authored-by: Yostra <straya@chia.net>
Co-authored-by: Mariano Sorgente <3069354+mariano54@users.noreply.github.com>
Co-authored-by: xdustinface <xdustinfacex@gmail.com>
Co-authored-by: dustinface <35775977+xdustinface@users.noreply.github.com>
---
 .../workflows/build-test-macos-blockchain.yml |  2 +-
 .github/workflows/build-test-macos-clvm.yml   |  2 +-
 .../workflows/build-test-macos-core-cmds.yml  |  2 +-
 .../build-test-macos-core-consensus.yml       |  2 +-
 .../build-test-macos-core-custom_types.yml    |  2 +-
 .../build-test-macos-core-daemon.yml          |  2 +-
 ...ld-test-macos-core-full_node-full_sync.yml |  2 +-
 ...build-test-macos-core-full_node-stores.yml |  2 +-
 .../build-test-macos-core-full_node.yml       |  2 +-
 .../build-test-macos-core-server.yml          |  2 +-
 .../workflows/build-test-macos-core-ssl.yml   |  2 +-
 .../workflows/build-test-macos-core-util.yml  |  2 +-
 .github/workflows/build-test-macos-core.yml   |  2 +-
 .../build-test-macos-farmer_harvester.yml     |  2 +-
 .../workflows/build-test-macos-generator.yml  |  2 +-
 .../workflows/build-test-macos-plot_sync.yml  |  2 +-
 .../workflows/build-test-macos-plotting.yml   |  2 +-
 .github/workflows/build-test-macos-pools.yml  |  2 +-
 .../workflows/build-test-macos-simulation.yml |  2 +-
 .github/workflows/build-test-macos-tools.yml  |  2 +-
 .github/workflows/build-test-macos-util.yml   |  2 +-
 .../build-test-macos-wallet-cat_wallet.yml    |  2 +-
 .../build-test-macos-wallet-did_wallet.yml    |  2 +-
 .../build-test-macos-wallet-rl_wallet.yml     |  2 +-
 .../workflows/build-test-macos-wallet-rpc.yml |  2 +-
 .../build-test-macos-wallet-simple_sync.yml   |  2 +-
 .../build-test-macos-wallet-sync.yml          |  2 +-
 .github/workflows/build-test-macos-wallet.yml |  2 +-
 .../build-test-macos-weight_proof.yml         |  2 +-
 .../build-test-ubuntu-blockchain.yml          |  2 +-
 .github/workflows/build-test-ubuntu-clvm.yml  |  2 +-
 .../workflows/build-test-ubuntu-core-cmds.yml |  2 +-
 .../build-test-ubuntu-core-consensus.yml      |  2 +-
 .../build-test-ubuntu-core-custom_types.yml   |  2 +-
 .../build-test-ubuntu-core-daemon.yml         |  2 +-
 ...d-test-ubuntu-core-full_node-full_sync.yml |  2 +-
 ...uild-test-ubuntu-core-full_node-stores.yml |  2 +-
 .../build-test-ubuntu-core-full_node.yml      |  2 +-
 .../build-test-ubuntu-core-server.yml         |  2 +-
 .../workflows/build-test-ubuntu-core-ssl.yml  |  2 +-
 .../workflows/build-test-ubuntu-core-util.yml |  2 +-
 .github/workflows/build-test-ubuntu-core.yml  |  2 +-
 .../build-test-ubuntu-farmer_harvester.yml    |  2 +-
 .../workflows/build-test-ubuntu-generator.yml |  2 +-
 .../workflows/build-test-ubuntu-plot_sync.yml |  2 +-
 .../workflows/build-test-ubuntu-plotting.yml  |  2 +-
 .github/workflows/build-test-ubuntu-pools.yml |  2 +-
 .../build-test-ubuntu-simulation.yml          |  2 +-
 .github/workflows/build-test-ubuntu-tools.yml |  2 +-
 .github/workflows/build-test-ubuntu-util.yml  |  2 +-
 .../build-test-ubuntu-wallet-cat_wallet.yml   |  2 +-
 .../build-test-ubuntu-wallet-did_wallet.yml   |  2 +-
 .../build-test-ubuntu-wallet-rl_wallet.yml    |  2 +-
 .../build-test-ubuntu-wallet-rpc.yml          |  2 +-
 .../build-test-ubuntu-wallet-simple_sync.yml  |  2 +-
 .../build-test-ubuntu-wallet-sync.yml         |  2 +-
 .../workflows/build-test-ubuntu-wallet.yml    |  2 +-
 .../build-test-ubuntu-weight_proof.yml        |  2 +-
 .../workflows/check_wheel_availability.yaml   |  2 +-
 .github/workflows/test-install-scripts.yml    | 22 +++++++------------
 Install.ps1                                   |  2 +-
 install.sh                                    | 17 +++++++++-----
 pytest.ini                                    |  2 ++
 tests/runner_templates/build-test-macos       |  2 +-
 tests/runner_templates/build-test-ubuntu      |  2 +-
 65 files changed, 84 insertions(+), 81 deletions(-)

diff --git a/.github/workflows/build-test-macos-blockchain.yml b/.github/workflows/build-test-macos-blockchain.yml
index cd92c3e12..6ef0c05cd 100644
--- a/.github/workflows/build-test-macos-blockchain.yml
+++ b/.github/workflows/build-test-macos-blockchain.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-clvm.yml b/.github/workflows/build-test-macos-clvm.yml
index 213aeaee5..8a43873a8 100644
--- a/.github/workflows/build-test-macos-clvm.yml
+++ b/.github/workflows/build-test-macos-clvm.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-cmds.yml b/.github/workflows/build-test-macos-core-cmds.yml
index ad056811e..4e324932a 100644
--- a/.github/workflows/build-test-macos-core-cmds.yml
+++ b/.github/workflows/build-test-macos-core-cmds.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-consensus.yml b/.github/workflows/build-test-macos-core-consensus.yml
index 8cded054e..4656af217 100644
--- a/.github/workflows/build-test-macos-core-consensus.yml
+++ b/.github/workflows/build-test-macos-core-consensus.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-custom_types.yml b/.github/workflows/build-test-macos-core-custom_types.yml
index f8d950e36..e787390cb 100644
--- a/.github/workflows/build-test-macos-core-custom_types.yml
+++ b/.github/workflows/build-test-macos-core-custom_types.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-daemon.yml b/.github/workflows/build-test-macos-core-daemon.yml
index 7be54a932..37e7e76ef 100644
--- a/.github/workflows/build-test-macos-core-daemon.yml
+++ b/.github/workflows/build-test-macos-core-daemon.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-full_node-full_sync.yml b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
index 552b0a4a8..b0a97654d 100644
--- a/.github/workflows/build-test-macos-core-full_node-full_sync.yml
+++ b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-full_node-stores.yml b/.github/workflows/build-test-macos-core-full_node-stores.yml
index 06f362dcb..3b7578939 100644
--- a/.github/workflows/build-test-macos-core-full_node-stores.yml
+++ b/.github/workflows/build-test-macos-core-full_node-stores.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-full_node.yml b/.github/workflows/build-test-macos-core-full_node.yml
index 9db1b8b8d..c4989869a 100644
--- a/.github/workflows/build-test-macos-core-full_node.yml
+++ b/.github/workflows/build-test-macos-core-full_node.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-server.yml b/.github/workflows/build-test-macos-core-server.yml
index f80358b7d..258142b93 100644
--- a/.github/workflows/build-test-macos-core-server.yml
+++ b/.github/workflows/build-test-macos-core-server.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-ssl.yml b/.github/workflows/build-test-macos-core-ssl.yml
index 1711e2d80..baa7738d7 100644
--- a/.github/workflows/build-test-macos-core-ssl.yml
+++ b/.github/workflows/build-test-macos-core-ssl.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core-util.yml b/.github/workflows/build-test-macos-core-util.yml
index a062fdd09..d287d994f 100644
--- a/.github/workflows/build-test-macos-core-util.yml
+++ b/.github/workflows/build-test-macos-core-util.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-core.yml b/.github/workflows/build-test-macos-core.yml
index 5734712dd..50ba6823f 100644
--- a/.github/workflows/build-test-macos-core.yml
+++ b/.github/workflows/build-test-macos-core.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-farmer_harvester.yml b/.github/workflows/build-test-macos-farmer_harvester.yml
index 9ebfb33cf..0a90a9ea0 100644
--- a/.github/workflows/build-test-macos-farmer_harvester.yml
+++ b/.github/workflows/build-test-macos-farmer_harvester.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-generator.yml b/.github/workflows/build-test-macos-generator.yml
index 3579b3423..36233d554 100644
--- a/.github/workflows/build-test-macos-generator.yml
+++ b/.github/workflows/build-test-macos-generator.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-plot_sync.yml b/.github/workflows/build-test-macos-plot_sync.yml
index 9933ce387..580674923 100644
--- a/.github/workflows/build-test-macos-plot_sync.yml
+++ b/.github/workflows/build-test-macos-plot_sync.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-plotting.yml b/.github/workflows/build-test-macos-plotting.yml
index c4567aa62..cf556233b 100644
--- a/.github/workflows/build-test-macos-plotting.yml
+++ b/.github/workflows/build-test-macos-plotting.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-pools.yml b/.github/workflows/build-test-macos-pools.yml
index f2bad167a..a09c32886 100644
--- a/.github/workflows/build-test-macos-pools.yml
+++ b/.github/workflows/build-test-macos-pools.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-simulation.yml b/.github/workflows/build-test-macos-simulation.yml
index aee486d14..fb1f23de5 100644
--- a/.github/workflows/build-test-macos-simulation.yml
+++ b/.github/workflows/build-test-macos-simulation.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-tools.yml b/.github/workflows/build-test-macos-tools.yml
index dbded6899..d0950dfcd 100644
--- a/.github/workflows/build-test-macos-tools.yml
+++ b/.github/workflows/build-test-macos-tools.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-util.yml b/.github/workflows/build-test-macos-util.yml
index 74ecf863b..6c1295933 100644
--- a/.github/workflows/build-test-macos-util.yml
+++ b/.github/workflows/build-test-macos-util.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-wallet-cat_wallet.yml b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
index 59c3a94a4..8b39fab3c 100644
--- a/.github/workflows/build-test-macos-wallet-cat_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-wallet-did_wallet.yml b/.github/workflows/build-test-macos-wallet-did_wallet.yml
index 115a025e4..2bb2c7718 100644
--- a/.github/workflows/build-test-macos-wallet-did_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-did_wallet.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-wallet-rl_wallet.yml b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
index 6a1fec488..e3884a948 100644
--- a/.github/workflows/build-test-macos-wallet-rl_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-wallet-rpc.yml b/.github/workflows/build-test-macos-wallet-rpc.yml
index 6a3acae8b..f73fa3936 100644
--- a/.github/workflows/build-test-macos-wallet-rpc.yml
+++ b/.github/workflows/build-test-macos-wallet-rpc.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-wallet-simple_sync.yml b/.github/workflows/build-test-macos-wallet-simple_sync.yml
index 0944cc2ea..1013c7921 100644
--- a/.github/workflows/build-test-macos-wallet-simple_sync.yml
+++ b/.github/workflows/build-test-macos-wallet-simple_sync.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-wallet-sync.yml b/.github/workflows/build-test-macos-wallet-sync.yml
index f828659f0..8efaab273 100644
--- a/.github/workflows/build-test-macos-wallet-sync.yml
+++ b/.github/workflows/build-test-macos-wallet-sync.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-wallet.yml b/.github/workflows/build-test-macos-wallet.yml
index 6bc89ae0b..dbaf20f65 100644
--- a/.github/workflows/build-test-macos-wallet.yml
+++ b/.github/workflows/build-test-macos-wallet.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-macos-weight_proof.yml b/.github/workflows/build-test-macos-weight_proof.yml
index cec62d95f..04d2485e1 100644
--- a/.github/workflows/build-test-macos-weight_proof.yml
+++ b/.github/workflows/build-test-macos-weight_proof.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-blockchain.yml b/.github/workflows/build-test-ubuntu-blockchain.yml
index c19918886..f9e2e0051 100644
--- a/.github/workflows/build-test-ubuntu-blockchain.yml
+++ b/.github/workflows/build-test-ubuntu-blockchain.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-clvm.yml b/.github/workflows/build-test-ubuntu-clvm.yml
index 8b8d97e0d..fdd4dcf08 100644
--- a/.github/workflows/build-test-ubuntu-clvm.yml
+++ b/.github/workflows/build-test-ubuntu-clvm.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-cmds.yml b/.github/workflows/build-test-ubuntu-core-cmds.yml
index 7edd499d9..1de478c11 100644
--- a/.github/workflows/build-test-ubuntu-core-cmds.yml
+++ b/.github/workflows/build-test-ubuntu-core-cmds.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-consensus.yml b/.github/workflows/build-test-ubuntu-core-consensus.yml
index 2f7fc109b..5f3d5a131 100644
--- a/.github/workflows/build-test-ubuntu-core-consensus.yml
+++ b/.github/workflows/build-test-ubuntu-core-consensus.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-custom_types.yml b/.github/workflows/build-test-ubuntu-core-custom_types.yml
index 559f5b982..6a3e9b374 100644
--- a/.github/workflows/build-test-ubuntu-core-custom_types.yml
+++ b/.github/workflows/build-test-ubuntu-core-custom_types.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-daemon.yml b/.github/workflows/build-test-ubuntu-core-daemon.yml
index eb0cf56ff..f4f0ac5f4 100644
--- a/.github/workflows/build-test-ubuntu-core-daemon.yml
+++ b/.github/workflows/build-test-ubuntu-core-daemon.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml b/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
index 24cdeb5c3..ec91bea67 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node-full_sync.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-full_node-stores.yml b/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
index 468870192..553fb749b 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node-stores.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-full_node.yml b/.github/workflows/build-test-ubuntu-core-full_node.yml
index 34f8f746e..00179a6c7 100644
--- a/.github/workflows/build-test-ubuntu-core-full_node.yml
+++ b/.github/workflows/build-test-ubuntu-core-full_node.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-server.yml b/.github/workflows/build-test-ubuntu-core-server.yml
index adef8eb31..370eafeec 100644
--- a/.github/workflows/build-test-ubuntu-core-server.yml
+++ b/.github/workflows/build-test-ubuntu-core-server.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-ssl.yml b/.github/workflows/build-test-ubuntu-core-ssl.yml
index 031b4d71e..2f2ccde62 100644
--- a/.github/workflows/build-test-ubuntu-core-ssl.yml
+++ b/.github/workflows/build-test-ubuntu-core-ssl.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core-util.yml b/.github/workflows/build-test-ubuntu-core-util.yml
index 41ae35a25..c3ebb1e9f 100644
--- a/.github/workflows/build-test-ubuntu-core-util.yml
+++ b/.github/workflows/build-test-ubuntu-core-util.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-core.yml b/.github/workflows/build-test-ubuntu-core.yml
index 216984f64..4744ad6aa 100644
--- a/.github/workflows/build-test-ubuntu-core.yml
+++ b/.github/workflows/build-test-ubuntu-core.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-farmer_harvester.yml b/.github/workflows/build-test-ubuntu-farmer_harvester.yml
index 0e4cdbc82..e7feb26cc 100644
--- a/.github/workflows/build-test-ubuntu-farmer_harvester.yml
+++ b/.github/workflows/build-test-ubuntu-farmer_harvester.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-generator.yml b/.github/workflows/build-test-ubuntu-generator.yml
index e3dc6aaa9..bcbf1e377 100644
--- a/.github/workflows/build-test-ubuntu-generator.yml
+++ b/.github/workflows/build-test-ubuntu-generator.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-plot_sync.yml b/.github/workflows/build-test-ubuntu-plot_sync.yml
index 26f8be548..d345ddcb5 100644
--- a/.github/workflows/build-test-ubuntu-plot_sync.yml
+++ b/.github/workflows/build-test-ubuntu-plot_sync.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-plotting.yml b/.github/workflows/build-test-ubuntu-plotting.yml
index 4d4d4ef4f..ffec6d840 100644
--- a/.github/workflows/build-test-ubuntu-plotting.yml
+++ b/.github/workflows/build-test-ubuntu-plotting.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-pools.yml b/.github/workflows/build-test-ubuntu-pools.yml
index 69b8d42fb..92405b59a 100644
--- a/.github/workflows/build-test-ubuntu-pools.yml
+++ b/.github/workflows/build-test-ubuntu-pools.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-simulation.yml b/.github/workflows/build-test-ubuntu-simulation.yml
index be3dfca01..0afe15af6 100644
--- a/.github/workflows/build-test-ubuntu-simulation.yml
+++ b/.github/workflows/build-test-ubuntu-simulation.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-tools.yml b/.github/workflows/build-test-ubuntu-tools.yml
index 4ed939841..5baf8cf0b 100644
--- a/.github/workflows/build-test-ubuntu-tools.yml
+++ b/.github/workflows/build-test-ubuntu-tools.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-util.yml b/.github/workflows/build-test-ubuntu-util.yml
index b973a8f52..6ac03033d 100644
--- a/.github/workflows/build-test-ubuntu-util.yml
+++ b/.github/workflows/build-test-ubuntu-util.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
index d7bfb2dc8..11471fb40 100644
--- a/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-cat_wallet.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
index bd47b8609..50fa41255 100644
--- a/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-did_wallet.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml b/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
index 5444f3bda..5a87100fa 100644
--- a/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-rl_wallet.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-wallet-rpc.yml b/.github/workflows/build-test-ubuntu-wallet-rpc.yml
index ee196ca3f..2b1564487 100644
--- a/.github/workflows/build-test-ubuntu-wallet-rpc.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-rpc.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml b/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
index 0ec30ae4a..43aa3d9ea 100644
--- a/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-simple_sync.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-wallet-sync.yml b/.github/workflows/build-test-ubuntu-wallet-sync.yml
index eeecfe12a..693243eed 100644
--- a/.github/workflows/build-test-ubuntu-wallet-sync.yml
+++ b/.github/workflows/build-test-ubuntu-wallet-sync.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-wallet.yml b/.github/workflows/build-test-ubuntu-wallet.yml
index 35fe07923..b0715af35 100644
--- a/.github/workflows/build-test-ubuntu-wallet.yml
+++ b/.github/workflows/build-test-ubuntu-wallet.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/build-test-ubuntu-weight_proof.yml b/.github/workflows/build-test-ubuntu-weight_proof.yml
index 4e52234bd..fd2979b00 100644
--- a/.github/workflows/build-test-ubuntu-weight_proof.yml
+++ b/.github/workflows/build-test-ubuntu-weight_proof.yml
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/.github/workflows/check_wheel_availability.yaml b/.github/workflows/check_wheel_availability.yaml
index 4563629cf..7aea5be5e 100644
--- a/.github/workflows/check_wheel_availability.yaml
+++ b/.github/workflows/check_wheel_availability.yaml
@@ -38,7 +38,7 @@ jobs:
             matrix: arm
           - name: Intel
             matrix: intel
-        python-version: ['3.7', '3.8', '3.9']
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         exclude:
           - os:
               matrix: macos
diff --git a/.github/workflows/test-install-scripts.yml b/.github/workflows/test-install-scripts.yml
index 6ad2cfc38..021409c6a 100644
--- a/.github/workflows/test-install-scripts.yml
+++ b/.github/workflows/test-install-scripts.yml
@@ -90,10 +90,10 @@ jobs:
           type: fedora
           # (34, 3.9) https://packages.fedoraproject.org/search?query=python3&releases=Fedora+34&start=0
           url: "docker://fedora:34"
-#        - name: fedora:35
-#          type: fedora
-#          # (35, 3.10) https://packages.fedoraproject.org/search?query=python3&releases=Fedora+35&start=0
-#          url: "docker://fedora:35"
+        - name: fedora:35
+          type: fedora
+          # (35, 3.10) https://packages.fedoraproject.org/search?query=python3&releases=Fedora+35&start=0
+          url: "docker://fedora:35"
         - name: rockylinux:8
           type: rocky
           url: "docker://rockylinux:8"
@@ -113,6 +113,10 @@ jobs:
           type: ubuntu
           # https://packages.ubuntu.com/impish/python3 (21.10, 3.9)
           url: "docker://ubuntu:impish"
+        - name: ubuntu:jammy (22.04)
+          type: ubuntu
+          # https://packages.ubuntu.com/jammy/python3 (22.04, 3.10)
+          url: "docker://ubuntu:jammy"
         - name: linuxmintd/mint19.1-amd64 (Tessa)
           type: mint
           # 3.6 default with an option for 3.7
@@ -191,16 +195,6 @@ jobs:
         apt-get --yes update
         apt-get install --yes git lsb-release sudo
 
-    # @TODO this step can be removed once Python 3.10 is supported
-    # Python 3.10 is now the default in bookworm, so install 3.9 specifically so install does not fail
-    - name: Prepare debian:bookworm
-      if: ${{ matrix.distribution.name == 'debian:bookworm' }}
-      env:
-        DEBIAN_FRONTEND: noninteractive
-      run: |
-        apt-get update -y
-        apt-get install -y python3.9-venv
-
     - name: Prepare Fedora
       if: ${{ matrix.distribution.type == 'fedora' }}
       run: |
diff --git a/Install.ps1 b/Install.ps1
index 8350d2082..89acb6928 100644
--- a/Install.ps1
+++ b/Install.ps1
@@ -43,7 +43,7 @@ if ($null -eq (Get-Command py -ErrorAction SilentlyContinue))
     Exit 1
 }
 
-$supportedPythonVersions = "3.9", "3.8", "3.7"
+$supportedPythonVersions = "3.10", "3.9", "3.8", "3.7"
 if (Test-Path env:INSTALL_PYTHON_VERSION)
 {
     $pythonVersion = $env:INSTALL_PYTHON_VERSION
diff --git a/install.sh b/install.sh
index 8e2b97131..ced5ad92c 100755
--- a/install.sh
+++ b/install.sh
@@ -59,6 +59,7 @@ git submodule update --init mozilla-ca
 UBUNTU_PRE_2004=0
 UBUNTU_2000=0
 UBUNTU_2100=0
+UBUNTU_2200=0
 
 if $UBUNTU; then
   LSB_RELEASE=$(lsb_release -rs)
@@ -71,8 +72,10 @@ if $UBUNTU; then
     UBUNTU_PRE_2004=1
   elif [ "$(echo "$LSB_RELEASE<21" | bc)" = "1" ]; then
     UBUNTU_2000=1
-  else
+  elif [ "$(echo "$LSB_RELEASE<22" | bc)" = "1" ]; then
     UBUNTU_2100=1
+  else
+    UBUNTU_2200=1
   fi
 fi
 
@@ -132,9 +135,13 @@ if [ "$(uname)" = "Linux" ]; then
     sudo apt-get update
     sudo apt-get install -y python3.8-venv python3-distutils openssl
   elif [ "$UBUNTU_2100" = "1" ]; then
-    echo "Installing on Ubuntu 21.04 or newer."
+    echo "Installing on Ubuntu 21.04."
     sudo apt-get update
     sudo apt-get install -y python3.9-venv python3-distutils openssl
+  elif [ "$UBUNTU_2200" = "1" ]; then
+    echo "Installing on Ubuntu 22.04 LTS or newer."
+    sudo apt-get update
+    sudo apt-get install -y python3.10-venv python3-distutils openssl
   elif [ "$DEBIAN" = "true" ]; then
     echo "Installing on Debian."
     sudo apt-get update
@@ -194,14 +201,14 @@ fi
 find_python() {
   set +e
   unset BEST_VERSION
-  for V in 39 3.9 38 3.8 37 3.7 3; do
+  for V in 310 3.10 39 3.9 38 3.8 37 3.7 3; do
     if command -v python$V >/dev/null; then
       if [ "$BEST_VERSION" = "" ]; then
         BEST_VERSION=$V
         if [ "$BEST_VERSION" = "3" ]; then
           PY3_VERSION=$(python$BEST_VERSION --version | cut -d ' ' -f2)
-          if [[ "$PY3_VERSION" =~ 3.10.* ]]; then
-            echo "Chia requires Python version <= 3.9.10"
+          if [[ "$PY3_VERSION" =~ 3.11.* ]]; then
+            echo "Chia requires Python version < 3.11.0"
             echo "Current Python version = $PY3_VERSION"
             # If Arch, direct to Arch Wiki
             if type pacman >/dev/null 2>&1 && [ -f "/etc/arch-release" ]; then
diff --git a/pytest.ini b/pytest.ini
index 953e5cbf4..628c1af61 100644
--- a/pytest.ini
+++ b/pytest.ini
@@ -21,3 +21,5 @@ filterwarnings =
     ignore:Exception ignored in:pytest.PytestUnraisableExceptionWarning
     ignore:cannot collect test class:pytest.PytestCollectionWarning
     ignore:The loop argument is deprecated since Python 3\.8, and scheduled for removal in Python 3\.10.:DeprecationWarning
+    ignore:The distutils package is deprecated:DeprecationWarning
+    ignore:There is no current event loop:DeprecationWarning
diff --git a/tests/runner_templates/build-test-macos b/tests/runner_templates/build-test-macos
index 25417a8d9..50b3de295 100644
--- a/tests/runner_templates/build-test-macos
+++ b/tests/runner_templates/build-test-macos
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.8, 3.9]
+        python-version: ['3.9', '3.10']
         os: [macOS-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
diff --git a/tests/runner_templates/build-test-ubuntu b/tests/runner_templates/build-test-ubuntu
index dae0a828a..cbba677e1 100644
--- a/tests/runner_templates/build-test-ubuntu
+++ b/tests/runner_templates/build-test-ubuntu
@@ -27,7 +27,7 @@ jobs:
       fail-fast: false
       max-parallel: 4
       matrix:
-        python-version: [3.7, 3.8, 3.9]
+        python-version: ['3.7', '3.8', '3.9', '3.10']
         os: [ubuntu-latest]
     env:
       CHIA_ROOT: ${{ github.workspace }}/.chia/mainnet
-- 
2.34.1


From 3abcbf1dfa6cfcd5f9f5b47285e8bd5afe35f839 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Tue, 26 Apr 2022 16:18:16 -0500
Subject: [PATCH 65/77] Build installers on push to release branches (#11321)

---
 .github/workflows/build-linux-arm64-installer.yml | 1 +
 .github/workflows/build-linux-installer-deb.yml   | 1 +
 .github/workflows/build-linux-installer-rpm.yml   | 1 +
 .github/workflows/build-macos-installer.yml       | 1 +
 .github/workflows/build-macos-m1-installer.yml    | 1 +
 .github/workflows/build-windows-installer.yml     | 1 +
 6 files changed, 6 insertions(+)

diff --git a/.github/workflows/build-linux-arm64-installer.yml b/.github/workflows/build-linux-arm64-installer.yml
index 418cebd28..cc27b1877 100644
--- a/.github/workflows/build-linux-arm64-installer.yml
+++ b/.github/workflows/build-linux-arm64-installer.yml
@@ -4,6 +4,7 @@ on:
   push:
     branches:
       - main
+      - 'release/**'
     tags:
         - '**'
   pull_request:
diff --git a/.github/workflows/build-linux-installer-deb.yml b/.github/workflows/build-linux-installer-deb.yml
index 3147ffc05..6aa183cdd 100644
--- a/.github/workflows/build-linux-installer-deb.yml
+++ b/.github/workflows/build-linux-installer-deb.yml
@@ -5,6 +5,7 @@ on:
   push:
     branches:
       - main
+      - 'release/**'
     tags:
         - '**'
   pull_request:
diff --git a/.github/workflows/build-linux-installer-rpm.yml b/.github/workflows/build-linux-installer-rpm.yml
index 38f6d5486..2f0e37b45 100644
--- a/.github/workflows/build-linux-installer-rpm.yml
+++ b/.github/workflows/build-linux-installer-rpm.yml
@@ -5,6 +5,7 @@ on:
   push:
     branches:
       - main
+      - 'release/**'
     tags:
         - '**'
   pull_request:
diff --git a/.github/workflows/build-macos-installer.yml b/.github/workflows/build-macos-installer.yml
index 6748cc037..98855f7f7 100644
--- a/.github/workflows/build-macos-installer.yml
+++ b/.github/workflows/build-macos-installer.yml
@@ -4,6 +4,7 @@ on:
   push:
     branches:
       - main
+      - 'release/**'
     tags:
         - '**'
   pull_request:
diff --git a/.github/workflows/build-macos-m1-installer.yml b/.github/workflows/build-macos-m1-installer.yml
index d234c1514..faa29793d 100644
--- a/.github/workflows/build-macos-m1-installer.yml
+++ b/.github/workflows/build-macos-m1-installer.yml
@@ -4,6 +4,7 @@ on:
   push:
     branches:
       - main
+      - 'release/**'
     tags:
       - '**'
   pull_request:
diff --git a/.github/workflows/build-windows-installer.yml b/.github/workflows/build-windows-installer.yml
index 15fa47090..5ce9ad16a 100644
--- a/.github/workflows/build-windows-installer.yml
+++ b/.github/workflows/build-windows-installer.yml
@@ -4,6 +4,7 @@ on:
   push:
     branches:
       - main
+      - 'release/**'
     tags:
         - '**'
   pull_request:
-- 
2.34.1


From 6268722992819a2aea574d4e6b557e1ce6c6347f Mon Sep 17 00:00:00 2001
From: William Blanke <wjb98672@gmail.com>
Date: Wed, 27 Apr 2022 11:18:40 -0700
Subject: [PATCH 66/77] updated gui to 4fc7fe11cc668277aa0d4c68e1f8a48765db9241

---
 chia-blockchain-gui | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/chia-blockchain-gui b/chia-blockchain-gui
index 042e2af1a..4fc7fe11c 160000
--- a/chia-blockchain-gui
+++ b/chia-blockchain-gui
@@ -1 +1 @@
-Subproject commit 042e2af1a4f0333939286328d0b59d592e605daf
+Subproject commit 4fc7fe11cc668277aa0d4c68e1f8a48765db9241
-- 
2.34.1


From 28d9dbfd3a5fc87a882bb7332347131af53be87c Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 27 Apr 2022 11:37:21 -0700
Subject: [PATCH 67/77] More general Ubuntu references in install.sh (#11325)

* More general Ubuntu references in install.sh

* oops
---
 install.sh | 32 ++++++++++++++++----------------
 1 file changed, 16 insertions(+), 16 deletions(-)

diff --git a/install.sh b/install.sh
index ced5ad92c..bed90d26b 100755
--- a/install.sh
+++ b/install.sh
@@ -56,10 +56,10 @@ fi
 # Get submodules
 git submodule update --init mozilla-ca
 
-UBUNTU_PRE_2004=0
-UBUNTU_2000=0
-UBUNTU_2100=0
-UBUNTU_2200=0
+UBUNTU_PRE_20=0
+UBUNTU_20=0
+UBUNTU_21=0
+UBUNTU_22=0
 
 if $UBUNTU; then
   LSB_RELEASE=$(lsb_release -rs)
@@ -69,13 +69,13 @@ if $UBUNTU; then
   fi
   # Mint 20.04 responds with 20 here so 20 instead of 20.04
   if [ "$(echo "$LSB_RELEASE<20" | bc)" = "1" ]; then
-    UBUNTU_PRE_2004=1
+    UBUNTU_PRE_20=1
   elif [ "$(echo "$LSB_RELEASE<21" | bc)" = "1" ]; then
-    UBUNTU_2000=1
+    UBUNTU_20=1
   elif [ "$(echo "$LSB_RELEASE<22" | bc)" = "1" ]; then
-    UBUNTU_2100=1
+    UBUNTU_21=1
   else
-    UBUNTU_2200=1
+    UBUNTU_22=1
   fi
 fi
 
@@ -125,21 +125,21 @@ install_python3_and_sqlite3_from_source_with_yum() {
 # Manage npm and other install requirements on an OS specific basis
 if [ "$(uname)" = "Linux" ]; then
   #LINUX=1
-  if [ "$UBUNTU_PRE_2004" = "1" ]; then
+  if [ "$UBUNTU_PRE_20" = "1" ]; then
     # Ubuntu
-    echo "Installing on Ubuntu pre 20.04 LTS."
+    echo "Installing on Ubuntu pre 20.*."
     sudo apt-get update
     sudo apt-get install -y python3.7-venv python3.7-distutils openssl
-  elif [ "$UBUNTU_2000" = "1" ]; then
-    echo "Installing on Ubuntu 20.04 LTS."
+  elif [ "$UBUNTU_20" = "1" ]; then
+    echo "Installing on Ubuntu 20.*."
     sudo apt-get update
     sudo apt-get install -y python3.8-venv python3-distutils openssl
-  elif [ "$UBUNTU_2100" = "1" ]; then
-    echo "Installing on Ubuntu 21.04."
+  elif [ "$UBUNTU_21" = "1" ]; then
+    echo "Installing on Ubuntu 21.*."
     sudo apt-get update
     sudo apt-get install -y python3.9-venv python3-distutils openssl
-  elif [ "$UBUNTU_2200" = "1" ]; then
-    echo "Installing on Ubuntu 22.04 LTS or newer."
+  elif [ "$UBUNTU_22" = "1" ]; then
+    echo "Installing on Ubuntu 22.* or newer."
     sudo apt-get update
     sudo apt-get install -y python3.10-venv python3-distutils openssl
   elif [ "$DEBIAN" = "true" ]; then
-- 
2.34.1


From 7630d220f51e7d5034689974b89e54c951b2370b Mon Sep 17 00:00:00 2001
From: Mariano Sorgente <3069354+mariano54@users.noreply.github.com>
Date: Wed, 27 Apr 2022 14:38:48 -0400
Subject: [PATCH 68/77] Optimize BLS verification when public key is repeated
 (#11318)

* Optimize BLS verification when public key is repeated

* Fix accidental commit

* Lint

* Fix isort

* Address comments
---
 chia/util/cached_bls.py            | 12 ++++-
 tests/core/util/test_cached_bls.py | 84 +++++++++++++++++-------------
 2 files changed, 59 insertions(+), 37 deletions(-)

diff --git a/chia/util/cached_bls.py b/chia/util/cached_bls.py
index ef6fffa0f..15621b741 100644
--- a/chia/util/cached_bls.py
+++ b/chia/util/cached_bls.py
@@ -1,5 +1,5 @@
 import functools
-from typing import List, Optional, Sequence
+from typing import Dict, List, Optional, Sequence
 
 from blspy import AugSchemeMPL, G1Element, G2Element, GTElement
 
@@ -24,11 +24,19 @@ def get_pairings(cache: LRUCache, pks: List[bytes48], msgs: Sequence[bytes], for
                 return []
         pairings.append(pairing)
 
+    # G1Element.from_bytes can be expensive due to subgroup check, so we avoid recomputing it with this cache
+    pk_bytes_to_g1: Dict[bytes48, G1Element] = {}
     for i, pairing in enumerate(pairings):
         if pairing is None:
             aug_msg = pks[i] + msgs[i]
             aug_hash: G2Element = AugSchemeMPL.g2_from_message(aug_msg)
-            pairing = G1Element.from_bytes(pks[i]).pair(aug_hash)
+
+            pk_parsed: Optional[G1Element] = pk_bytes_to_g1.get(pks[i])
+            if pk_parsed is None:
+                pk_parsed = G1Element.from_bytes(pks[i])
+                pk_bytes_to_g1[pks[i]] = pk_parsed
+
+            pairing = pk_parsed.pair(aug_hash)
 
             h = bytes(std_hash(aug_msg))
             cache.put(h, pairing)
diff --git a/tests/core/util/test_cached_bls.py b/tests/core/util/test_cached_bls.py
index eca0f9a1f..f85a665f9 100644
--- a/tests/core/util/test_cached_bls.py
+++ b/tests/core/util/test_cached_bls.py
@@ -1,40 +1,54 @@
-import unittest
 from blspy import AugSchemeMPL, G1Element
 from chia.util import cached_bls
+from chia.util.hash import std_hash
 from chia.util.lru_cache import LRUCache
 
 
-class TestCachedBLS(unittest.TestCase):
-    def test_cached_bls(self):
-        n_keys = 10
-        seed = b"a" * 31
-        sks = [AugSchemeMPL.key_gen(seed + bytes([i])) for i in range(n_keys)]
-        pks = [bytes(sk.get_g1()) for sk in sks]
-
-        msgs = [("msg-%d" % (i,)).encode() for i in range(n_keys)]
-        sigs = [AugSchemeMPL.sign(sk, msg) for sk, msg in zip(sks, msgs)]
-        agg_sig = AugSchemeMPL.aggregate(sigs)
-
-        pks_half = pks[: n_keys // 2]
-        msgs_half = msgs[: n_keys // 2]
-        sigs_half = sigs[: n_keys // 2]
-        agg_sig_half = AugSchemeMPL.aggregate(sigs_half)
-
-        assert AugSchemeMPL.aggregate_verify([G1Element.from_bytes(pk) for pk in pks], msgs, agg_sig)
-
-        # Verify with empty cache and populate it
-        assert cached_bls.aggregate_verify(pks_half, msgs_half, agg_sig_half, True)
-        # Verify with partial cache hit
-        assert cached_bls.aggregate_verify(pks, msgs, agg_sig, True)
-        # Verify with full cache hit
-        assert cached_bls.aggregate_verify(pks, msgs, agg_sig)
-
-        # Use a small cache which can not accommodate all pairings
-        local_cache = LRUCache(n_keys // 2)
-        # Verify signatures and cache pairings one at a time
-        for pk, msg, sig in zip(pks_half, msgs_half, sigs_half):
-            assert cached_bls.aggregate_verify([pk], [msg], sig, True, local_cache)
-        # Verify the same messages with aggregated signature (full cache hit)
-        assert cached_bls.aggregate_verify(pks_half, msgs_half, agg_sig_half, False, local_cache)
-        # Verify more messages (partial cache hit)
-        assert cached_bls.aggregate_verify(pks, msgs, agg_sig, False, local_cache)
+def test_cached_bls():
+    n_keys = 10
+    seed = b"a" * 31
+    sks = [AugSchemeMPL.key_gen(seed + bytes([i])) for i in range(n_keys)]
+    pks = [bytes(sk.get_g1()) for sk in sks]
+
+    msgs = [("msg-%d" % (i,)).encode() for i in range(n_keys)]
+    sigs = [AugSchemeMPL.sign(sk, msg) for sk, msg in zip(sks, msgs)]
+    agg_sig = AugSchemeMPL.aggregate(sigs)
+
+    pks_half = pks[: n_keys // 2]
+    msgs_half = msgs[: n_keys // 2]
+    sigs_half = sigs[: n_keys // 2]
+    agg_sig_half = AugSchemeMPL.aggregate(sigs_half)
+
+    assert AugSchemeMPL.aggregate_verify([G1Element.from_bytes(pk) for pk in pks], msgs, agg_sig)
+
+    # Verify with empty cache and populate it
+    assert cached_bls.aggregate_verify(pks_half, msgs_half, agg_sig_half, True)
+    # Verify with partial cache hit
+    assert cached_bls.aggregate_verify(pks, msgs, agg_sig, True)
+    # Verify with full cache hit
+    assert cached_bls.aggregate_verify(pks, msgs, agg_sig)
+
+    # Use a small cache which can not accommodate all pairings
+    local_cache = LRUCache(n_keys // 2)
+    # Verify signatures and cache pairings one at a time
+    for pk, msg, sig in zip(pks_half, msgs_half, sigs_half):
+        assert cached_bls.aggregate_verify([pk], [msg], sig, True, local_cache)
+    # Verify the same messages with aggregated signature (full cache hit)
+    assert cached_bls.aggregate_verify(pks_half, msgs_half, agg_sig_half, False, local_cache)
+    # Verify more messages (partial cache hit)
+    assert cached_bls.aggregate_verify(pks, msgs, agg_sig, False, local_cache)
+
+
+def test_cached_bls_repeat_pk():
+    n_keys = 400
+    seed = b"a" * 32
+    sks = [AugSchemeMPL.key_gen(seed) for i in range(n_keys)] + [AugSchemeMPL.key_gen(std_hash(seed))]
+    pks = [bytes(sk.get_g1()) for sk in sks]
+
+    msgs = [("msg-%d" % (i,)).encode() for i in range(n_keys + 1)]
+    sigs = [AugSchemeMPL.sign(sk, msg) for sk, msg in zip(sks, msgs)]
+    agg_sig = AugSchemeMPL.aggregate(sigs)
+
+    assert AugSchemeMPL.aggregate_verify([G1Element.from_bytes(pk) for pk in pks], msgs, agg_sig)
+
+    assert cached_bls.aggregate_verify(pks, msgs, agg_sig, force_cache=True)
-- 
2.34.1


From a813e5906cb69b0b645c566bcb8d3e4489a92079 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 27 Apr 2022 11:40:31 -0700
Subject: [PATCH 69/77] Match plurality between macOS and Ubuntu test job names
 (#11317)

* Match plurality between macOS and Ubuntu test job names

With this, searching for `test /` will match both groups of jobs.

* rebuild workflows
---
 .github/workflows/build-test-macos-blockchain.yml               | 2 +-
 .github/workflows/build-test-macos-clvm.yml                     | 2 +-
 .github/workflows/build-test-macos-core-cmds.yml                | 2 +-
 .github/workflows/build-test-macos-core-consensus.yml           | 2 +-
 .github/workflows/build-test-macos-core-custom_types.yml        | 2 +-
 .github/workflows/build-test-macos-core-daemon.yml              | 2 +-
 .github/workflows/build-test-macos-core-full_node-full_sync.yml | 2 +-
 .github/workflows/build-test-macos-core-full_node-stores.yml    | 2 +-
 .github/workflows/build-test-macos-core-full_node.yml           | 2 +-
 .github/workflows/build-test-macos-core-server.yml              | 2 +-
 .github/workflows/build-test-macos-core-ssl.yml                 | 2 +-
 .github/workflows/build-test-macos-core-util.yml                | 2 +-
 .github/workflows/build-test-macos-core.yml                     | 2 +-
 .github/workflows/build-test-macos-farmer_harvester.yml         | 2 +-
 .github/workflows/build-test-macos-generator.yml                | 2 +-
 .github/workflows/build-test-macos-plot_sync.yml                | 2 +-
 .github/workflows/build-test-macos-plotting.yml                 | 2 +-
 .github/workflows/build-test-macos-pools.yml                    | 2 +-
 .github/workflows/build-test-macos-simulation.yml               | 2 +-
 .github/workflows/build-test-macos-tools.yml                    | 2 +-
 .github/workflows/build-test-macos-util.yml                     | 2 +-
 .github/workflows/build-test-macos-wallet-cat_wallet.yml        | 2 +-
 .github/workflows/build-test-macos-wallet-did_wallet.yml        | 2 +-
 .github/workflows/build-test-macos-wallet-rl_wallet.yml         | 2 +-
 .github/workflows/build-test-macos-wallet-rpc.yml               | 2 +-
 .github/workflows/build-test-macos-wallet-simple_sync.yml       | 2 +-
 .github/workflows/build-test-macos-wallet-sync.yml              | 2 +-
 .github/workflows/build-test-macos-wallet.yml                   | 2 +-
 .github/workflows/build-test-macos-weight_proof.yml             | 2 +-
 tests/runner_templates/build-test-macos                         | 2 +-
 30 files changed, 30 insertions(+), 30 deletions(-)

diff --git a/.github/workflows/build-test-macos-blockchain.yml b/.github/workflows/build-test-macos-blockchain.yml
index 6ef0c05cd..aa134b9a9 100644
--- a/.github/workflows/build-test-macos-blockchain.yml
+++ b/.github/workflows/build-test-macos-blockchain.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS blockchain Tests
+name: MacOS blockchain Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-clvm.yml b/.github/workflows/build-test-macos-clvm.yml
index 8a43873a8..be3bb4c4a 100644
--- a/.github/workflows/build-test-macos-clvm.yml
+++ b/.github/workflows/build-test-macos-clvm.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS clvm Tests
+name: MacOS clvm Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-cmds.yml b/.github/workflows/build-test-macos-core-cmds.yml
index 4e324932a..4c5aa735f 100644
--- a/.github/workflows/build-test-macos-core-cmds.yml
+++ b/.github/workflows/build-test-macos-core-cmds.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-cmds Tests
+name: MacOS core-cmds Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-consensus.yml b/.github/workflows/build-test-macos-core-consensus.yml
index 4656af217..ddeec9147 100644
--- a/.github/workflows/build-test-macos-core-consensus.yml
+++ b/.github/workflows/build-test-macos-core-consensus.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-consensus Tests
+name: MacOS core-consensus Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-custom_types.yml b/.github/workflows/build-test-macos-core-custom_types.yml
index e787390cb..551d58e77 100644
--- a/.github/workflows/build-test-macos-core-custom_types.yml
+++ b/.github/workflows/build-test-macos-core-custom_types.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-custom_types Tests
+name: MacOS core-custom_types Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-daemon.yml b/.github/workflows/build-test-macos-core-daemon.yml
index 37e7e76ef..0d387fbf0 100644
--- a/.github/workflows/build-test-macos-core-daemon.yml
+++ b/.github/workflows/build-test-macos-core-daemon.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-daemon Tests
+name: MacOS core-daemon Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-full_node-full_sync.yml b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
index b0a97654d..66769a378 100644
--- a/.github/workflows/build-test-macos-core-full_node-full_sync.yml
+++ b/.github/workflows/build-test-macos-core-full_node-full_sync.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-full_node-full_sync Tests
+name: MacOS core-full_node-full_sync Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-full_node-stores.yml b/.github/workflows/build-test-macos-core-full_node-stores.yml
index 3b7578939..33e2e2241 100644
--- a/.github/workflows/build-test-macos-core-full_node-stores.yml
+++ b/.github/workflows/build-test-macos-core-full_node-stores.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-full_node-stores Tests
+name: MacOS core-full_node-stores Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-full_node.yml b/.github/workflows/build-test-macos-core-full_node.yml
index c4989869a..b229b0c51 100644
--- a/.github/workflows/build-test-macos-core-full_node.yml
+++ b/.github/workflows/build-test-macos-core-full_node.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-full_node Tests
+name: MacOS core-full_node Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-server.yml b/.github/workflows/build-test-macos-core-server.yml
index 258142b93..568838f39 100644
--- a/.github/workflows/build-test-macos-core-server.yml
+++ b/.github/workflows/build-test-macos-core-server.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-server Tests
+name: MacOS core-server Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-ssl.yml b/.github/workflows/build-test-macos-core-ssl.yml
index baa7738d7..c3bec08f3 100644
--- a/.github/workflows/build-test-macos-core-ssl.yml
+++ b/.github/workflows/build-test-macos-core-ssl.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-ssl Tests
+name: MacOS core-ssl Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core-util.yml b/.github/workflows/build-test-macos-core-util.yml
index d287d994f..602c2b452 100644
--- a/.github/workflows/build-test-macos-core-util.yml
+++ b/.github/workflows/build-test-macos-core-util.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core-util Tests
+name: MacOS core-util Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-core.yml b/.github/workflows/build-test-macos-core.yml
index 50ba6823f..182fea18f 100644
--- a/.github/workflows/build-test-macos-core.yml
+++ b/.github/workflows/build-test-macos-core.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS core Tests
+name: MacOS core Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-farmer_harvester.yml b/.github/workflows/build-test-macos-farmer_harvester.yml
index 0a90a9ea0..5015a4437 100644
--- a/.github/workflows/build-test-macos-farmer_harvester.yml
+++ b/.github/workflows/build-test-macos-farmer_harvester.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS farmer_harvester Tests
+name: MacOS farmer_harvester Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-generator.yml b/.github/workflows/build-test-macos-generator.yml
index 36233d554..d5cffdae5 100644
--- a/.github/workflows/build-test-macos-generator.yml
+++ b/.github/workflows/build-test-macos-generator.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS generator Tests
+name: MacOS generator Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-plot_sync.yml b/.github/workflows/build-test-macos-plot_sync.yml
index 580674923..4866045b5 100644
--- a/.github/workflows/build-test-macos-plot_sync.yml
+++ b/.github/workflows/build-test-macos-plot_sync.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS plot_sync Tests
+name: MacOS plot_sync Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-plotting.yml b/.github/workflows/build-test-macos-plotting.yml
index cf556233b..bcd8a20d4 100644
--- a/.github/workflows/build-test-macos-plotting.yml
+++ b/.github/workflows/build-test-macos-plotting.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS plotting Tests
+name: MacOS plotting Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-pools.yml b/.github/workflows/build-test-macos-pools.yml
index a09c32886..3c5c4144c 100644
--- a/.github/workflows/build-test-macos-pools.yml
+++ b/.github/workflows/build-test-macos-pools.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS pools Tests
+name: MacOS pools Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-simulation.yml b/.github/workflows/build-test-macos-simulation.yml
index fb1f23de5..e23a38870 100644
--- a/.github/workflows/build-test-macos-simulation.yml
+++ b/.github/workflows/build-test-macos-simulation.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS simulation Tests
+name: MacOS simulation Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-tools.yml b/.github/workflows/build-test-macos-tools.yml
index d0950dfcd..c7cfa7670 100644
--- a/.github/workflows/build-test-macos-tools.yml
+++ b/.github/workflows/build-test-macos-tools.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS tools Tests
+name: MacOS tools Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-util.yml b/.github/workflows/build-test-macos-util.yml
index 6c1295933..537b277e3 100644
--- a/.github/workflows/build-test-macos-util.yml
+++ b/.github/workflows/build-test-macos-util.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS util Tests
+name: MacOS util Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-wallet-cat_wallet.yml b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
index 8b39fab3c..1cb2e8a1e 100644
--- a/.github/workflows/build-test-macos-wallet-cat_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-cat_wallet.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS wallet-cat_wallet Tests
+name: MacOS wallet-cat_wallet Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-wallet-did_wallet.yml b/.github/workflows/build-test-macos-wallet-did_wallet.yml
index 2bb2c7718..127edfe27 100644
--- a/.github/workflows/build-test-macos-wallet-did_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-did_wallet.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS wallet-did_wallet Tests
+name: MacOS wallet-did_wallet Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-wallet-rl_wallet.yml b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
index e3884a948..6eecba2fa 100644
--- a/.github/workflows/build-test-macos-wallet-rl_wallet.yml
+++ b/.github/workflows/build-test-macos-wallet-rl_wallet.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS wallet-rl_wallet Tests
+name: MacOS wallet-rl_wallet Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-wallet-rpc.yml b/.github/workflows/build-test-macos-wallet-rpc.yml
index f73fa3936..09a162e38 100644
--- a/.github/workflows/build-test-macos-wallet-rpc.yml
+++ b/.github/workflows/build-test-macos-wallet-rpc.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS wallet-rpc Tests
+name: MacOS wallet-rpc Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-wallet-simple_sync.yml b/.github/workflows/build-test-macos-wallet-simple_sync.yml
index 1013c7921..35a8d489a 100644
--- a/.github/workflows/build-test-macos-wallet-simple_sync.yml
+++ b/.github/workflows/build-test-macos-wallet-simple_sync.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS wallet-simple_sync Tests
+name: MacOS wallet-simple_sync Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-wallet-sync.yml b/.github/workflows/build-test-macos-wallet-sync.yml
index 8efaab273..6afc76768 100644
--- a/.github/workflows/build-test-macos-wallet-sync.yml
+++ b/.github/workflows/build-test-macos-wallet-sync.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS wallet-sync Tests
+name: MacOS wallet-sync Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-wallet.yml b/.github/workflows/build-test-macos-wallet.yml
index dbaf20f65..b661ce220 100644
--- a/.github/workflows/build-test-macos-wallet.yml
+++ b/.github/workflows/build-test-macos-wallet.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS wallet Tests
+name: MacOS wallet Test
 
 on:
   push:
diff --git a/.github/workflows/build-test-macos-weight_proof.yml b/.github/workflows/build-test-macos-weight_proof.yml
index 04d2485e1..3b377706b 100644
--- a/.github/workflows/build-test-macos-weight_proof.yml
+++ b/.github/workflows/build-test-macos-weight_proof.yml
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS weight_proof Tests
+name: MacOS weight_proof Test
 
 on:
   push:
diff --git a/tests/runner_templates/build-test-macos b/tests/runner_templates/build-test-macos
index 50b3de295..369dbc074 100644
--- a/tests/runner_templates/build-test-macos
+++ b/tests/runner_templates/build-test-macos
@@ -1,7 +1,7 @@
 #
 # THIS FILE IS GENERATED. SEE https://github.com/Chia-Network/chia-blockchain/tree/main/tests#readme
 #
-name: MacOS TEST_NAME Tests
+name: MacOS TEST_NAME Test
 
 on:
   push:
-- 
2.34.1


From 79034bb82ea1cdda93ee48122002f8bcb9e534f8 Mon Sep 17 00:00:00 2001
From: Arvid Norberg <arvid@libtorrent.org>
Date: Wed, 27 Apr 2022 20:43:33 +0200
Subject: [PATCH 70/77] improve generate_chain (#11242)

* improve generate_chain to have proper command line options. Make it include block references by default.

* fix shell linter
---
 tests/block_tools.py          |  19 +++
 tests/tools/test_full_sync.py |   9 +-
 tools/cpu_utilization.py      |   2 +
 tools/generate_chain.py       | 277 ++++++++++++++++++++++------------
 tools/run_benchmark.sh        |  20 +++
 tools/test_constants.py       |   3 +-
 tools/test_full_sync.py       | 103 +++++++++++--
 7 files changed, 320 insertions(+), 113 deletions(-)
 create mode 100755 tools/run_benchmark.sh

diff --git a/tests/block_tools.py b/tests/block_tools.py
index 0cb9e541a..3212d027f 100644
--- a/tests/block_tools.py
+++ b/tests/block_tools.py
@@ -2067,3 +2067,22 @@ def create_block_tools(
     asyncio.get_event_loop().run_until_complete(bt.setup_plots())
 
     return bt
+
+
+def make_unfinished_block(block: FullBlock, constants: ConsensusConstants) -> UnfinishedBlock:
+    if is_overflow_block(constants, block.reward_chain_block.signage_point_index):
+        finished_ss = block.finished_sub_slots[:-1]
+    else:
+        finished_ss = block.finished_sub_slots
+
+    return UnfinishedBlock(
+        finished_ss,
+        block.reward_chain_block.get_unfinished(),
+        block.challenge_chain_sp_proof,
+        block.reward_chain_sp_proof,
+        block.foliage,
+        block.foliage_transaction_block,
+        block.transactions_info,
+        block.transactions_generator,
+        block.transactions_generator_ref_list,
+    )
diff --git a/tests/tools/test_full_sync.py b/tests/tools/test_full_sync.py
index ad64138ec..dd8f1373c 100644
--- a/tests/tools/test_full_sync.py
+++ b/tests/tools/test_full_sync.py
@@ -4,10 +4,15 @@ import asyncio
 import os
 from pathlib import Path
 
+import pytest
+
 from tools.test_full_sync import run_sync_test
 
 
-def test_full_sync_test():
+@pytest.mark.parametrize("keep_up", [True, False])
+def test_full_sync_test(keep_up: bool):
     file_path = os.path.realpath(__file__)
     db_file = Path(file_path).parent / "test-blockchain-db.sqlite"
-    asyncio.run(run_sync_test(db_file, db_version=2, profile=False, single_thread=False, test_constants=False))
+    asyncio.run(
+        run_sync_test(db_file, db_version=2, profile=False, single_thread=False, test_constants=False, keep_up=keep_up)
+    )
diff --git a/tools/cpu_utilization.py b/tools/cpu_utilization.py
index 9f9f9019a..6b11d82df 100644
--- a/tools/cpu_utilization.py
+++ b/tools/cpu_utilization.py
@@ -60,6 +60,8 @@ def main(pid: int, output: str, threads: bool) -> None:
 
             time.sleep(0.05)
             step += 1
+    except psutil.NoSuchProcess:
+        pass
     except KeyboardInterrupt:
         pass
 
diff --git a/tools/generate_chain.py b/tools/generate_chain.py
index 4e7a8e942..b842778a1 100644
--- a/tools/generate_chain.py
+++ b/tools/generate_chain.py
@@ -1,17 +1,19 @@
 import cProfile
 import random
 import sqlite3
+import sys
 import time
 from contextlib import closing, contextmanager
 from pathlib import Path
-from typing import Iterator, List
+from typing import Iterator, List, Optional
 
+import click
 import zstd
 
 from chia.types.blockchain_format.coin import Coin
 from chia.types.spend_bundle import SpendBundle
 from chia.util.chia_logging import initialize_logging
-from chia.util.ints import uint64
+from chia.util.ints import uint32, uint64
 from chia.util.path import mkdir
 from tests.block_tools import create_block_tools
 from tests.util.keyring import TempKeyring
@@ -19,7 +21,7 @@ from tools.test_constants import test_constants
 
 
 @contextmanager
-def enable_profiler(profile: bool) -> Iterator[None]:
+def enable_profiler(profile: bool, counter: int) -> Iterator[None]:
     if not profile:
         yield
         return
@@ -28,107 +30,92 @@ def enable_profiler(profile: bool) -> Iterator[None]:
         yield
 
     pr.create_stats()
-    pr.dump_stats("generate-chain.profile")
-
-
-root_path = Path("./test-chain").resolve()
-mkdir(root_path)
-with TempKeyring() as keychain:
-
-    bt = create_block_tools(constants=test_constants, root_path=root_path, keychain=keychain)
-    initialize_logging(
-        "generate_chain", {"log_level": "DEBUG", "log_stdout": False, "log_syslog": False}, root_path=root_path
-    )
-
-    with closing(sqlite3.connect("stress-test-blockchain.sqlite")) as db:
-
-        print("initializing v2 block store")
-        db.execute(
-            "CREATE TABLE full_blocks("
-            "header_hash blob PRIMARY KEY,"
-            "prev_hash blob,"
-            "height bigint,"
-            "in_main_chain tinyint,"
-            "block blob)"
+    pr.dump_stats(f"generate-chain-{counter}.profile")
+
+
+@click.command()
+@click.option("--length", type=int, default=None, required=False, help="the number of blocks to generate")
+@click.option(
+    "--fill-rate",
+    type=int,
+    default=100,
+    required=False,
+    help="the transaction fill rate of blocks. Specified in percent of max block cost",
+)
+@click.option("--profile", is_flag=True, required=False, default=False, help="dump CPU profile at the end")
+@click.option(
+    "--block-refs",
+    type=bool,
+    required=False,
+    default=True,
+    help="include a long list of block references in each transaction block",
+)
+@click.option(
+    "--output", type=str, required=False, default=None, help="the filename to write the resulting sqlite database to"
+)
+def main(length: int, fill_rate: int, profile: bool, block_refs: bool, output: Optional[str]) -> None:
+
+    if fill_rate < 0 or fill_rate > 100:
+        print("fill-rate must be within [0, 100]")
+        sys.exit(1)
+
+    if not length:
+        if block_refs:
+            # we won't have full reflist until after 512 transaction blocks
+            length = 1500
+        else:
+            # the cost of looking up coins will be deflated because there are so
+            # few, but a longer chain takes longer to make and test
+            length = 500
+
+    if length <= 0:
+        print("the output blockchain must have at least length 1")
+        sys.exit(1)
+
+    if output is None:
+        output = f"stress-test-blockchain-{length}-{fill_rate}{'-refs' if block_refs else ''}.sqlite"
+
+    root_path = Path("./test-chain").resolve()
+    mkdir(root_path)
+    with TempKeyring() as keychain:
+
+        bt = create_block_tools(constants=test_constants, root_path=root_path, keychain=keychain)
+        initialize_logging(
+            "generate_chain", {"log_level": "DEBUG", "log_stdout": False, "log_syslog": False}, root_path=root_path
         )
 
-        wallet = bt.get_farmer_wallet_tool()
-        coinbase_puzzlehash = wallet.get_new_puzzlehash()
+        print(f"writing blockchain to {output}")
+        with closing(sqlite3.connect(output)) as db:
 
-        blocks = bt.get_consecutive_blocks(
-            3,
-            farmer_reward_puzzle_hash=coinbase_puzzlehash,
-            pool_reward_puzzle_hash=coinbase_puzzlehash,
-            guarantee_transaction_block=True,
-            genesis_timestamp=uint64(1234567890),
-            time_per_block=30,
-        )
-
-        unspent_coins: List[Coin] = []
-
-        for b in blocks:
-            for coin in b.get_included_reward_coins():
-                if coin.puzzle_hash == coinbase_puzzlehash:
-                    unspent_coins.append(coin)
             db.execute(
-                "INSERT INTO full_blocks VALUES(?, ?, ?, ?, ?)",
-                (
-                    b.header_hash,
-                    b.prev_header_hash,
-                    b.height,
-                    1,  # in_main_chain
-                    zstd.compress(bytes(b)),
-                ),
+                "CREATE TABLE full_blocks("
+                "header_hash blob PRIMARY KEY,"
+                "prev_hash blob,"
+                "height bigint,"
+                "in_main_chain tinyint,"
+                "block blob)"
             )
-        db.commit()
 
-        # build 2000 transaction blocks
-        with enable_profiler(False):
-            for k in range(2000):
-
-                start_time = time.monotonic()
+            wallet = bt.get_farmer_wallet_tool()
+            farmer_puzzlehash = wallet.get_new_puzzlehash()
+            pool_puzzlehash = wallet.get_new_puzzlehash()
+            transaction_blocks: List[uint32] = []
+
+            blocks = bt.get_consecutive_blocks(
+                3,
+                farmer_reward_puzzle_hash=farmer_puzzlehash,
+                pool_reward_puzzle_hash=pool_puzzlehash,
+                keep_going_until_tx_block=True,
+                genesis_timestamp=uint64(1234567890),
+                use_timestamp_residual=True,
+            )
 
-                print(f"block: {len(blocks)} unspent: {len(unspent_coins)}")
-                new_coins: List[Coin] = []
-                spend_bundles: List[SpendBundle] = []
-                for i in range(1010):
-                    if unspent_coins == []:
-                        break
-                    c = unspent_coins.pop(random.randrange(len(unspent_coins)))
-                    receiver = wallet.get_new_puzzlehash()
-                    bundle = wallet.generate_signed_transaction(uint64(c.amount // 2), receiver, c)
-                    new_coins.extend(bundle.additions())
-                    spend_bundles.append(bundle)
-
-                coinbase_puzzlehash = wallet.get_new_puzzlehash()
-                blocks = bt.get_consecutive_blocks(
-                    1,
-                    blocks,
-                    farmer_reward_puzzle_hash=coinbase_puzzlehash,
-                    pool_reward_puzzle_hash=coinbase_puzzlehash,
-                    guarantee_transaction_block=True,
-                    transaction_data=SpendBundle.aggregate(spend_bundles),
-                    time_per_block=30,
-                )
+            unspent_coins: List[Coin] = []
 
-                b = blocks[-1]
+            for b in blocks:
                 for coin in b.get_included_reward_coins():
-                    if coin.puzzle_hash == coinbase_puzzlehash:
+                    if coin.puzzle_hash in [farmer_puzzlehash, pool_puzzlehash]:
                         unspent_coins.append(coin)
-                unspent_coins.extend(new_coins)
-
-                if b.transactions_info:
-                    fill_rate = b.transactions_info.cost / test_constants.MAX_BLOCK_COST_CLVM
-                else:
-                    fill_rate = 0
-
-                end_time = time.monotonic()
-
-                print(
-                    f"included {i} spend bundles. fill_rate: {fill_rate*100:.1f}% "
-                    f"new coins: {len(new_coins)} time: {end_time - start_time:0.2f}s"
-                )
-
                 db.execute(
                     "INSERT INTO full_blocks VALUES(?, ?, ?, ?, ?)",
                     (
@@ -139,4 +126,104 @@ with TempKeyring() as keychain:
                         zstd.compress(bytes(b)),
                     ),
                 )
-                db.commit()
+            db.commit()
+
+            b = blocks[-1]
+
+            num_tx_per_block = int(1010 * fill_rate / 100)
+
+            while True:
+                with enable_profiler(profile, b.height):
+                    start_time = time.monotonic()
+
+                    new_coins: List[Coin] = []
+                    spend_bundles: List[SpendBundle] = []
+                    i = 0
+                    for i in range(num_tx_per_block):
+                        if unspent_coins == []:
+                            break
+                        c = unspent_coins.pop(random.randrange(len(unspent_coins)))
+                        receiver = wallet.get_new_puzzlehash()
+                        bundle = wallet.generate_signed_transaction(uint64(c.amount // 2), receiver, c)
+                        new_coins.extend(bundle.additions())
+                        spend_bundles.append(bundle)
+
+                    block_references: List[uint32]
+                    if block_refs:
+                        block_references = random.sample(transaction_blocks, min(len(transaction_blocks), 512))
+                        random.shuffle(block_references)
+                    else:
+                        block_references = []
+
+                    farmer_puzzlehash = wallet.get_new_puzzlehash()
+                    pool_puzzlehash = wallet.get_new_puzzlehash()
+                    prev_num_blocks = len(blocks)
+                    blocks = bt.get_consecutive_blocks(
+                        1,
+                        blocks,
+                        farmer_reward_puzzle_hash=farmer_puzzlehash,
+                        pool_reward_puzzle_hash=pool_puzzlehash,
+                        keep_going_until_tx_block=True,
+                        transaction_data=SpendBundle.aggregate(spend_bundles),
+                        previous_generator=block_references,
+                        use_timestamp_residual=True,
+                    )
+                    prev_tx_block = b
+                    prev_block = blocks[-2]
+                    b = blocks[-1]
+                    height = b.height
+                    assert b.is_transaction_block()
+                    transaction_blocks.append(height)
+
+                    for bl in blocks[prev_num_blocks:]:
+                        for coin in bl.get_included_reward_coins():
+                            unspent_coins.append(coin)
+                    unspent_coins.extend(new_coins)
+
+                    if b.transactions_info:
+                        actual_fill_rate = b.transactions_info.cost / test_constants.MAX_BLOCK_COST_CLVM
+                        if b.transactions_info.cost > test_constants.MAX_BLOCK_COST_CLVM:
+                            print(f"COST EXCEEDED: {b.transactions_info.cost}")
+                    else:
+                        actual_fill_rate = 0
+
+                    end_time = time.monotonic()
+                    if prev_tx_block is not None:
+                        assert b.foliage_transaction_block
+                        assert prev_tx_block.foliage_transaction_block
+                        ts = b.foliage_transaction_block.timestamp - prev_tx_block.foliage_transaction_block.timestamp
+                    else:
+                        ts = 0
+
+                    print(
+                        f"height: {b.height} "
+                        f"spends: {i+1} "
+                        f"refs: {len(block_references)} "
+                        f"fill_rate: {actual_fill_rate*100:.1f}% "
+                        f"new coins: {len(new_coins)} "
+                        f"unspent: {len(unspent_coins)} "
+                        f"difficulty: {b.weight - prev_block.weight} "
+                        f"timestamp: {ts} "
+                        f"time: {end_time - start_time:0.2f}s "
+                        f"tx-block-ratio: {len(transaction_blocks)*100/b.height:0.0f}% "
+                    )
+
+                    new_blocks = [
+                        (
+                            b.header_hash,
+                            b.prev_header_hash,
+                            b.height,
+                            1,  # in_main_chain
+                            zstd.compress(bytes(b)),
+                        )
+                        for b in blocks[prev_num_blocks:]
+                    ]
+                    db.executemany("INSERT INTO full_blocks VALUES(?, ?, ?, ?, ?)", new_blocks)
+                    db.commit()
+                    if height >= length:
+                        break
+
+
+if __name__ == "__main__":
+    # pylint: disable = no-value-for-parameter
+    main()
diff --git a/tools/run_benchmark.sh b/tools/run_benchmark.sh
new file mode 100755
index 000000000..5fb0d19fc
--- /dev/null
+++ b/tools/run_benchmark.sh
@@ -0,0 +1,20 @@
+#!/bin/sh
+
+run_benchmark() {
+   # shellcheck disable=SC2086
+   python ./tools/test_full_sync.py run $3 --profile --test-constants "$1" &
+   test_pid=$!
+   python ./tools/cpu_utilization.py $test_pid
+   mkdir -p "$2"
+   mv test-full-sync.log cpu.png cpu-usage.log plot-cpu.gnuplot "$2"
+   python ./tools/test_full_sync.py analyze
+   mv slow-batch-*.profile slow-batch-*.png "$2"
+}
+
+cd ..
+
+run_benchmark stress-test-blockchain-1500-0-refs.sqlite "$1-sync-empty" ""
+run_benchmark stress-test-blockchain-1500-0-refs.sqlite "$1-keepup-empty" --keep-up
+
+run_benchmark stress-test-blockchain-500-100.sqlite "$1-sync-full" ""
+run_benchmark stress-test-blockchain-500-100.sqlite "$1-keepup-full" --keep-up
diff --git a/tools/test_constants.py b/tools/test_constants.py
index a2c2be4e8..0d86a8fab 100644
--- a/tools/test_constants.py
+++ b/tools/test_constants.py
@@ -2,8 +2,9 @@ from chia.consensus.default_constants import DEFAULT_CONSTANTS
 
 test_constants = DEFAULT_CONSTANTS.replace(
     **{
-        "MIN_PLOT_SIZE": 20,
+        "MIN_PLOT_SIZE": 18,
         "MIN_BLOCKS_PER_CHALLENGE_BLOCK": 12,
+        "DIFFICULTY_STARTING": 2 ** 9,
         "DISCRIMINANT_SIZE_BITS": 16,
         "SUB_EPOCH_BLOCKS": 170,
         "WEIGHT_PROOF_THRESHOLD": 2,
diff --git a/tools/test_full_sync.py b/tools/test_full_sync.py
index d4088b9bf..1eec2373c 100755
--- a/tools/test_full_sync.py
+++ b/tools/test_full_sync.py
@@ -3,21 +3,29 @@
 import asyncio
 import cProfile
 import logging
+import os
 import tempfile
 import time
 from contextlib import contextmanager
 from pathlib import Path
-from typing import Iterator
+from typing import Iterator, List
 
 import aiosqlite
 import click
 import zstd
 
+import chia.server.ws_connection as ws
 from chia.cmds.init_funcs import chia_init
 from chia.consensus.default_constants import DEFAULT_CONSTANTS
 from chia.full_node.full_node import FullNode
+from chia.protocols import full_node_protocol
+from chia.server.outbound_message import Message, NodeType
+from chia.types.blockchain_format.sized_bytes import bytes32
 from chia.types.full_block import FullBlock
+from chia.types.peer_info import PeerInfo
 from chia.util.config import load_config
+from chia.util.ints import uint16
+from tests.block_tools import make_unfinished_block
 from tools.test_constants import test_constants as TEST_CONSTANTS
 
 
@@ -42,12 +50,30 @@ def enable_profiler(profile: bool, counter: int) -> Iterator[None]:
         receive_start_time = time.monotonic()
         yield
 
-    if time.monotonic() - receive_start_time > 10:
+    if time.monotonic() - receive_start_time > 5:
         pr.create_stats()
         pr.dump_stats(f"slow-batch-{counter:05d}.profile")
 
 
-async def run_sync_test(file: Path, db_version, profile: bool, single_thread: bool, test_constants: bool) -> None:
+class FakeServer:
+    async def send_to_all(self, messages: List[Message], node_type: NodeType):
+        pass
+
+    async def send_to_all_except(self, messages: List[Message], node_type: NodeType, exclude: bytes32):
+        pass
+
+
+class FakePeer:
+    def get_peer_logging(self) -> PeerInfo:
+        return PeerInfo("0.0.0.0", uint16(0))
+
+    def __init__(self):
+        self.peer_node_id = bytes([0] * 32)
+
+
+async def run_sync_test(
+    file: Path, db_version, profile: bool, single_thread: bool, test_constants: bool, keep_up: bool
+) -> None:
 
     logger = logging.getLogger()
     logger.setLevel(logging.WARNING)
@@ -84,10 +110,15 @@ async def run_sync_test(file: Path, db_version, profile: bool, single_thread: bo
 
         try:
             await full_node._start()
+            full_node.set_server(FakeServer())  # type: ignore[arg-type]
+
+            peer: ws.WSChiaConnection = FakePeer()  # type: ignore[assignment]
 
             print()
             counter = 0
             height = 0
+            monotonic = 0
+            prev_hash = None
             async with aiosqlite.connect(file) as in_db:
                 await in_db.execute("pragma query_only")
                 rows = await in_db.execute(
@@ -97,33 +128,67 @@ async def run_sync_test(file: Path, db_version, profile: bool, single_thread: bo
                 block_batch = []
 
                 start_time = time.monotonic()
+                logger.warning(f"starting test {start_time}")
+                worst_batch_height = None
+                worst_batch_time_per_block = None
                 async for r in rows:
+                    batch_start_time = time.monotonic()
                     with enable_profiler(profile, counter):
                         block = FullBlock.from_bytes(zstd.decompress(r[2]))
-
                         block_batch.append(block)
+
+                        assert block.height == monotonic
+                        monotonic += 1
+                        assert prev_hash is None or block.prev_header_hash == prev_hash
+                        prev_hash = block.header_hash
+
                         if len(block_batch) < 32:
                             continue
 
-                        success, advanced_peak, fork_height, coin_changes = await full_node.receive_block_batch(
-                            block_batch, None, None  # type: ignore[arg-type]
-                        )
-                        end_height = block_batch[-1].height
-                        full_node.blockchain.clean_block_record(end_height - full_node.constants.BLOCKS_CACHE_SIZE)
+                        if keep_up:
+                            for b in block_batch:
+                                await full_node.respond_unfinished_block(
+                                    full_node_protocol.RespondUnfinishedBlock(make_unfinished_block(b, constants)), peer
+                                )
+                                await full_node.respond_block(full_node_protocol.RespondBlock(b))
+                        else:
+                            success, advanced_peak, fork_height, coin_changes = await full_node.receive_block_batch(
+                                block_batch, peer, None
+                            )
+                            end_height = block_batch[-1].height
+                            full_node.blockchain.clean_block_record(end_height - full_node.constants.BLOCKS_CACHE_SIZE)
+
+                            if not success:
+                                raise RuntimeError("failed to ingest block batch")
+
+                            assert advanced_peak
+
+                        time_per_block = (time.monotonic() - batch_start_time) / len(block_batch)
+                        if not worst_batch_height or worst_batch_time_per_block > time_per_block:
+                            worst_batch_height = height
+                            worst_batch_time_per_block = time_per_block
 
-                    assert success
-                    assert advanced_peak
                     counter += len(block_batch)
                     height += len(block_batch)
-                    print(f"\rheight {height} {counter/(time.monotonic() - start_time):0.2f} blocks/s   ", end="")
+                    print(
+                        f"\rheight {height} {time_per_block:0.2f} s/block   ",
+                        end="",
+                    )
+                    batch_start_time = time.monotonic()
                     block_batch = []
                     if check_log.exit_with_failure:
                         raise RuntimeError("error printed to log. exiting")
 
                     if counter >= 100000:
-                        start_time = time.monotonic()
+                        batch_start_time = time.monotonic()
                         counter = 0
                         print()
+                end_time = time.monotonic()
+                logger.warning(f"test completed at {end_time}")
+                logger.warning(f"duration: {end_time - start_time:0.2f} s")
+                logger.warning(f"worst time-per-block: {worst_batch_time_per_block:0.2f} s")
+                logger.warning(f"worst height: {worst_batch_height}")
+                logger.warning(f"end-height: {height}")
         finally:
             print("closing full node")
             full_node._close()
@@ -153,11 +218,19 @@ def main() -> None:
     default=False,
     help="run node in a single process, to include validation in profiles",
 )
-def run(file: Path, db_version: int, profile: bool, single_thread: bool, test_constants: bool) -> None:
+@click.option(
+    "--keep-up",
+    is_flag=True,
+    required=False,
+    default=False,
+    help="pass blocks to the full node as if we're staying synced, rather than syncing",
+)
+def run(file: Path, db_version: int, profile: bool, single_thread: bool, test_constants: bool, keep_up: bool) -> None:
     """
     The FILE parameter should point to an existing blockchain database file (in v2 format)
     """
-    asyncio.run(run_sync_test(Path(file), db_version, profile, single_thread, test_constants))
+    print(f"PID: {os.getpid()}")
+    asyncio.run(run_sync_test(Path(file), db_version, profile, single_thread, test_constants, keep_up))
 
 
 @main.command("analyze", short_help="generate call stacks for all profiles dumped to current directory")
-- 
2.34.1


From 23158c656e46f2791bc72bef899d21c043d76d59 Mon Sep 17 00:00:00 2001
From: Mariano Sorgente <3069354+mariano54@users.noreply.github.com>
Date: Wed, 27 Apr 2022 17:07:41 -0400
Subject: [PATCH 71/77] Fix issue with missing coins (#11338)

* raise error when request fails

* Gather when cancelling sync

* Increase timeout

* Increase timeout even more
---
 chia/wallet/util/wallet_sync_utils.py | 17 +++++++++--------
 chia/wallet/wallet_node.py            |  3 +++
 2 files changed, 12 insertions(+), 8 deletions(-)

diff --git a/chia/wallet/util/wallet_sync_utils.py b/chia/wallet/util/wallet_sync_utils.py
index 01e1a66ef..484edcf35 100644
--- a/chia/wallet/util/wallet_sync_utils.py
+++ b/chia/wallet/util/wallet_sync_utils.py
@@ -57,10 +57,10 @@ async def subscribe_to_phs(
     Tells full nodes that we are interested in puzzle hashes, and returns the response.
     """
     msg = wallet_protocol.RegisterForPhUpdates(puzzle_hashes, uint32(max(min_height, uint32(0))))
-    all_coins_state: Optional[RespondToPhUpdates] = await peer.register_interest_in_puzzle_hash(msg)
-    if all_coins_state is not None:
-        return all_coins_state.coin_states
-    return []
+    all_coins_state: Optional[RespondToPhUpdates] = await peer.register_interest_in_puzzle_hash(msg, timeout=300)
+    if all_coins_state is None:
+        raise ValueError(f"None response from peer {peer.peer_host} for register_interest_in_puzzle_hash")
+    return all_coins_state.coin_states
 
 
 async def subscribe_to_coin_updates(
@@ -72,10 +72,11 @@ async def subscribe_to_coin_updates(
     Tells full nodes that we are interested in coin ids, and returns the response.
     """
     msg = wallet_protocol.RegisterForCoinUpdates(coin_names, uint32(max(0, min_height)))
-    all_coins_state: Optional[RespondToCoinUpdates] = await peer.register_interest_in_coin(msg)
-    if all_coins_state is not None:
-        return all_coins_state.coin_states
-    return []
+    all_coins_state: Optional[RespondToCoinUpdates] = await peer.register_interest_in_coin(msg, timeout=300)
+
+    if all_coins_state is None:
+        raise ValueError(f"None response from peer {peer.peer_host} for register_interest_in_coin")
+    return all_coins_state.coin_states
 
 
 def validate_additions(
diff --git a/chia/wallet/wallet_node.py b/chia/wallet/wallet_node.py
index f417e58d7..79e250826 100644
--- a/chia/wallet/wallet_node.py
+++ b/chia/wallet/wallet_node.py
@@ -707,9 +707,11 @@ class WalletNode:
         for states in chunks(items, chunk_size):
             if self.server is None:
                 self.log.error("No server")
+                await asyncio.gather(*all_tasks)
                 return False
             if peer.peer_node_id not in self.server.all_connections:
                 self.log.error(f"Disconnected from peer {peer.peer_node_id} host {peer.peer_host}")
+                await asyncio.gather(*all_tasks)
                 return False
             if trusted:
                 async with self.wallet_state_manager.db_wrapper.lock:
@@ -737,6 +739,7 @@ class WalletNode:
                     await asyncio.sleep(0.1)
                     if self._shut_down:
                         self.log.info("Terminating receipt and validation due to shut down request")
+                        await asyncio.gather(*all_tasks)
                         return False
                 concurrent_tasks_cs_heights.append(last_change_height_cs(states[0]))
                 all_tasks.append(asyncio.create_task(receive_and_validate(states, idx, concurrent_tasks_cs_heights)))
-- 
2.34.1


From 58e231e92940d5971950ce63133cf1c1c563c902 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Wed, 27 Apr 2022 14:28:13 -0700
Subject: [PATCH 72/77] add daemon entry point (#11329)

* add daemon entry point

* remove argv parameter from chia.daemon.server.main()
---
 chia/daemon/server.py | 6 +++---
 setup.py              | 1 +
 2 files changed, 4 insertions(+), 3 deletions(-)

diff --git a/chia/daemon/server.py b/chia/daemon/server.py
index db3618bdd..a8e6a5cb7 100644
--- a/chia/daemon/server.py
+++ b/chia/daemon/server.py
@@ -1401,13 +1401,13 @@ def run_daemon(root_path: Path, wait_for_unlock: bool = False) -> int:
     return result
 
 
-def main(argv) -> int:
+def main() -> int:
     from chia.util.default_root import DEFAULT_ROOT_PATH
     from chia.util.keychain import Keychain
 
-    wait_for_unlock = "--wait-for-unlock" in argv and Keychain.is_keyring_locked()
+    wait_for_unlock = "--wait-for-unlock" in sys.argv[1:] and Keychain.is_keyring_locked()
     return run_daemon(DEFAULT_ROOT_PATH, wait_for_unlock)
 
 
 if __name__ == "__main__":
-    main(sys.argv[1:])
+    main()
diff --git a/setup.py b/setup.py
index 6fcb759a4..e7e85f0f2 100644
--- a/setup.py
+++ b/setup.py
@@ -118,6 +118,7 @@ kwargs = dict(
     entry_points={
         "console_scripts": [
             "chia = chia.cmds.chia:main",
+            "chia_daemon = chia.daemon.server:main",
             "chia_wallet = chia.server.start_wallet:main",
             "chia_full_node = chia.server.start_full_node:main",
             "chia_harvester = chia.server.start_harvester:main",
-- 
2.34.1


From ad3259e8fde75f1f0663c73a46171d599d051824 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Wed, 27 Apr 2022 18:10:41 -0500
Subject: [PATCH 73/77] Mark workspace safe for arm installers (#11339)

---
 .github/workflows/build-linux-arm64-installer.yml | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/.github/workflows/build-linux-arm64-installer.yml b/.github/workflows/build-linux-arm64-installer.yml
index cc27b1877..f2b0f97c6 100644
--- a/.github/workflows/build-linux-arm64-installer.yml
+++ b/.github/workflows/build-linux-arm64-installer.yml
@@ -31,6 +31,9 @@ jobs:
     steps:
     - uses: Chia-Network/actions/clean-workspace@main
 
+    - name: Add safe git directory
+      uses: Chia-Network/actions/git-mark-workspace-safe@main
+
     - name: Checkout Code
       uses: actions/checkout@v3
       with:
-- 
2.34.1


From f1b7eb0d2d05eeb8c8ac8a8e38307e2618562580 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Thu, 28 Apr 2022 09:31:22 -0500
Subject: [PATCH 74/77] Forward "proof" event to metrics (#11345)

---
 chia/rpc/farmer_rpc_api.py | 9 +++++++++
 1 file changed, 9 insertions(+)

diff --git a/chia/rpc/farmer_rpc_api.py b/chia/rpc/farmer_rpc_api.py
index fb22062ad..ffbab929a 100644
--- a/chia/rpc/farmer_rpc_api.py
+++ b/chia/rpc/farmer_rpc_api.py
@@ -64,6 +64,15 @@ class FarmerRpcApi:
                     "metrics",
                 )
             )
+        elif change == "proof":
+            payloads.append(
+                create_payload_dict(
+                    "proof",
+                    change_data,
+                    self.service_name,
+                    "metrics",
+                )
+            )
 
         return payloads
 
-- 
2.34.1


From 9dc4e159054826ae2d50229a8521304fd3b16165 Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Thu, 28 Apr 2022 09:15:31 -0700
Subject: [PATCH 75/77] Only Ubuntu 18 needs distutils (#11308)

Co-authored-by: wjblanke <wjb98672@gmail.com>
---
 install.sh | 9 ++++++---
 1 file changed, 6 insertions(+), 3 deletions(-)

diff --git a/install.sh b/install.sh
index bed90d26b..98022928e 100755
--- a/install.sh
+++ b/install.sh
@@ -129,19 +129,22 @@ if [ "$(uname)" = "Linux" ]; then
     # Ubuntu
     echo "Installing on Ubuntu pre 20.*."
     sudo apt-get update
+    # distutils must be installed as well to avoid a complaint about ensurepip while
+    # creating the venv.  This may be related to a mis-check while using or
+    # misconfiguration of the secondary Python version 3.7.  The primary is Python 3.6.
     sudo apt-get install -y python3.7-venv python3.7-distutils openssl
   elif [ "$UBUNTU_20" = "1" ]; then
     echo "Installing on Ubuntu 20.*."
     sudo apt-get update
-    sudo apt-get install -y python3.8-venv python3-distutils openssl
+    sudo apt-get install -y python3.8-venv openssl
   elif [ "$UBUNTU_21" = "1" ]; then
     echo "Installing on Ubuntu 21.*."
     sudo apt-get update
-    sudo apt-get install -y python3.9-venv python3-distutils openssl
+    sudo apt-get install -y python3.9-venv openssl
   elif [ "$UBUNTU_22" = "1" ]; then
     echo "Installing on Ubuntu 22.* or newer."
     sudo apt-get update
-    sudo apt-get install -y python3.10-venv python3-distutils openssl
+    sudo apt-get install -y python3.10-venv openssl
   elif [ "$DEBIAN" = "true" ]; then
     echo "Installing on Debian."
     sudo apt-get update
-- 
2.34.1


From 4070224da3b09b96242114f0651b51d27b762d0f Mon Sep 17 00:00:00 2001
From: Kyle Altendorf <sda@fstab.net>
Date: Thu, 28 Apr 2022 09:16:16 -0700
Subject: [PATCH 76/77] Use Install.ps1 in build_windows.ps1 (#11058)

* Use Install.ps1 in build_windows.ps1

* -d

* stop moving madmax and bladebit down into site-packages
---
 build_scripts/build_windows.ps1 | 21 ++-------------------
 1 file changed, 2 insertions(+), 19 deletions(-)

diff --git a/build_scripts/build_windows.ps1 b/build_scripts/build_windows.ps1
index e0e7e8fcc..35bc988f0 100644
--- a/build_scripts/build_windows.ps1
+++ b/build_scripts/build_windows.ps1
@@ -26,12 +26,9 @@ else
 Write-Output "   ---"
 Write-Output "Create venv - python3.9 is required in PATH"
 Write-Output "   ---"
-python -m venv venv
+.\Install.ps1 -d
 . .\venv\Scripts\Activate.ps1
-python -m pip install --upgrade pip
-pip install wheel pep517
-pip install pywin32
-pip install pyinstaller==5.0
+
 
 Write-Output "   ---"
 # The environment variable CHIA_INSTALLER_VERSION needs to be defined
@@ -43,20 +40,6 @@ if (-not (Test-Path env:CHIA_INSTALLER_VERSION)) {
 Write-Output "Chia Version is: $env:CHIA_INSTALLER_VERSION"
 Write-Output "   ---"
 
-Write-Output "Checking if madmax exists"
-Write-Output "   ---"
-if (Test-Path -Path .\madmax\) {
-    Write-Output "   madmax exists, moving to expected directory"
-    mv .\madmax\ .\venv\lib\site-packages\
-}
-
-Write-Output "Checking if bladebit exists"
-Write-Output "   ---"
-if (Test-Path -Path .\bladebit\) {
-    Write-Output "   bladebit exists, moving to expected directory"
-    mv .\bladebit\ .\venv\lib\site-packages\
-}
-
 Write-Output "   ---"
 Write-Output "Build chia-blockchain wheels"
 Write-Output "   ---"
-- 
2.34.1


From acfdd75a20a4d8b09fd81d8d4489972e50cbb5f8 Mon Sep 17 00:00:00 2001
From: Chris Marslender <chrismarslender@gmail.com>
Date: Thu, 28 Apr 2022 11:16:53 -0500
Subject: [PATCH 77/77] Updated warning about CHIA_ROOT being set when running
 init (#11346)

* Remove warning about CHIA_ROOT being set when running init

* Update to still output the CHIA_ROOT if set, but not instruct the user to remove it

* Store chia_root in a var
---
 chia/cmds/init_funcs.py | 9 +++------
 1 file changed, 3 insertions(+), 6 deletions(-)

diff --git a/chia/cmds/init_funcs.py b/chia/cmds/init_funcs.py
index 70dd0c1ce..a3bd26b7e 100644
--- a/chia/cmds/init_funcs.py
+++ b/chia/cmds/init_funcs.py
@@ -430,12 +430,9 @@ def chia_init(
     protected Keychain. When launching the daemon from the GUI, we want the GUI to
     handle unlocking the keychain.
     """
-    if os.environ.get("CHIA_ROOT", None) is not None:
-        print(
-            f"warning, your CHIA_ROOT is set to {os.environ['CHIA_ROOT']}. "
-            f"Please unset the environment variable and run chia init again\n"
-            f"or manually migrate config.yaml"
-        )
+    chia_root = os.environ.get("CHIA_ROOT", None)
+    if chia_root is not None:
+        print(f"CHIA_ROOT is set to {chia_root}")
 
     print(f"Chia directory {root_path}")
     if root_path.is_dir() and Path(root_path / "config" / "config.yaml").exists():
-- 
2.34.1

